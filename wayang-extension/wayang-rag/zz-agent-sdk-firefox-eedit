


# Wayang AI Agent SDK - Complete Class Outline

Based on the comprehensive blueprint, here's' the complete class outline for the Agent SDK. This SDK will be used by both the main platform and standalone generated agents.

## 1. Core Agent Abstractions

### 1.1 Agent Base Classes

```java
package io.wayang.agent.core;


```

### 1.2 Agent Context and Results

```java
package io.wayang.agent.core;

```

## 2. Node System

### 2.1 Node Abstractions

```java
package io.wayang.agent.node;




```

### 2.2 Specialized Node Types

```java
package io.wayang.agent.node.types;




```

## 3. Plugin System

```java
package io.wayang.agent.plugin;




```

## 4. Tool System (MCP Compatible)

```java
package io.wayang.agent.tool;



```

## 5. Memory System

```java
package io.wayang.agent.memory;



```

This is the first part of the comprehensive class outline. Would you like me to continue with:

1. RAG System
2. Orchestration Engine  
3. Planning Engine
4. Model Router
5. Observability & Monitoring
6. Security & Guardrails
7. Persistence & State Management
8. Event Bus & Messaging
9. A2A (Agent-to-Agent) Communication
10. Code Generation
11. UI/API Layer
12. Testing Infrastructure

Let me know which sections you'd like me to detail next!


# Wayang AI Agent SDK - RAG System (Continued)

## 6. RAG System

### 6.1 Core RAG Abstractions

```java
package io.wayang.agent.rag;


/**
 * Retrieval request
 */
@Immutable
public final class RetrievalRequest {
    private final String query;
    private final String tenantId;
    private final int topK;
    private final Map<String, Object> filters;
    private final RetrievalStrategy strategy;
    private final double hybridWeight; // 0.0 = pure semantic, 1.0 = pure lexical
    private final boolean enableReranking;
    
    private RetrievalRequest(Builder builder) {
        this.query = requireNonNull(builder.query);
        this.tenantId = builder.tenantId;
        this.topK = builder.topK;
        this.filters = Map.copyOf(builder.filters);
        this.strategy = builder.strategy;
        this.hybridWeight = builder.hybridWeight;
        this.enableReranking = builder.enableReranking;
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String query;
        private String tenantId;
        private int topK = 5;
        private Map<String, Object> filters = new HashMap<>();
        private RetrievalStrategy strategy = RetrievalStrategy.HYBRID;
        private double hybridWeight = 0.5;
        private boolean enableReranking = true;
        
        public Builder query(String query) {
            this.query = query;
            return this;
        }
        
        public Builder tenantId(String tenantId) {
            this.tenantId = tenantId;
            return this;
        }
        
        public Builder topK(int topK) {
            this.topK = topK;
            return this;
        }
        
        public Builder filter(String key, Object value) {
            this.filters.put(key, value);
            return this;
        }
        
        public Builder filters(Map<String, Object> filters) {
            this.filters.putAll(filters);
            return this;
        }
        
        public Builder strategy(RetrievalStrategy strategy) {
            this.strategy = strategy;
            return this;
        }
        
        public Builder hybridWeight(double hybridWeight) {
            this.hybridWeight = hybridWeight;
            return this;
        }
        
        public Builder enableReranking(boolean enableReranking) {
            this.enableReranking = enableReranking;
            return this;
        }
        
        public RetrievalRequest build() {
            return new RetrievalRequest(this);
        }
    }
}

/**
 * Document representation
 */
@Immutable
public final class Document {
    private final String id;
    private final String content;
    private final Map<String, Object> metadata;
    private final Optional<String> title;
    private final Optional<String> source;
    private final Instant createdAt;
    
    private Document(Builder builder) {
        this.id = requireNonNull(builder.id);
        this.content = requireNonNull(builder.content);
        this.metadata = Map.copyOf(builder.metadata);
        this.title = builder.title;
        this.source = builder.source;
        this.createdAt = builder.createdAt;
    }
    
    public String getId() {
        return id;
    }
    
    public String getContent() {
        return content;
    }
    
    public Map<String, Object> getMetadata() {
        return metadata;
    }
    
    public Optional<String> getTitle() {
        return title;
    }
    
    public Optional<String> getSource() {
        return source;
    }
    
    public Instant getCreatedAt() {
        return createdAt;
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String id;
        private String content;
        private Map<String, Object> metadata = new HashMap<>();
        private Optional<String> title = Optional.empty();
        private Optional<String> source = Optional.empty();
        private Instant createdAt = Instant.now();
        
        public Builder id(String id) {
            this.id = id;
            return this;
        }
        
        public Builder content(String content) {
            this.content = content;
            return this;
        }
        
        public Builder metadata(Map<String, Object> metadata) {
            this.metadata.putAll(metadata);
            return this;
        }
        
        public Builder metadata(String key, Object value) {
            this.metadata.put(key, value);
            return this;
        }
        
        public Builder title(String title) {
            this.title = Optional.ofNullable(title);
            return this;
        }
        
        public Builder source(String source) {
            this.source = Optional.ofNullable(source);
            return this;
        }
        
        public Builder createdAt(Instant createdAt) {
            this.createdAt = createdAt;
            return this;
        }
        
        public Document build() {
            return new Document(this);
        }
    }
}
```

### 6.2 Ingestion Pipeline

```java
package io.wayang.agent.rag.ingestion;

/**
 * Ingestion pipeline - processes documents for RAG
 * 
 * Pipeline stages:
 * 1. Extraction - parse various formats
 * 2. Chunking - split into optimal chunks
 * 3. Cleaning - normalize and clean text
 * 4. Enrichment - add metadata
 * 5. Embedding - generate vectors
 * 6. Indexing - store in vector DB
 */
@ApplicationScoped
public class IngestionPipeline {
    private final DocumentExtractor extractor;
    private final DocumentChunker chunker;
    private final DocumentCleaner cleaner;
    private final MetadataEnricher enricher;
    private final EmbeddingService embeddingService;
    private final VectorStore vectorStore;
    private final MetadataStore metadataStore;
    private final PIIDetector piiDetector;
    
    @Inject
    public IngestionPipeline(DocumentExtractor extractor,
                            DocumentChunker chunker,
                            DocumentCleaner cleaner,
                            MetadataEnricher enricher,
                            EmbeddingService embeddingService,
                            VectorStore vectorStore,
                            MetadataStore metadataStore,
                            PIIDetector piiDetector) {
        this.extractor = extractor;
        this.chunker = chunker;
        this.cleaner = cleaner;
        this.enricher = enricher;
        this.embeddingService = embeddingService;
        this.vectorStore = vectorStore;
        this.metadataStore = metadataStore;
        this.piiDetector = piiDetector;
    }
    
    /**
     * Ingest documents through the pipeline
     */
    public IngestionResult ingest(IngestionRequest request) {
        IngestionResult.Builder resultBuilder = IngestionResult.builder();
        
        for (Document document : request.getDocuments()) {
            try {
                ingestDocument(document, request, resultBuilder);
            } catch (Exception e) {
                resultBuilder.failure(document.getId(), e.getMessage());
            }
        }
        
        return resultBuilder.build();
    }
    
    private void ingestDocument(Document document, IngestionRequest request,
                               IngestionResult.Builder resultBuilder) {
        // 1. Extract text if needed (for PDFs, DOCX, etc.)
        String extractedText = extractor.extract(document);
        
        // 2. Detect and optionally redact PII
        if (request.getConfig().isRedactPII()) {
            extractedText = piiDetector.redact(extractedText);
        }
        
        // 3. Clean and normalize
        String cleanedText = cleaner.clean(extractedText);
        
        // 4. Chunk into optimal segments
        List<DocumentChunk> chunks = chunker.chunk(
                cleanedText, 
                request.getConfig().getChunkSize(),
                request.getConfig().getChunkOverlap()
        );
        
        // 5. Enrich with metadata
        chunks = enricher.enrich(chunks, document.getMetadata());
        
        // 6. Generate embeddings
        List<ChunkWithEmbedding> embeddedChunks = chunks.stream()
                .map(chunk -> {
                    float[] embedding = embeddingService.embed(chunk.getText());
                    return new ChunkWithEmbedding(chunk, embedding);
                })
                .collect(Collectors.toList());
        
        // 7. Store in vector store
        for (ChunkWithEmbedding embeddedChunk : embeddedChunks) {
            String chunkId = generateChunkId(document.getId(), embeddedChunk.getChunk());
            
            vectorStore.upsert(
                    chunkId,
                    embeddedChunk.getEmbedding(),
                    embeddedChunk.getChunk().toMap()
            );
            
            // Store metadata separately for efficient filtering
            metadataStore.store(chunkId, document.getId(), embeddedChunk.getChunk());
        }
        
        resultBuilder.success(document.getId(), embeddedChunks.size());
    }
    
    private String generateChunkId(String documentId, DocumentChunk chunk) {
        return documentId + "_chunk_" + chunk.getIndex();
    }
}

/**
 * Document chunker - splits documents into optimal chunks
 */
@ApplicationScoped
public class DocumentChunker {
    private final TokenizerService tokenizerService;
    
    @Inject
    public DocumentChunker(TokenizerService tokenizerService) {
        this.tokenizerService = tokenizerService;
    }
    
    /**
     * Chunk document with overlap for context preservation
     */
    public List<DocumentChunk> chunk(String text, int chunkSize, int overlap) {
        List<DocumentChunk> chunks = new ArrayList<>();
        
        // Tokenize text
        List<String> tokens = tokenizerService.tokenize(text);
        
        int index = 0;
        int position = 0;
        
        while (position < tokens.size()) {
            int end = Math.min(position + chunkSize, tokens.size());
            List<String> chunkTokens = tokens.subList(position, end);
            
            String chunkText = String.join(" ", chunkTokens);
            
            DocumentChunk chunk = DocumentChunk.builder()
                    .index(index++)
                    .text(chunkText)
                    .startPosition(position)
                    .endPosition(end)
                    .tokenCount(chunkTokens.size())
                    .build();
            
            chunks.add(chunk);
            
            // Move position with overlap
            position += (chunkSize - overlap);
        }
        
        return chunks;
    }
    
    /**
     * Semantic chunking - split by semantic boundaries
     */
    public List<DocumentChunk> semanticChunk(String text, int maxChunkSize) {
        // Split by paragraphs first
        String[] paragraphs = text.split("\n\n+");
        
        List<DocumentChunk> chunks = new ArrayList<>();
        StringBuilder currentChunk = new StringBuilder();
        int index = 0;
        int position = 0;
        
        for (String paragraph : paragraphs) {
            List<String> tokens = tokenizerService.tokenize(paragraph);
            
            if (currentChunk.length() > 0 && 
                tokenizerService.countTokens(currentChunk.toString()) + tokens.size() > maxChunkSize) {
                // Flush current chunk
                chunks.add(createChunk(currentChunk.toString(), index++, position));
                currentChunk = new StringBuilder();
            }
            
            if (currentChunk.length() > 0) {
                currentChunk.append("\n\n");
            }
            currentChunk.append(paragraph);
            position += tokens.size();
        }
        
        // Add final chunk
        if (currentChunk.length() > 0) {
            chunks.add(createChunk(currentChunk.toString(), index, position));
        }
        
        return chunks;
    }
    
    private DocumentChunk createChunk(String text, int index, int position) {
        return DocumentChunk.builder()
                .index(index)
                .text(text)
                .startPosition(position)
                .tokenCount(tokenizerService.countTokens(text))
                .build();
    }
}

```

### 6.3 Retrieval Engine

```java
package io.wayang.agent.rag.retrieval;

/**
 * Retrieval engine - hybrid search with re-ranking
 */
@ApplicationScoped
public class RetrievalEngine {
    private final VectorStore vectorStore;
    private final LexicalSearcher lexicalSearcher;
    private final ReRanker reRanker;
    private final EmbeddingService embeddingService;
    
    @Inject
    public RetrievalEngine(VectorStore vectorStore,
                          LexicalSearcher lexicalSearcher,
                          ReRanker reRanker,
                          EmbeddingService embeddingService) {
        this.vectorStore = vectorStore;
        this.lexicalSearcher = lexicalSearcher;
        this.reRanker = reRanker;
        this.embeddingService = embeddingService;
    }
    
    /**
     * Retrieve documents using configured strategy
     */
    public RetrievalResult retrieve(RetrievalRequest request) {
        return switch (request.getStrategy()) {
            case SEMANTIC -> semanticRetrieval(request);
            case LEXICAL -> lexicalRetrieval(request);
            case HYBRID -> hybridRetrieval(request);
        };
    }
    
    /**
     * Semantic retrieval using vector similarity
     */
    private RetrievalResult semanticRetrieval(RetrievalRequest request) {
        // Generate query embedding
        float[] queryEmbedding = embeddingService.embed(request.getQuery());
        
        // Search vector store
        List<SearchResult> results = vectorStore.search(
                queryEmbedding,
                request.getTopK() * 2, // Get more candidates for re-ranking
                request.getFilters()
        );
        
        // Re-rank if enabled
        if (request.isEnableReranking()) {
            results = reRanker.rerank(request.getQuery(), results, request.getTopK());
        } else {
            results = results.subList(0, Math.min(request.getTopK(), results.size()));
        }
        
        return RetrievalResult.builder()
                .documents(toDocuments(results))
                .strategy(RetrievalStrategy.SEMANTIC)
                .build();
    }
    
    /**
     * Lexical retrieval using BM25 or full-text search
     */
    private RetrievalResult lexicalRetrieval(RetrievalRequest request) {
        List<SearchResult> results = lexicalSearcher.search(
                request.getQuery(),
                request.getTopK(),
                request.getFilters()
        );
        
        return RetrievalResult.builder()
                .documents(toDocuments(results))
                .strategy(RetrievalStrategy.LEXICAL)
                .build();
    }
    
    /**
     * Hybrid retrieval combining semantic and lexical
     */
    private RetrievalResult hybridRetrieval(RetrievalRequest request) {
        // Get semantic results
        float[] queryEmbedding = embeddingService.embed(request.getQuery());
        List<SearchResult> semanticResults = vectorStore.search(
                queryEmbedding,
                request.getTopK() * 2,
                request.getFilters()
        );
        
        // Get lexical results
        List<SearchResult> lexicalResults = lexicalSearcher.search(
                request.getQuery(),
                request.getTopK() * 2,
                request.getFilters()
        );
        
        // Fuse results
        List<SearchResult> fusedResults = fuseResults(
                semanticResults,
                lexicalResults,
                request.getHybridWeight()
        );
        
        // Re-rank if enabled
        if (request.isEnableReranking()) {
            fusedResults = reRanker.rerank(request.getQuery(), fusedResults, request.getTopK());
        } else {
            fusedResults = fusedResults.subList(0, Math.min(request.getTopK(), fusedResults.size()));
        }
        
        return RetrievalResult.builder()
                .documents(toDocuments(fusedResults))
                .strategy(RetrievalStrategy.HYBRID)
                .build();
    }
    
    /**
     * Fuse semantic and lexical results using reciprocal rank fusion
     */
    private List<SearchResult> fuseResults(List<SearchResult> semanticResults,
                                          List<SearchResult> lexicalResults,
                                          double hybridWeight) {
        Map<String, FusedScore> scoreMap = new HashMap<>();
        
        // Add semantic scores
        for (int i = 0; i < semanticResults.size(); i++) {
            SearchResult result = semanticResults.get(i);
            double rrfScore = 1.0 / (60.0 + i + 1); // RRF with k=60
            scoreMap.computeIfAbsent(result.getId(), id -> new FusedScore(result))
                   .addSemanticScore(rrfScore * (1 - hybridWeight));
        }
        
        // Add lexical scores
        for (int i = 0; i < lexicalResults.size(); i++) {
            SearchResult result = lexicalResults.get(i);
            double rrfScore = 1.0 / (60.0 + i + 1);
            scoreMap.computeIfAbsent(result.getId(), id -> new FusedScore(result))
                   .addLexicalScore(rrfScore * hybridWeight);
        }
        
        // Sort by fused score
        return scoreMap.values().stream()
                .sorted(Comparator.comparing(FusedScore::getTotalScore).reversed())
                .map(FusedScore::getResult)
                .collect(Collectors.toList());
    }
    
    private List<RetrievedDocument> toDocuments(List<SearchResult> results) {
        return results.stream()
                .map(result -> RetrievedDocument.builder()
                        .id(result.getId())
                        .content(result.getContent())
                        .score(result.getScore())
                        .metadata(result.getMetadata())
                        .build())
                .collect(Collectors.toList());
    }
    
    private static class FusedScore {
        private final SearchResult result;
        private double semanticScore = 0.0;
        private double lexicalScore = 0.0;
        
        public FusedScore(SearchResult result) {
            this.result = result;
        }
        
        public void addSemanticScore(double score) {
            this.semanticScore += score;
        }
        
        public void addLexicalScore(double score) {
            this.lexicalScore += score;
        }
        
        public double getTotalScore() {
            return semanticScore + lexicalScore;
        }
        
        public SearchResult getResult() {
            return result.withScore(getTotalScore());
        }
    }
}

/**
 * Re-ranker - re-ranks retrieval results for better relevance
 */
@ApplicationScoped
public class ReRanker {
    private final CrossEncoderModel crossEncoder;
    private final LLMService llmService;
    
    @Inject
    public ReRanker(CrossEncoderModel crossEncoder, LLMService llmService) {
        this.crossEncoder = crossEncoder;
        this.llmService = llmService;
    }
    
    /**
     * Re-rank results using cross-encoder
     */
    public List<SearchResult> rerank(String query, List<SearchResult> results, int topK) {
        List<RerankScore> scores = results.stream()
                .map(result -> {
                    double score = crossEncoder.score(query, result.getContent());
                    return new RerankScore(result, score);
                })
                .sorted(Comparator.comparing(RerankScore::getScore).reversed())
                .limit(topK)
                .collect(Collectors.toList());
        
        return scores.stream()
                .map(RerankScore::getResult)
                .collect(Collectors.toList());
    }
    
    /**
     * Re-rank using LLM as judge
     */
    public List<SearchResult> rerankWithLLM(String query, List<SearchResult> results, int topK) {
        // Use LLM to score relevance
        List<RerankScore> scores = new ArrayList<>();
        
        for (SearchResult result : results) {
            String prompt = buildRelevancePrompt(query, result.getContent());
            double score = llmService.scoreRelevance(prompt);
            scores.add(new RerankScore(result, score));
        }
        
        return scores.stream()
                .sorted(Comparator.comparing(RerankScore::getScore).reversed())
                .limit(topK)
                .map(RerankScore::getResult)
                .collect(Collectors.toList());
    }
    
    private String buildRelevancePrompt(String query, String document) {
        return String.format(
                "Rate the relevance of the following document to the query on a scale of 0-1.\n\n" +
                "Query: %s\n\n" +
                "Document: %s\n\n" +
                "Relevance score:",
                query, document
        );
    }
    
    private static class RerankScore {
        private final SearchResult result;
        private final double score;
        
        public RerankScore(SearchResult result, double score) {
            this.result = result.withScore(score);
            this.score = score;
        }
        
        public SearchResult getResult() {
            return result;
        }
        
        public double getScore() {
            return score;
        }
    }
}
```

### 6.4 Context Assembly

```java
package io.wayang.agent.rag.context;

/**
 * Context assembler - builds LLM context from retrieved documents
 */
@ApplicationScoped
public class ContextAssembler {
    private final TokenizerService tokenizerService;
    
    @Inject
    public ContextAssembler(TokenizerService tokenizerService) {
        this.tokenizerService = tokenizerService;
    }
    
    /**
     * Assemble context from retrieved documents
     */
    public RAGContext assemble(List<RetrievedDocument> documents, RAGConfig config) {
        // Sort by relevance score
        List<RetrievedDocument> sortedDocs = documents.stream()
                .sorted(Comparator.comparing(RetrievedDocument::getScore).reversed())
                .collect(Collectors.toList());
        
        // Build context within token budget
        StringBuilder contextBuilder = new StringBuilder();
        List<Citation> citations = new ArrayList<>();
        int tokenCount = 0;
        int maxTokens = config.getMaxContextTokens();
        
        for (int i = 0; i < sortedDocs.size(); i++) {
            RetrievedDocument doc = sortedDocs.get(i);
            String content = doc.getContent();
            int docTokens = tokenizerService.countTokens(content);
            
            if (tokenCount + docTokens > maxTokens) {
                // Truncate if this is the first document
                if (i == 0) {
                    int availableTokens = maxTokens - tokenCount;
                    content = tokenizerService.truncate(content, availableTokens);
                    docTokens = availableTokens;
                } else {
                    break;
                }
            }
            
            // Add document to context
            if (contextBuilder.length() > 0) {
                contextBuilder.append("\n\n");
            }
            contextBuilder.append(String.format("[Document %d]\n%s", i + 1, content));
            
            // Add citation
            citations.add(Citation.builder()
                    .index(i + 1)
                    .documentId(doc.getId())
                    .source(doc.getMetadata().get("source"))
                    .score(doc.getScore())
                    .build());
            
            tokenCount += docTokens;
        }
        
        return RAGContext.builder()
                .contextText(contextBuilder.toString())
                .citations(citations)
                .tokenCount(tokenCount)
                .documentCount(citations.size())
                .build();
    }
}

/**
 * RAG context - assembled context for LLM
 */
@Immutable
public final class RAGContext {
    private final String contextText;
    private final List<Citation> citations;
    private final int tokenCount;
    private final int documentCount;
    
    private RAGContext(Builder builder) {
        this.contextText = requireNonNull(builder.contextText);
        this.citations = List.copyOf(builder.citations);
        this.tokenCount = builder.tokenCount;
        this.documentCount = builder.documentCount;
    }
    
    public String getContextText() {
        return contextText;
    }
    
    public List<Citation> getCitations() {
        return citations;
    }
    
    public int getTokenCount() {
        return tokenCount;
    }
    
    public int getDocumentCount() {
        return documentCount;
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String contextText;
        private List<Citation> citations = new ArrayList<>();
        private int tokenCount;
        private int documentCount;
        
        public Builder contextText(String contextText) {
            this.contextText = contextText;
            return this;
        }
        
        public Builder citations(List<Citation> citations) {
            this.citations = new ArrayList<>(citations);
            return this;
        }
        
        public Builder citation(Citation citation) {
            this.citations.add(citation);
            return this;
        }
        
        public Builder tokenCount(int tokenCount) {
            this.tokenCount = tokenCount;
            return this;
        }
        
        public Builder documentCount(int documentCount) {
            this.documentCount = documentCount;
            return this;
        }
        
        public RAGContext build() {
            return new RAGContext(this);
        }
    }
}

/**
 * Citation - reference to source document
 */
@Immutable
public final class Citation {
    private final int index;
    private final String documentId;
    private final Object source;
    private final double score;
    
    private Citation(Builder builder) {
        this.index = builder.index;
        this.documentId = requireNonNull(builder.documentId);
        this.source = builder.source;
        this.score = builder.score;
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private int index;
        private String documentId;
        private Object source;
        private double score;
        
        public Builder index(int index) {
            this.index = index;
            return this;
        }
        
        public Builder documentId(String documentId) {
            this.documentId = documentId;
            return this;
        }
        
        public Builder source(Object source) {
            this.source = source;
            return this;
        }
        
        public Builder score(double score) {
            this.score = score;
            return this;
        }
        
        public Citation build() {
            return new Citation(this);
        }
    }
}
```

### 6.5 Vector Store Abstraction

```java
package io.wayang.agent.rag.vector;

/**
 * Vector store interface - abstraction over vector databases
 */
public interface VectorStore {
    /**
     * Upsert vector with metadata
     */
    void upsert(String id, float[] embedding, Map<String, Object> metadata);
    
    /**
     * Batch upsert
     */
    void upsertBatch(List<VectorEntry> entries);
    
    /**
     * Search for similar vectors
     */
    List<SearchResult> search(float[] queryEmbedding, int topK, Map<String, Object> filters);
    
    /**
     * Delete vector by ID
     */
    void delete(String id);
    
    /**
     * Delete vectors by filter
     */
    void deleteByFilter(Map<String, Object> filters);
}

/**
 * pgvector implementation
 */
@ApplicationScoped
@Named("pgvector")
public class PgVectorStore implements VectorStore {
    private final DataSource dataSource;
    
    @Inject
    public PgVectorStore(@Named("rag") DataSource dataSource) {
        this.dataSource = dataSource;
    }
    
    @Override
    public void upsert(String id, float[] embedding, Map<String, Object> metadata) {
        String sql = """
            INSERT INTO embeddings (id, embedding, metadata)
            VALUES (?, ?::vector, ?::jsonb)
            ON CONFLICT (id) DO UPDATE
            SET embedding = EXCLUDED.embedding, metadata = EXCLUDED.metadata
            """;
        
        try (Connection conn = dataSource.getConnection();
             PreparedStatement stmt = conn.prepareStatement(sql)) {
            
            stmt.setString(1, id);
            stmt.setString(2, vectorToString(embedding));
            stmt.setString(3, toJson(metadata));
            stmt.executeUpdate();
            
        } catch (SQLException e) {
            throw new VectorStoreException("Failed to upsert vector", e);
        }
    }
    
    @Override
    public List<SearchResult> search(float[] queryEmbedding, int topK, Map<String, Object> filters) {
        StringBuilder sql = new StringBuilder("""
            SELECT id, content, metadata, 1 - (embedding <=> ?::vector) as score
            FROM embeddings
            """);
        
        // Add filters
        if (!filters.isEmpty()) {
            sql.append("WHERE ");
            sql.append(buildFilterClause(filters));
        }
        
        sql.append(" ORDER BY embedding <=> ?::vector LIMIT ?");
        
        try (Connection conn = dataSource.getConnection();
             PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            
            String embeddingStr = vectorToString(queryEmbedding);
            stmt.setString(1, embeddingStr);
            stmt.setString(2, embeddingStr);
            stmt.setInt(3, topK);
            
            ResultSet rs = stmt.executeQuery();
            List<SearchResult> results = new ArrayList<>();
            
            while (rs.next()) {
                results.add(SearchResult.builder()
                        .id(rs.getString("id"))
                        .content(rs.getString("content"))
                        .score(rs.getDouble("score"))
                        .metadata(parseJson(rs.getString("metadata")))
                        .build());
            }
            
            return results;
            
        } catch (SQLException e) {
            throw new VectorStoreException("Search failed", e);
        }
    }
    
    private String vectorToString(float[] vector) {
        return "[" + Arrays.stream(vector)
                .mapToObj(String::valueOf)
                .collect(Collectors.joining(",")) + "]";
    }
    
    private String buildFilterClause(Map<String, Object> filters) {
        return filters.entrySet().stream()
                .map(entry -> String.format("metadata->>'%s' = '%s'", entry.getKey(), entry.getValue()))
                .collect(Collectors.joining(" AND "));
    }
    
    // Additional implementation methods...
}
```

This completes the RAG System section. The design includes:

1. **Core RAG Service** - orchestrates ingestion and retrieval
2. **Ingestion Pipeline** - processes documents through extraction, chunking, cleaning, embedding
3. **Retrieval Engine** - hybrid search with semantic, lexical, and fused strategies
4. **Re-Ranking** - improves relevance with cross-encoders or LLM-as-judge
5. **Context Assembly** - builds optimized context for LLMs with citations
6. **Vector Store Abstraction** - pluggable vector database support (pgvector, Milvus, etc.)

Would you like me to continue with the next section? The remaining major sections are:

2. Orchestration Engine
3. Planning Engine
4. Model Router
5. Observability & Monitoring
6. Security & Guardrails
7. Persistence & State Management
8. Event Bus & Messaging
9. A2A Communication
10. Code Generation
11. UI/API Layer
12. Testing Infrastructure





# Wayang AI Agent SDK - Complete Agent SDK

## 7. Agent SDK Core

### 7.1 Agent Factory and Registry

```java
package io.wayang.agent.sdk;

/**
 * Agent factory - creates agent instances
 */
public interface AgentFactory {
    /**
     * Create agent from descriptor
     */
    Agent create(AgentDescriptor descriptor, AgentConfig config);
    
    /**
     * Supports this agent type
     */
    boolean supports(AgentType type);
    
    /**
     * Get agent type this factory creates
     */
    AgentType getAgentType();
}

/**
 * Agent registry - manages available agent types
 */
@ApplicationScoped
public class AgentRegistry {
    private final Map<String, AgentDescriptor> descriptors = new ConcurrentHashMap<>();
    private final Map<AgentType, AgentFactory> factories = new ConcurrentHashMap<>();
    
    /**
     * Register agent descriptor
     */
    public void register(AgentDescriptor descriptor) {
        descriptors.put(descriptor.getId(), descriptor);
    }
    
    /**
     * Register agent factory
     */
    public void registerFactory(AgentFactory factory) {
        factories.put(factory.getAgentType(), factory);
    }
    
    /**
     * Get agent descriptor
     */
    public Optional<AgentDescriptor> getDescriptor(String agentId) {
        return Optional.ofNullable(descriptors.get(agentId));
    }
    
    /**
     * List all agent descriptors
     */
    public List<AgentDescriptor> listDescriptors() {
        return new ArrayList<>(descriptors.values());
    }
    
    /**
     * List descriptors by capability
     */
    public List<AgentDescriptor> findByCapability(Capability capability) {
        return descriptors.values().stream()
                .filter(d -> d.getCapabilities().contains(capability))
                .collect(Collectors.toList());
    }
    
    /**
     * Create agent instance
     */
    public Agent createAgent(String agentId, AgentConfig config) {
        AgentDescriptor descriptor = getDescriptor(agentId)
                .orElseThrow(() -> new AgentException("Agent not found: " + agentId));
        
        AgentFactory factory = factories.get(descriptor.getType());
        if (factory == null) {
            throw new AgentException("No factory for agent type: " + descriptor.getType());
        }
        
        return factory.create(descriptor, config);
    }
}

/**
 * Agent descriptor - immutable metadata about agent type
 */
@Immutable
public final class AgentDescriptor {
    private final String id;
    private final String name;
    private final String version;
    private final AgentType type;
    private final String description;
    private final Set<Capability> capabilities;
    private final List<InputDescriptor> inputs;
    private final List<OutputDescriptor> outputs;
    private final Map<String, PropertyDescriptor> properties;
    private final ResourceProfile resourceProfile;
    private final SecurityProfile securityProfile;
    
    private AgentDescriptor(Builder builder) {
        this.id = requireNonNull(builder.id);
        this.name = requireNonNull(builder.name);
        this.version = requireNonNull(builder.version);
        this.type = requireNonNull(builder.type);
        this.description = builder.description;
        this.capabilities = Set.copyOf(builder.capabilities);
        this.inputs = List.copyOf(builder.inputs);
        this.outputs = List.copyOf(builder.outputs);
        this.properties = Map.copyOf(builder.properties);
        this.resourceProfile = builder.resourceProfile;
        this.securityProfile = builder.securityProfile;
    }
    
    // Getters...
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String id;
        private String name;
        private String version;
        private AgentType type;
        private String description;
        private Set<Capability> capabilities = new HashSet<>();
        private List<InputDescriptor> inputs = new ArrayList<>();
        private List<OutputDescriptor> outputs = new ArrayList<>();
        private Map<String, PropertyDescriptor> properties = new HashMap<>();
        private ResourceProfile resourceProfile = ResourceProfile.defaults();
        private SecurityProfile securityProfile = SecurityProfile.defaults();
        
        public Builder id(String id) {
            this.id = id;
            return this;
        }
        
        public Builder name(String name) {
            this.name = name;
            return this;
        }
        
        public Builder version(String version) {
            this.version = version;
            return this;
        }
        
        public Builder type(AgentType type) {
            this.type = type;
            return this;
        }
        
        public Builder description(String description) {
            this.description = description;
            return this;
        }
        
        public Builder capability(Capability capability) {
            this.capabilities.add(capability);
            return this;
        }
        
        public Builder capabilities(Set<Capability> capabilities) {
            this.capabilities.addAll(capabilities);
            return this;
        }
        
        public Builder input(InputDescriptor input) {
            this.inputs.add(input);
            return this;
        }
        
        public Builder output(OutputDescriptor output) {
            this.outputs.add(output);
            return this;
        }
        
        public Builder property(PropertyDescriptor property) {
            this.properties.put(property.getName(), property);
            return this;
        }
        
        public Builder resourceProfile(ResourceProfile resourceProfile) {
            this.resourceProfile = resourceProfile;
            return this;
        }
        
        public Builder securityProfile(SecurityProfile securityProfile) {
            this.securityProfile = securityProfile;
            return this;
        }
        
        public AgentDescriptor build() {
            return new AgentDescriptor(this);
        }
    }
}

/**
 * Agent configuration
 */
@Immutable
public final class AgentConfig {
    private final String agentId;
    private final Map<String, Object> properties;
    private final PersonaConfig persona;
    private final ResourceLimits resourceLimits;
    private final SecurityConfig securityConfig;
    private final Map<String, String> metadata;
    
    private AgentConfig(Builder builder) {
        this.agentId = requireNonNull(builder.agentId);
        this.properties = Map.copyOf(builder.properties);
        this.persona = builder.persona;
        this.resourceLimits = builder.resourceLimits;
        this.securityConfig = builder.securityConfig;
        this.metadata = Map.copyOf(builder.metadata);
    }
    
    public <T> Optional<T> getProperty(String key, Class<T> type) {
        return Optional.ofNullable(properties.get(key))
                .map(type::cast);
    }
    
    public <T> T getRequiredProperty(String key, Class<T> type) {
        return getProperty(key, type)
                .orElseThrow(() -> new IllegalStateException("Required property missing: " + key));
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String agentId;
        private Map<String, Object> properties = new HashMap<>();
        private PersonaConfig persona;
        private ResourceLimits resourceLimits = ResourceLimits.defaults();
        private SecurityConfig securityConfig = SecurityConfig.defaults();
        private Map<String, String> metadata = new HashMap<>();
        
        public Builder agentId(String agentId) {
            this.agentId = agentId;
            return this;
        }
        
        public Builder property(String key, Object value) {
            this.properties.put(key, value);
            return this;
        }
        
        public Builder properties(Map<String, Object> properties) {
            this.properties.putAll(properties);
            return this;
        }
        
        public Builder persona(PersonaConfig persona) {
            this.persona = persona;
            return this;
        }
        
        public Builder resourceLimits(ResourceLimits resourceLimits) {
            this.resourceLimits = resourceLimits;
            return this;
        }
        
        public Builder securityConfig(SecurityConfig securityConfig) {
            this.securityConfig = securityConfig;
            return this;
        }
        
        public Builder metadata(String key, String value) {
            this.metadata.put(key, value);
            return this;
        }
        
        public AgentConfig build() {
            return new AgentConfig(this);
        }
    }
}
```

### 7.2 Specialized Agent Implementations

```java
package io.wayang.agent.sdk.impl;

/**
 * Planner agent - decomposes goals into execution plans
 */
public class PlannerAgent extends AutonomousAgent {
    private final PlanningEngine planningEngine;
    private final TaskDecomposer taskDecomposer;
    private final NodeMapper nodeMapper;
    private final PlanValidator planValidator;
    
    public PlannerAgent(String id, 
                       PlanningEngine planningEngine,
                       TaskDecomposer taskDecomposer,
                       NodeMapper nodeMapper,
                       PlanValidator planValidator,
                       ReasoningEngine reasoningEngine,
                       MemoryService memoryService) {
        super(id, Set.of(Capability.PLANNING, Capability.REASONING), 
              reasoningEngine, memoryService);
        this.planningEngine = planningEngine;
        this.taskDecomposer = taskDecomposer;
        this.nodeMapper = nodeMapper;
        this.planValidator = planValidator;
    }
    
    @Override
    protected void doInitialize(AgentConfig config) throws AgentInitializationException {
        // Initialize planner-specific components
    }
    
    @Override
    protected AgentResult doExecute(AgentContext context) throws AgentExecutionException {
        // Extract goal from context
        Goal goal = extractGoal(context);
        
        // Generate execution plan
        ExecutionPlan plan = plan(goal, context);
        
        // Validate plan
        ValidationResult validation = planValidator.validate(plan);
        if (!validation.isValid()) {
            return AgentResult.failure(new AgentExecutionException(
                    "Plan validation failed: " + validation.getErrors()));
        }
        
        // Store plan in memory
        memoryService.storeEpisode(Episode.fromPlan(plan));
        
        return AgentResult.success()
                .output("plan", plan)
                .output("estimatedCost", plan.getEstimatedCost())
                .output("estimatedDuration", plan.getEstimatedDuration())
                .build();
    }
    
    @Override
    protected ExecutionPlan plan(Goal goal, AgentContext context) {
        // Decompose goal into tasks
        List<Task> tasks = taskDecomposer.decompose(goal);
        
        // Map tasks to nodes
        List<PlanNode> nodes = nodeMapper.mapToNodes(tasks);
        
        // Build execution graph
        ExecutionGraph graph = planningEngine.buildGraph(nodes);
        
        // Create execution plan
        return ExecutionPlan.builder()
                .goal(goal)
                .graph(graph)
                .nodes(nodes)
                .build();
    }
    
    @Override
    protected void reflect(AgentResult result, AgentContext context) {
        // Analyze execution results
        // Update planning strategies based on outcomes
    }
    
    private Goal extractGoal(AgentContext context) {
        String goalDescription = context.getRequiredInput("goal", String.class);
        Map<String, Object> constraints = context.getInput("constraints", Map.class)
                .orElse(Map.of());
        
        return Goal.builder()
                .description(goalDescription)
                .constraints(constraints)
                .build();
    }
}

/**
 * Evaluator agent - assesses quality and correctness
 */
public class EvaluatorAgent extends SpecialistAgent {
    private final EvaluationEngine evaluationEngine;
    private final List<EvaluationCriterion> criteria;
    private final ModelRouter modelRouter;
    
    public EvaluatorAgent(String id,
                         EvaluationEngine evaluationEngine,
                         List<EvaluationCriterion> criteria,
                         ModelRouter modelRouter) {
        super(id, "evaluation", Set.of(Capability.EVALUATION, Capability.LLM_ACCESS));
        this.evaluationEngine = evaluationEngine;
        this.criteria = criteria;
        this.modelRouter = modelRouter;
    }
    
    @Override
    protected void doInitialize(AgentConfig config) throws AgentInitializationException {
        // Load evaluation criteria from config
    }
    
    @Override
    protected AgentResult doExecute(AgentContext context) throws AgentExecutionException {
        Object output = context.getRequiredInput("output", Object.class);
        Optional<Object> expectedOutput = context.getInput("expectedOutput", Object.class);
        
        // Evaluate against criteria
        EvaluationResult evaluation = evaluationEngine.evaluate(
                output, 
                expectedOutput.orElse(null), 
                criteria
        );
        
        // Determine action based on evaluation
        EvaluationAction action = determineAction(evaluation);
        
        return AgentResult.success()
                .output("score", evaluation.getScore())
                .output("passed", evaluation.isPassed())
                .output("feedback", evaluation.getFeedback())
                .output("action", action)
                .output("details", evaluation.getDetails())
                .build();
    }
    
    private EvaluationAction determineAction(EvaluationResult evaluation) {
        if (evaluation.getScore() >= 0.8) {
            return EvaluationAction.ACCEPT;
        } else if (evaluation.getScore() >= 0.5) {
            return EvaluationAction.REVISE;
        } else {
            return EvaluationAction.REJECT;
        }
    }
}

/**
 * Critic agent - provides improvement suggestions
 */
public class CriticAgent extends SpecialistAgent {
    private final CriticEngine criticEngine;
    private final ReasoningAnalyzer reasoningAnalyzer;
    private final ModelRouter modelRouter;
    
    public CriticAgent(String id,
                      CriticEngine criticEngine,
                      ReasoningAnalyzer reasoningAnalyzer,
                      ModelRouter modelRouter) {
        super(id, "critique", Set.of(Capability.CRITIQUE, Capability.LLM_ACCESS));
        this.criticEngine = criticEngine;
        this.reasoningAnalyzer = reasoningAnalyzer;
        this.modelRouter = modelRouter;
    }
    
    @Override
    protected void doInitialize(AgentConfig config) throws AgentInitializationException {
        // Initialize critic-specific components
    }
    
    @Override
    protected AgentResult doExecute(AgentContext context) throws AgentExecutionException {
        Object output = context.getRequiredInput("output", Object.class);
        Optional<Object> reasoning = context.getInput("reasoning", Object.class);
        Object contextData = context.getInput("context", Object.class).orElse(null);
        
        // Critique the output
        CritiqueResult critique = criticEngine.critique(output, contextData);
        
        // Analyze reasoning if provided
        Optional<ReasoningAnalysis> reasoningAnalysis = reasoning.map(reasoningAnalyzer::analyze);
        
        // Generate improvement suggestions
        List<Suggestion> suggestions = generateSuggestions(critique, reasoningAnalysis);
        
        return AgentResult.success()
                .output("score", critique.getScore())
                .output("issues", critique.getIssues())
                .output("suggestions", suggestions)
                .output("action", critique.getRecommendedAction())
                .output("confidence", critique.getConfidence())
                .build();
    }
    
    private List<Suggestion> generateSuggestions(CritiqueResult critique,
                                                 Optional<ReasoningAnalysis> reasoningAnalysis) {
        List<Suggestion> suggestions = new ArrayList<>(critique.getSuggestions());
        
        reasoningAnalysis.ifPresent(analysis -> {
            if (analysis.hasLogicalGaps()) {
                suggestions.add(Suggestion.builder()
                        .type(SuggestionType.REASONING_IMPROVEMENT)
                        .description("Address logical gaps in reasoning")
                        .priority(Priority.HIGH)
                        .build());
            }
        });
        
        return suggestions;
    }
}

/**
 * Guardrails agent - enforces safety and compliance
 */
public class GuardrailsAgent extends SpecialistAgent {
    private final GuardrailsEngine guardrailsEngine;
    private final PolicyEngine policyEngine;
    private final PIIDetector piiDetector;
    private final ToxicityDetector toxicityDetector;
    
    public GuardrailsAgent(String id,
                          GuardrailsEngine guardrailsEngine,
                          PolicyEngine policyEngine,
                          PIIDetector piiDetector,
                          ToxicityDetector toxicityDetector) {
        super(id, "guardrails", Set.of(Capability.SAFETY, Capability.COMPLIANCE));
        this.guardrailsEngine = guardrailsEngine;
        this.policyEngine = policyEngine;
        this.piiDetector = piiDetector;
        this.toxicityDetector = toxicityDetector;
    }
    
    @Override
    protected void doInitialize(AgentConfig config) throws AgentInitializationException {
        // Load policies and rules
    }
    
    @Override
    protected AgentResult doExecute(AgentContext context) throws AgentExecutionException {
        Object content = context.getRequiredInput("content", Object.class);
        CheckType checkType = context.getInput("checkType", CheckType.class)
                .orElse(CheckType.FULL);
        
        // Run guardrails checks
        GuardrailResult result = guardrailsEngine.check(content, checkType);
        
        // Additional specific checks
        if (result.isAllowed()) {
            // PII detection
            PIIDetectionResult piiResult = piiDetector.detect(content);
            if (piiResult.hasPII() && context.getSecurityContext().requiresPIIProtection()) {
                result = GuardrailResult.blocked("PII detected: " + piiResult.getTypes());
            }
            
            // Toxicity check
            if (result.isAllowed()) {
                ToxicityResult toxicityResult = toxicityDetector.detect(content);
                if (toxicityResult.isToxic()) {
                    result = GuardrailResult.blocked("Toxic content detected");
                }
            }
        }
        
        return AgentResult.success()
                .output("allowed", result.isAllowed())
                .output("action", result.getAction())
                .output("reason", result.getReason())
                .output("redactedContent", result.getRedactedContent())
                .output("violations", result.getViolations())
                .build();
    }
}

/**
 * RAG agent - performs retrieval augmented generation
 */
public class RAGAgent extends SpecialistAgent {
    private final RAGService ragService;
    private final EmbeddingService embeddingService;
    private final ContextAssembler contextAssembler;
    
    public RAGAgent(String id,
                   RAGService ragService,
                   EmbeddingService embeddingService,
                   ContextAssembler contextAssembler) {
        super(id, "rag", Set.of(Capability.RETRIEVAL, Capability.CONTEXT_BUILDING));
        this.ragService = ragService;
        this.embeddingService = embeddingService;
        this.contextAssembler = contextAssembler;
    }
    
    @Override
    protected void doInitialize(AgentConfig config) throws AgentInitializationException {
        // Initialize RAG-specific components
    }
    
    @Override
    protected AgentResult doExecute(AgentContext context) throws AgentExecutionException {
        String query = context.getRequiredInput("query", String.class);
        RAGConfig ragConfig = context.getInput("ragConfig", RAGConfig.class)
                .orElse(RAGConfig.defaults());
        
        // Retrieve context
        RAGContext ragContext = ragService.retrieveContext(query, ragConfig);
        
        return AgentResult.success()
                .output("context", ragContext.getContextText())
                .output("citations", ragContext.getCitations())
                .output("documentCount", ragContext.getDocumentCount())
                .output("tokenCount", ragContext.getTokenCount())
                .build();
    }
}

/**
 * Tool executor agent - executes external tools
 */
public class ToolExecutorAgent extends SpecialistAgent {
    private final ToolGateway toolGateway;
    private final ToolReasoner toolReasoner;
    private final ToolRegistry toolRegistry;
    
    public ToolExecutorAgent(String id,
                            ToolGateway toolGateway,
                            ToolReasoner toolReasoner,
                            ToolRegistry toolRegistry) {
        super(id, "tool-executor", Set.of(Capability.TOOL_EXECUTION));
        this.toolGateway = toolGateway;
        this.toolReasoner = toolReasoner;
        this.toolRegistry = toolRegistry;
    }
    
    @Override
    protected void doInitialize(AgentConfig config) throws AgentInitializationException {
        // Initialize tool executor
    }
    
    @Override
    protected AgentResult doExecute(AgentContext context) throws AgentExecutionException {
        // Get tool request
        Optional<ToolRequest> directRequest = context.getInput("toolRequest", ToolRequest.class);
        
        ToolRequest request;
        if (directRequest.isPresent()) {
            request = directRequest.get();
        } else {
            // Synthesize tool request from description
            String toolDescription = context.getRequiredInput("toolDescription", String.class);
            String toolId = context.getRequiredInput("toolId", String.class);
            
            ToolDescriptor toolDescriptor = toolRegistry.getDescriptor(toolId)
                    .orElseThrow(() -> new AgentExecutionException("Tool not found: " + toolId));
            
            request = toolReasoner.synthesize(toolDescription, toolDescriptor);
        }
        
        // Execute tool
        ToolResponse response = toolGateway.execute(request);
        
        return AgentResult.success()
                .output("result", response.getResult())
                .output("status", response.getStatus())
                .output("metadata", response.getMetadata())
                .build();
    }
}
```

### 7.3 Agent Lifecycle Management

```java
package io.wayang.agent.sdk.lifecycle;

/**
 * Agent lifecycle manager - manages agent instances
 */
@ApplicationScoped
public class AgentLifecycleManager {
    private final AgentRegistry registry;
    private final Map<String, ManagedAgent> activeAgents = new ConcurrentHashMap<>();
    private final ExecutorService executorService;
    private final AgentHealthMonitor healthMonitor;
    
    @Inject
    public AgentLifecycleManager(AgentRegistry registry,
                                AgentHealthMonitor healthMonitor) {
        this.registry = registry;
        this.healthMonitor = healthMonitor;
        this.executorService = Executors.newCachedThreadPool();
    }
    
    /**
     * Create and start agent
     */
    public String createAgent(String agentId, AgentConfig config) {
        Agent agent = registry.createAgent(agentId, config);
        
        String instanceId = UUID.randomUUID().toString();
        ManagedAgent managedAgent = new ManagedAgent(instanceId, agent, config);
        
        // Initialize agent
        agent.initialize(config);
        
        // Register and start monitoring
        activeAgents.put(instanceId, managedAgent);
        healthMonitor.startMonitoring(managedAgent);
        
        return instanceId;
    }
    
    /**
     * Execute agent
     */
    public CompletableFuture<AgentResult> executeAgent(String instanceId, AgentContext context) {
        ManagedAgent managedAgent = activeAgents.get(instanceId);
        if (managedAgent == null) {
            return CompletableFuture.failedFuture(
                    new AgentException("Agent not found: " + instanceId));
        }
        
        return CompletableFuture.supplyAsync(() -> {
            try {
                managedAgent.recordExecutionStart();
                AgentResult result = managedAgent.getAgent().execute(context);
                managedAgent.recordExecutionEnd(result);
                return result;
            } catch (Exception e) {
                managedAgent.recordFailure(e);
                throw new CompletionException(e);
            }
        }, executorService);
    }
    
    /**
     * Destroy agent
     */
    public void destroyAgent(String instanceId) {
        ManagedAgent managedAgent = activeAgents.remove(instanceId);
        if (managedAgent != null) {
            healthMonitor.stopMonitoring(managedAgent);
            managedAgent.getAgent().destroy();
        }
    }
    
    /**
     * Get agent health status
     */
    public HealthStatus getHealthStatus(String instanceId) {
        ManagedAgent managedAgent = activeAgents.get(instanceId);
        return managedAgent != null ? managedAgent.getHealthStatus() : HealthStatus.UNKNOWN;
    }
    
    /**
     * List active agents
     */
    public List<AgentInfo> listActiveAgents() {
        return activeAgents.values().stream()
                .map(ManagedAgent::getInfo)
                .collect(Collectors.toList());
    }
}

/**
 * Managed agent - wrapper for agent lifecycle
 */
class ManagedAgent {
    private final String instanceId;
    private final Agent agent;
    private final AgentConfig config;
    private final AtomicReference<HealthStatus> healthStatus = new AtomicReference<>(HealthStatus.HEALTHY);
    private final AtomicLong executionCount = new AtomicLong(0);
    private final AtomicLong failureCount = new AtomicLong(0);
    private volatile Instant lastExecutionTime;
    private volatile Duration lastExecutionDuration;
    
    public ManagedAgent(String instanceId, Agent agent, AgentConfig config) {
        this.instanceId = instanceId;
        this.agent = agent;
        this.config = config;
    }
    
    public void recordExecutionStart() {
        executionCount.incrementAndGet();
    }
    
    public void recordExecutionEnd(AgentResult result) {
        lastExecutionTime = Instant.now();
        // Calculate duration if available
    }
    
    public void recordFailure(Exception e) {
        failureCount.incrementAndGet();
        if (failureCount.get() > 5) {
            healthStatus.set(HealthStatus.UNHEALTHY);
        }
    }
    
    public AgentInfo getInfo() {
        return AgentInfo.builder()
                .instanceId(instanceId)
                .agentId(agent.getId())
                .type(agent.getType())
                .healthStatus(healthStatus.get())
                .executionCount(executionCount.get())
                .failureCount(failureCount.get())
                .lastExecutionTime(lastExecutionTime)
                .build();
    }
    
    // Getters...
    public String getInstanceId() { return instanceId; }
    public Agent getAgent() { return agent; }
    public AgentConfig getConfig() { return config; }
    public HealthStatus getHealthStatus() { return healthStatus.get(); }
}

/**
 * Agent health monitor
 */
@ApplicationScoped
public class AgentHealthMonitor {
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(2);
    private final Map<String, ScheduledFuture<?>> monitoringTasks = new ConcurrentHashMap<>();
    
    public void startMonitoring(ManagedAgent agent) {
        ScheduledFuture<?> task = scheduler.scheduleAtFixedRate(
                () -> checkHealth(agent),
                30,
                30,
                TimeUnit.SECONDS
        );
        
        monitoringTasks.put(agent.getInstanceId(), task);
    }
    
    public void stopMonitoring(ManagedAgent agent) {
        ScheduledFuture<?> task = monitoringTasks.remove(agent.getInstanceId());
        if (task != null) {
            task.cancel(false);
        }
    }
    
    private void checkHealth(ManagedAgent agent) {
        try {
            HealthStatus status = agent.getAgent().checkHealth();
            // Update health status and trigger alerts if needed
        } catch (Exception e) {
            // Handle health check failure
        }
    }
}
```

### 7.4 Agent Communication (A2A)

```java
package io.wayang.agent.sdk.a2a;

/**
 * Agent-to-Agent message
 */
@Immutable
public final class A2AMessage {
    private final String messageId;
    private final String fromAgentId;
    private final String toAgentId;
    private final String correlationId;
    private final MessageType type;
    private final MessagePurpose purpose;
    private final Map<String, Object> payload;
    private final Map<String, Object> contextHints;
    private final SecurityToken securityToken;
    private final Instant timestamp;
    
    private A2AMessage(Builder builder) {
        this.messageId = requireNonNull(builder.messageId);
        this.fromAgentId = requireNonNull(builder.fromAgentId);
        this.toAgentId = requireNonNull(builder.toAgentId);
        this.correlationId = builder.correlationId;
        this.type = requireNonNull(builder.type);
        this.purpose = requireNonNull(builder.purpose);
        this.payload = Map.copyOf(builder.payload);
        this.contextHints = Map.copyOf(builder.contextHints);
        this.securityToken = builder.securityToken;
        this.timestamp = builder.timestamp;
    }
    
    // Getters...
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String messageId = UUID.randomUUID().toString();
        private String fromAgentId;
        private String toAgentId;
        private String correlationId;
        private MessageType type;
        private MessagePurpose purpose;
        private Map<String, Object> payload = new HashMap<>();
        private Map<String, Object> contextHints = new HashMap<>();
        private SecurityToken securityToken;
        private Instant timestamp = Instant.now();
        
        public Builder messageId(String messageId) {
            this.messageId = messageId;
            return this;
        }
        
        public Builder from(String fromAgentId) {
            this.fromAgentId = fromAgentId;
            return this;
        }
        
        public Builder to(String toAgentId) {
            this.toAgentId = toAgentId;
            return this;
        }
        
        public Builder correlationId(String correlationId) {
            this.correlationId = correlationId;
            return this;
        }
        
        public Builder type(MessageType type) {
            this.type = type;
            return this;
        }
        
        public Builder purpose(MessagePurpose purpose) {
            this.purpose = purpose;
            return this;
        }
        
        public Builder payload(String key, Object value) {
            this.payload.put(key, value);
            return this;
        }
        
        public Builder payload(Map<String, Object> payload) {
            this.payload.putAll(payload);
            return this;
        }

        public Builder contextHint(String key, Object value) {
            this.contextHints.put(key, value);
            return this;
        }
        
        public Builder securityToken(SecurityToken securityToken) {
            this.securityToken = securityToken;
            return this;
        }
        
        public A2AMessage build() {
            return new A2AMessage(this);
        }
    }
}

/**
 * A2A Router - routes messages between agents
 */
@ApplicationScoped
public class A2ARouter {
    private final AgentRegistry agentRegistry;
    private final A2AMessageBus messageBus;
    private final A2APolicyEngine policyEngine;
    private final ContextHandoverManager contextManager;
    private final A2AMetrics metrics;
    
    @Inject
    public A2ARouter(AgentRegistry agentRegistry,
                    A2AMessageBus messageBus,
                    A2APolicyEngine policyEngine,
                    ContextHandoverManager contextManager) {
        this.agentRegistry = agentRegistry;
        this.messageBus = messageBus;
        this.policyEngine = policyEngine;
        this.contextManager = contextManager;
        this.metrics = new A2AMetrics();
    }
    
    /**
     * Send message from one agent to another
     */
    public CompletableFuture<A2AResponse> send(A2AMessage message) {
        metrics.recordMessageSent();
        
        // Validate message
        ValidationResult validation = validateMessage(message);
        if (!validation.isValid()) {
            return CompletableFuture.failedFuture(
                    new A2AException("Invalid message: " + validation.getErrors()));
        }
        
        // Check policy
        PolicyResult policyResult = policyEngine.evaluate(message);
        if (!policyResult.isAllowed()) {
            return CompletableFuture.failedFuture(
                    new A2AException("Policy violation: " + policyResult.getReason()));
        }
        
        // Handle context handover
        A2AMessage enrichedMessage = contextManager.prepareHandover(message);
        
        // Route message
        return messageBus.publish(enrichedMessage)
                .thenApply(response -> {
                    metrics.recordMessageDelivered();
                    return response;
                })
                .exceptionally(ex -> {
                    metrics.recordMessageFailed();
                    throw new CompletionException(ex);
                });
    }
    
    /**
     * Subscribe to messages for an agent
     */
    public void subscribe(String agentId, A2AMessageHandler handler) {
        messageBus.subscribe(agentId, handler);
    }
    
    private ValidationResult validateMessage(A2AMessage message) {
        ValidationResult.Builder builder = ValidationResult.builder();
        
        // Validate sender exists
        if (!agentRegistry.getDescriptor(message.getFromAgentId()).isPresent()) {
            builder.error("Sender agent not found: " + message.getFromAgentId());
        }
        
        // Validate receiver exists
        if (!agentRegistry.getDescriptor(message.getToAgentId()).isPresent()) {
            builder.error("Receiver agent not found: " + message.getToAgentId());
        }
        
        return builder.build();
    }
}

/**
 * A2A Message Bus - async message delivery
 */
@ApplicationScoped
public class A2AMessageBus {
    private final Map<String, List<A2AMessageHandler>> subscribers = new ConcurrentHashMap<>();
    private final ExecutorService executorService = Executors.newCachedThreadPool();
    
    /**
     * Publish message to agent
     */
    public CompletableFuture<A2AResponse> publish(A2AMessage message) {
        List<A2AMessageHandler> handlers = subscribers.get(message.getToAgentId());
        
        if (handlers == null || handlers.isEmpty()) {
            return CompletableFuture.failedFuture(
                    new A2AException("No handlers for agent: " + message.getToAgentId()));
        }
        
        // Deliver to first handler (load balancing can be added)
        A2AMessageHandler handler = handlers.get(0);
        
        return CompletableFuture.supplyAsync(() -> 
                handler.handle(message), executorService);
    }
    
    /**
     * Subscribe handler for agent messages
     */
    public void subscribe(String agentId, A2AMessageHandler handler) {
        subscribers.computeIfAbsent(agentId, k -> new CopyOnWriteArrayList<>())
                  .add(handler);
    }
    
    /**
     * Unsubscribe handler
     */
    public void unsubscribe(String agentId, A2AMessageHandler handler) {
        List<A2AMessageHandler> handlers = subscribers.get(agentId);
        if (handlers != null) {
            handlers.remove(handler);
        }
    }
}

/**
 * Message handler interface
 */
@FunctionalInterface
public interface A2AMessageHandler {
    A2AResponse handle(A2AMessage message);
}

/**
 * Context handover manager - manages context transfer between agents
 */
@ApplicationScoped
public class ContextHandoverManager {
    private final SecurityService securityService;
    
    @Inject
    public ContextHandoverManager(SecurityService securityService) {
        this.securityService = securityService;
    }
    
    /**
     * Prepare message for context handover
     */
    public A2AMessage prepareHandover(A2AMessage message) {
        // Redact sensitive fields based on receiver capabilities
        Map<String, Object> sanitizedPayload = sanitizePayload(
                message.getPayload(),
                message.getToAgentId()
        );
        
        // Add ephemeral credentials if needed
        SecurityToken token = securityService.issueEphemeralToken(
                message.getFromAgentId(),
                message.getToAgentId()
        );
        
        return A2AMessage.builder()
                .messageId(message.getMessageId())
                .from(message.getFromAgentId())
                .to(message.getToAgentId())
                .correlationId(message.getCorrelationId())
                .type(message.getType())
                .purpose(message.getPurpose())
                .payload(sanitizedPayload)
                .contextHints(message.getContextHints())
                .securityToken(token)
                .build();
    }
    
    private Map<String, Object> sanitizePayload(Map<String, Object> payload, String receiverAgentId) {
        // Implement redaction logic based on receiver permissions
        return new HashMap<>(payload);
    }
}
```

### 7.5 Agent SDK Utilities

```java
package io.wayang.agent.sdk.util;

/**
 * Agent builder - fluent API for creating agents
 */
public class AgentBuilder {
    private final AgentRegistry registry;
    
    public AgentBuilder(AgentRegistry registry) {
        this.registry = registry;
    }
    
    public static AgentBuilder create() {
        return new AgentBuilder(new AgentRegistry());
    }
    
    public PlannerAgentBuilder planner(String id) {
        return new PlannerAgentBuilder(id, registry);
    }
    
    public EvaluatorAgentBuilder evaluator(String id) {
        return new EvaluatorAgentBuilder(id, registry);
    }
    
    public CriticAgentBuilder critic(String id) {
        return new CriticAgentBuilder(id, registry);
    }
    
    public GuardrailsAgentBuilder guardrails(String id) {
        return new GuardrailsAgentBuilder(id, registry);
    }
    
    public RAGAgentBuilder rag(String id) {
        return new RAGAgentBuilder(id, registry);
    }
    
    public ToolExecutorAgentBuilder toolExecutor(String id) {
        return new ToolExecutorAgentBuilder(id, registry);
    }
    
    public CustomAgentBuilder custom(String id, AgentType type) {
        return new CustomAgentBuilder(id, type, registry);
    }
}

/**
 * Planner agent builder
 */
public class PlannerAgentBuilder {
    private final String id;
    private final AgentRegistry registry;
    private PlanningEngine planningEngine;
    private TaskDecomposer taskDecomposer;
    private NodeMapper nodeMapper;
    private PlanValidator planValidator;
    private ReasoningEngine reasoningEngine;
    private MemoryService memoryService;
    
    public PlannerAgentBuilder(String id, AgentRegistry registry) {
        this.id = id;
        this.registry = registry;
    }
    
    public PlannerAgentBuilder planningEngine(PlanningEngine planningEngine) {
        this.planningEngine = planningEngine;
        return this;
    }
    
    public PlannerAgentBuilder taskDecomposer(TaskDecomposer taskDecomposer) {
        this.taskDecomposer = taskDecomposer;
        return this;
    }
    
    public PlannerAgentBuilder nodeMapper(NodeMapper nodeMapper) {
        this.nodeMapper = nodeMapper;
        return this;
    }
    
    public PlannerAgentBuilder planValidator(PlanValidator planValidator) {
        this.planValidator = planValidator;
        return this;
    }
    
    public PlannerAgentBuilder reasoningEngine(ReasoningEngine reasoningEngine) {
        this.reasoningEngine = reasoningEngine;
        return this;
    }
    
    public PlannerAgentBuilder memoryService(MemoryService memoryService) {
        this.memoryService = memoryService;
        return this;
    }
    
    public PlannerAgent build() {
        requireNonNull(planningEngine, "Planning engine is required");
        requireNonNull(taskDecomposer, "Task decomposer is required");
        requireNonNull(nodeMapper, "Node mapper is required");
        requireNonNull(planValidator, "Plan validator is required");
        requireNonNull(reasoningEngine, "Reasoning engine is required");
        requireNonNull(memoryService, "Memory service is required");
        
        PlannerAgent agent = new PlannerAgent(
                id,
                planningEngine,
                taskDecomposer,
                nodeMapper,
                planValidator,
                reasoningEngine,
                memoryService
        );
        
        // Register descriptor
        AgentDescriptor descriptor = AgentDescriptor.builder()
                .id(id)
                .name("Planner Agent")
                .type(AgentType.AUTONOMOUS)
                .capability(Capability.PLANNING)
                .capability(Capability.REASONING)
                .build();
        
        registry.register(descriptor);
        
        return agent;
    }
}

/**
 * Agent metrics collector
 */
@ApplicationScoped
public class AgentMetrics {
    private final String agentId;
    private final Counter executionCounter;
    private final Counter failureCounter;
    private final Histogram executionDuration;
    private final Gauge healthGauge;
    
    public AgentMetrics(String agentId) {
        this.agentId = agentId;
        this.executionCounter = Metrics.counter("agent.executions", "agent", agentId);
        this.failureCounter = Metrics.counter("agent.failures", "agent", agentId);
        this.executionDuration = Metrics.histogram("agent.execution.duration", "agent", agentId);
        this.healthGauge = Metrics.gauge("agent.health", "agent", agentId);
    }
    
    public void recordExecution() {
        executionCounter.increment();
    }
    
    public void recordFailure() {
        failureCounter.increment();
    }
    
    public void recordDuration(Duration duration) {
        executionDuration.record(duration.toMillis());
    }
    
    public void recordHealth(HealthStatus status) {
        healthGauge.set(status.ordinal());
    }
}
```

This completes the comprehensive Agent SDK section covering:

1. **Core Agent Abstractions** - Base interfaces and abstract classes
2. **Specialized Agent Implementations** - Planner, Evaluator, Critic, Guardrails, RAG, Tool Executor
3. **Lifecycle Management** - Creating, executing, monitoring, and destroying agents
4. **A2A Communication** - Agent-to-agent messaging and coordination
5. **Utilities** - Builders, metrics, and helper classes

The SDK provides a complete foundation for building and deploying AI agents in the Wayang platform. Would you like me to continue with another section?





# Wayang AI Agent SDK - RAG System (Real Implementation with Improvements)

## Complete RAG Module Implementation

### Project Structure

```
wayang-rag/
 pom.xml
 src/main/java/io/wayang/rag/
    api/
       RAGService.java
       IngestionService.java
       RetrievalService.java
    ingestion/
       pipeline/
          IngestionPipeline.java
          PipelineStage.java
          PipelineExecutor.java
       extractor/
          DocumentExtractor.java
          PDFExtractor.java
          TextExtractor.java
          HTMLExtractor.java
       chunker/
          DocumentChunker.java
          TokenAwareChunker.java
          SemanticChunker.java
       cleaner/
          TextCleaner.java
          PIIRedactor.java
       enricher/
           MetadataEnricher.java
           EntityExtractor.java
    retrieval/
       engine/
          RetrievalEngine.java
          HybridRetriever.java
          MultiStageRetriever.java
       reranker/
          ReRanker.java
          CrossEncoderReRanker.java
          LLMReRanker.java
       scorer/
           RelevanceScorer.java
           DiversityScorer.java
    vector/
       store/
          VectorStore.java
          PgVectorStore.java
          MilvusVectorStore.java
          WeaviateVectorStore.java
       embedding/
           EmbeddingService.java
           LocalEmbeddingService.java
           RemoteEmbeddingService.java
    context/
       ContextAssembler.java
       ContextOptimizer.java
       CitationBuilder.java
    config/
       RAGConfiguration.java
       VectorStoreConfiguration.java
    model/
        Document.java
        DocumentChunk.java
        SearchResult.java
        RAGContext.java
 src/main/resources/
     application.properties
```

### 1. Core Configuration

```java
package io.wayang.rag.config;

import io.quarkus.runtime.annotations.ConfigItem;
import io.quarkus.runtime.annotations.ConfigPhase;
import io.quarkus.runtime.annotations.ConfigRoot;

/**
 * RAG Configuration
 */
@ConfigRoot(name = "wayang.rag", phase = ConfigPhase.RUN_TIME)
public class RAGConfiguration {
    
    /**
     * Vector store configuration
     */
    @ConfigItem
    public VectorStoreConfig vectorStore;
    
    /**
     * Ingestion configuration
     */
    @ConfigItem
    public IngestionConfig ingestion;
    
    /**
     * Retrieval configuration
     */
    @ConfigItem
    public RetrievalConfig retrieval;
    
    /**
     * Embedding configuration
     */
    @ConfigItem
    public EmbeddingConfig embedding;
    
    public static class VectorStoreConfig {
        /**
         * Vector store provider (pgvector, milvus, weaviate)
         */
        @ConfigItem(defaultValue = "pgvector")
        public String provider;
        
        /**
         * Database connection URL
         */
        @ConfigItem
        public String url;
        
        /**
         * Username
         */
        @ConfigItem
        public String username;
        
        /**
         * Password
         */
        @ConfigItem
        public String password;
        
        /**
         * Vector dimension
         */
        @ConfigItem(defaultValue = "1536")
        public int dimension;
        
        /**
         * Index type (ivfflat, hnsw)
         */
        @ConfigItem(defaultValue = "hnsw")
        public String indexType;
        
        /**
         * Distance metric (cosine, l2, inner_product)
         */
        @ConfigItem(defaultValue = "cosine")
        public String distanceMetric;
        
        /**
         * Enable connection pooling
         */
        @ConfigItem(defaultValue = "true")
        public boolean pooling;
        
        /**
         * Pool size
         */
        @ConfigItem(defaultValue = "10")
        public int poolSize;
    }
    
    public static class IngestionConfig {
        /**
         * Default chunk size in tokens
         */
        @ConfigItem(defaultValue = "512")
        public int chunkSize;
        
        /**
         * Chunk overlap in tokens
         */
        @ConfigItem(defaultValue = "50")
        public int chunkOverlap;
        
        /**
         * Enable PII detection
         */
        @ConfigItem(defaultValue = "true")
        public boolean detectPII;
        
        /**
         * Enable PII redaction
         */
        @ConfigItem(defaultValue = "false")
        public boolean redactPII;
        
        /**
         * Batch size for embedding
         */
        @ConfigItem(defaultValue = "32")
        public int embeddingBatchSize;
        
        /**
         * Enable metadata extraction
         */
        @ConfigItem(defaultValue = "true")
        public boolean extractMetadata;
        
        /**
         * Enable entity extraction
         */
        @ConfigItem(defaultValue = "false")
        public boolean extractEntities;
    }
    
    public static class RetrievalConfig {
        /**
         * Default retrieval strategy
         */
        @ConfigItem(defaultValue = "HYBRID")
        public RetrievalStrategy strategy;
        
        /**
         * Default top-k results
         */
        @ConfigItem(defaultValue = "5")
        public int topK;
        
        /**
         * Hybrid search weight (0.0 = semantic only, 1.0 = lexical only)
         */
        @ConfigItem(defaultValue = "0.5")
        public double hybridWeight;
        
        /**
         * Enable reranking
         */
        @ConfigItem(defaultValue = "true")
        public boolean enableReranking;
        
        /**
         * Reranker type (cross-encoder, llm)
         */
        @ConfigItem(defaultValue = "cross-encoder")
        public String rerankerType;
        
        /**
         * Enable query expansion
         */
        @ConfigItem(defaultValue = "false")
        public boolean enableQueryExpansion;
        
        /**
         * Maximum context tokens
         */
        @ConfigItem(defaultValue = "4096")
        public int maxContextTokens;
    }
    
    public static class EmbeddingConfig {
        /**
         * Embedding model provider
         */
        @ConfigItem(defaultValue = "local")
        public String provider;
        
        /**
         * Model name
         */
        @ConfigItem(defaultValue = "all-MiniLM-L6-v2")
        public String modelName;
        
        /**
         * Local model path
         */
        @ConfigItem
        public String modelPath;
        
        /**
         * API endpoint for remote embedding
         */
        @ConfigItem
        public String apiEndpoint;
        
        /**
         * API key
         */
        @ConfigItem
        public String apiKey;
        
        /**
         * Batch size for embedding
         */
        @ConfigItem(defaultValue = "32")
        public int batchSize;
        
        /**
         * Enable caching
         */
        @ConfigItem(defaultValue = "true")
        public boolean enableCaching;
    }
}

/**
 * Retrieval strategy enum
 */
public enum RetrievalStrategy {
    SEMANTIC,    // Pure vector similarity
    LEXICAL,     // BM25/full-text search
    HYBRID       // Combined semantic + lexical
}
```

### 2. Core Models with Improvements

```java
package io.wayang.rag.model;

import com.fasterxml.jackson.annotation.JsonIgnore;
import com.fasterxml.jackson.annotation.JsonInclude;
import io.quarkus.runtime.annotations.RegisterForReflection;

import java.time.Instant;
import java.util.*;

/**
 * Enhanced Document model with builder pattern and validation
 */
@RegisterForReflection
@JsonInclude(JsonInclude.Include.NON_NULL)
public class Document {
    private final String id;
    private final String content;
    private final String title;
    private final String source;
    private final DocumentType type;
    private final Map<String, Object> metadata;
    private final Instant createdAt;
    private final Instant updatedAt;
    private final String tenantId;
    private final List<String> tags;
    private final String language;
    private final int contentLength;
    private final String checksum;
    
    private Document(Builder builder) {
        this.id = Objects.requireNonNull(builder.id, "Document ID is required");
        this.content = Objects.requireNonNull(builder.content, "Content is required");
        this.title = builder.title;
        this.source = builder.source;
        this.type = builder.type != null ? builder.type : DocumentType.TEXT;
        this.metadata = Collections.unmodifiableMap(new HashMap<>(builder.metadata));
        this.createdAt = builder.createdAt != null ? builder.createdAt : Instant.now();
        this.updatedAt = builder.updatedAt;
        this.tenantId = builder.tenantId;
        this.tags = Collections.unmodifiableList(new ArrayList<>(builder.tags));
        this.language = builder.language;
        this.contentLength = content.length();
        this.checksum = builder.checksum;
    }
    
    // Getters
    public String getId() { return id; }
    public String getContent() { return content; }
    public String getTitle() { return title; }
    public String getSource() { return source; }
    public DocumentType getType() { return type; }
    public Map<String, Object> getMetadata() { return metadata; }
    public Instant getCreatedAt() { return createdAt; }
    public Instant getUpdatedAt() { return updatedAt; }
    public String getTenantId() { return tenantId; }
    public List<String> getTags() { return tags; }
    public String getLanguage() { return language; }
    public int getContentLength() { return contentLength; }
    public String getChecksum() { return checksum; }
    
    @JsonIgnore
    public boolean hasMetadata(String key) {
        return metadata.containsKey(key);
    }
    
    @JsonIgnore
    public <T> Optional<T> getMetadata(String key, Class<T> type) {
        return Optional.ofNullable(metadata.get(key))
                .map(type::cast);
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public Builder toBuilder() {
        return new Builder(this);
    }
    
    public static class Builder {
        private String id;
        private String content;
        private String title;
        private String source;
        private DocumentType type;
        private Map<String, Object> metadata = new HashMap<>();
        private Instant createdAt;
        private Instant updatedAt;
        private String tenantId;
        private List<String> tags = new ArrayList<>();
        private String language;
        private String checksum;
        
        public Builder() {}
        
        public Builder(Document document) {
            this.id = document.id;
            this.content = document.content;
            this.title = document.title;
            this.source = document.source;
            this.type = document.type;
            this.metadata = new HashMap<>(document.metadata);
            this.createdAt = document.createdAt;
            this.updatedAt = document.updatedAt;
            this.tenantId = document.tenantId;
            this.tags = new ArrayList<>(document.tags);
            this.language = document.language;
            this.checksum = document.checksum;
        }
        
        public Builder id(String id) {
            this.id = id;
            return this;
        }
        
        public Builder content(String content) {
            this.content = content;
            return this;
        }
        
        public Builder title(String title) {
            this.title = title;
            return this;
        }
        
        public Builder source(String source) {
            this.source = source;
            return this;
        }
        
        public Builder type(DocumentType type) {
            this.type = type;
            return this;
        }
        
        public Builder metadata(String key, Object value) {
            this.metadata.put(key, value);
            return this;
        }
        
        public Builder metadata(Map<String, Object> metadata) {
            this.metadata.putAll(metadata);
            return this;
        }
        
        public Builder createdAt(Instant createdAt) {
            this.createdAt = createdAt;
            return this;
        }
        
        public Builder updatedAt(Instant updatedAt) {
            this.updatedAt = updatedAt;
            return this;
        }
        
        public Builder tenantId(String tenantId) {
            this.tenantId = tenantId;
            return this;
        }
        
        public Builder tag(String tag) {
            this.tags.add(tag);
            return this;
        }
        
        public Builder tags(List<String> tags) {
            this.tags.addAll(tags);
            return this;
        }
        
        public Builder language(String language) {
            this.language = language;
            return this;
        }
        
        public Builder checksum(String checksum) {
            this.checksum = checksum;
            return this;
        }
        
        public Document build() {
            return new Document(this);
        }
    }
}

/**
 * Document type enumeration
 */
public enum DocumentType {
    TEXT,
    PDF,
    HTML,
    MARKDOWN,
    JSON,
    XML,
    CSV,
    CODE
}

/**
 * Enhanced Document Chunk with semantic boundaries
 */
@RegisterForReflection
@JsonInclude(JsonInclude.Include.NON_NULL)
public class DocumentChunk {
    private final String id;
    private final String documentId;
    private final int index;
    private final String text;
    private final int startPosition;
    private final int endPosition;
    private final int tokenCount;
    private final Map<String, Object> metadata;
    private final List<String> entities;
    private final ChunkType chunkType;
    private final double semanticCoherence;
    
    private DocumentChunk(Builder builder) {
        this.id = Objects.requireNonNull(builder.id, "Chunk ID is required");
        this.documentId = Objects.requireNonNull(builder.documentId, "Document ID is required");
        this.index = builder.index;
        this.text = Objects.requireNonNull(builder.text, "Text is required");
        this.startPosition = builder.startPosition;
        this.endPosition = builder.endPosition;
        this.tokenCount = builder.tokenCount;
        this.metadata = Collections.unmodifiableMap(new HashMap<>(builder.metadata));
        this.entities = Collections.unmodifiableList(new ArrayList<>(builder.entities));
        this.chunkType = builder.chunkType != null ? builder.chunkType : ChunkType.PARAGRAPH;
        this.semanticCoherence = builder.semanticCoherence;
    }
    
    // Getters
    public String getId() { return id; }
    public String getDocumentId() { return documentId; }
    public int getIndex() { return index; }
    public String getText() { return text; }
    public int getStartPosition() { return startPosition; }
    public int getEndPosition() { return endPosition; }
    public int getTokenCount() { return tokenCount; }
    public Map<String, Object> getMetadata() { return metadata; }
    public List<String> getEntities() { return entities; }
    public ChunkType getChunkType() { return chunkType; }
    public double getSemanticCoherence() { return semanticCoherence; }
    
    public Map<String, Object> toMap() {
        Map<String, Object> map = new HashMap<>(metadata);
        map.put("id", id);
        map.put("documentId", documentId);
        map.put("index", index);
        map.put("text", text);
        map.put("startPosition", startPosition);
        map.put("endPosition", endPosition);
        map.put("tokenCount", tokenCount);
        map.put("entities", entities);
        map.put("chunkType", chunkType.name());
        map.put("semanticCoherence", semanticCoherence);
        return map;
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String id;
        private String documentId;
        private int index;
        private String text;
        private int startPosition;
        private int endPosition;
        private int tokenCount;
        private Map<String, Object> metadata = new HashMap<>();
        private List<String> entities = new ArrayList<>();
        private ChunkType chunkType;
        private double semanticCoherence;
        
        public Builder id(String id) {
            this.id = id;
            return this;
        }
        
        public Builder documentId(String documentId) {
            this.documentId = documentId;
            return this;
        }
        
        public Builder index(int index) {
            this.index = index;
            return this;
        }
        
        public Builder text(String text) {
            this.text = text;
            return this;
        }
        
        public Builder startPosition(int startPosition) {
            this.startPosition = startPosition;
            return this;
        }
        
        public Builder endPosition(int endPosition) {
            this.endPosition = endPosition;
            return this;
        }
        
        public Builder tokenCount(int tokenCount) {
            this.tokenCount = tokenCount;
            return this;
        }
        
        public Builder metadata(String key, Object value) {
            this.metadata.put(key, value);
            return this;
        }
        
        public Builder metadata(Map<String, Object> metadata) {
            this.metadata.putAll(metadata);
            return this;
        }
        
        public Builder entity(String entity) {
            this.entities.add(entity);
            return this;
        }
        
        public Builder entities(List<String> entities) {
            this.entities.addAll(entities);
            return this;
        }
        
        public Builder chunkType(ChunkType chunkType) {
            this.chunkType = chunkType;
            return this;
        }
        
        public Builder semanticCoherence(double semanticCoherence) {
            this.semanticCoherence = semanticCoherence;
            return this;
        }
        
        public DocumentChunk build() {
            if (id == null) {
                id = documentId + "_chunk_" + index;
            }
            return new DocumentChunk(this);
        }
    }
}

/**
 * Chunk type enum
 */
public enum ChunkType {
    SENTENCE,
    PARAGRAPH,
    SECTION,
    PAGE,
    CUSTOM
}

/**
 * Enhanced Search Result with provenance
 */
@RegisterForReflection
@JsonInclude(JsonInclude.Include.NON_NULL)
public class SearchResult {
    private final String id;
    private final String documentId;
    private final String content;
    private final double score;
    private final Map<String, Object> metadata;
    private final List<String> highlights;
    private final ScoreBreakdown scoreBreakdown;
    private final Instant retrievedAt;
    
    private SearchResult(Builder builder) {
        this.id = Objects.requireNonNull(builder.id, "ID is required");
        this.documentId = builder.documentId;
        this.content = Objects.requireNonNull(builder.content, "Content is required");
        this.score = builder.score;
        this.metadata = Collections.unmodifiableMap(new HashMap<>(builder.metadata));
        this.highlights = Collections.unmodifiableList(new ArrayList<>(builder.highlights));
        this.scoreBreakdown = builder.scoreBreakdown;
        this.retrievedAt = builder.retrievedAt != null ? builder.retrievedAt : Instant.now();
    }
    
    // Getters
    public String getId() { return id; }
    public String getDocumentId() { return documentId; }
    public String getContent() { return content; }
    public double getScore() { return score; }
    public Map<String, Object> getMetadata() { return metadata; }
    public List<String> getHighlights() { return highlights; }
    public ScoreBreakdown getScoreBreakdown() { return scoreBreakdown; }
    public Instant getRetrievedAt() { return retrievedAt; }
    
    public SearchResult withScore(double newScore) {
        return builder()
                .id(id)
                .documentId(documentId)
                .content(content)
                .score(newScore)
                .metadata(metadata)
                .highlights(highlights)
                .scoreBreakdown(scoreBreakdown)
                .retrievedAt(retrievedAt)
                .build();
    }
    
    public static Builder builder() {
        return new Builder();
    }
    
    public static class Builder {
        private String id;
        private String documentId;
        private String content;
        private double score;
        private Map<String, Object> metadata = new HashMap<>();
        private List<String> highlights = new ArrayList<>();
        private ScoreBreakdown scoreBreakdown;
        private Instant retrievedAt;
        
        public Builder id(String id) {
            this.id = id;
            return this;
        }
        
        public Builder documentId(String documentId) {
            this.documentId = documentId;
            return this;
        }
        
        public Builder content(String content) {
            this.content = content;
            return this;
        }
        
        public Builder score(double score) {
            this.score = score;
            return this;
        }
        
        public Builder metadata(Map<String, Object> metadata) {
            this.metadata.putAll(metadata);
            return this;
        }
        
        public Builder highlight(String highlight) {
            this.highlights.add(highlight);
            return this;
        }
        
        public Builder highlights(List<String> highlights) {
            this.highlights.addAll(highlights);
            return this;
        }
        
        public Builder scoreBreakdown(ScoreBreakdown scoreBreakdown) {
            this.scoreBreakdown = scoreBreakdown;
            return this;
        }
        
        public Builder retrievedAt(Instant retrievedAt) {
            this.retrievedAt = retrievedAt;
            return this;
        }
        
        public SearchResult build() {
            return new SearchResult(this);
        }
    }
}

/**
 * Score breakdown for transparency
 */
@RegisterForReflection
public class ScoreBreakdown {
    private final double semanticScore;
    private final double lexicalScore;
    private final double recencyScore;
    private final double diversityScore;
    private final double metadataScore;
    
    public ScoreBreakdown(double semanticScore, double lexicalScore, 
                         double recencyScore, double diversityScore, double metadataScore) {
        this.semanticScore = semanticScore;
        this.lexicalScore = lexicalScore;
        this.recencyScore = recencyScore;
        this.diversityScore = diversityScore;
        this.metadataScore = metadataScore;
    }
    
    // Getters
    public double getSemanticScore() { return semanticScore; }
    public double getLexicalScore() { return lexicalScore; }
    public double getRecencyScore() { return recencyScore; }
    public double getDiversityScore() { return diversityScore; }
    public double getMetadataScore() { return metadataScore; }
    
    public double getTotalScore() {
        return semanticScore + lexicalScore + recencyScore + diversityScore + metadataScore;
    }
}
```

### 3. Improved Embedding Service with Caching

```java





```

### 4. Local Embedding Provider with Sentence Transformers

```java

```

Would you like me to continue with:
1. **PgVector Store Implementation** with connection pooling and optimization
2. **Advanced Chunking Strategies** (semantic, sentence-aware, sliding window)
3. **Hybrid Retrieval Engine** with BM25 + Vector fusion
4. **Re-ranking Implementation** (Cross-encoder + LLM-as-judge)
5. **Context Assembly** with citation tracking
6. **Complete REST API** with OpenAPI documentation

Let me know which part you'd like next!'




## Root POM.xml

```xml

```

## application.properties

```properties

```

## META-INF/beans.xml

```xml

```

## .gitignore

```gitignore

```

## README.md

```markdown

This provides a complete, production-ready skeleton for the Wayang Agent SDK module. Would you like me to:

1. Create similar skeletons for other modules (RAG, Orchestration, etc.)?
2. Add more detailed implementation examples?
3. Include Docker and Kubernetes deployment configurations?
4. Add CI/CD pipeline configurations (GitHub Actions, GitLab CI)?




Ah, I understand now! This is a **critical architectural distinction**. Let me clarify the two approaches and redesign the module structure accordingly:


## Core Module Structure (Minimal Dependencies)

### wayang-core/wayang-api/pom.xml

```xml

```


## Individual Node Module Example

### wayang-nodes/wayang-node-rag/pom.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>io.wayang</groupId>
        <artifactId>wayang-nodes</artifactId>
        <version>1.0.0-SNAPSHOT</version>
    </parent>

    <artifactId>wayang-node-rag</artifactId>
    <name>Wayang RAG Node</name>
    <description>RAG node implementation (standalone module)</description>

    <dependencies>
        <!-- Core API (minimal) -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-api</artifactId>
        </dependency>

        <!-- ONLY dependencies specific to RAG -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-embedding</artifactId>
            <scope>provided</scope> <!-- Optional at runtime -->
        </dependency>

        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-vector</artifactId>
            <scope>provided</scope>
        </dependency>

        <!-- Minimal JSON -->
        <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <!-- Create standalone JAR -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.5.1</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <createDependencyReducedPom>false</createDependencyReducedPom>
                            <shadedArtifactAttached>true</shadedArtifactAttached>
                            <shadedClassifierName>standalone</shadedClassifierName>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
```

## Code Generator Architecture

### wayang-codegen/wayang-codegen-core

```java
package io.wayang.codegen;


/**
 * Dependency graph for code generation
 */
public class DependencyGraph {
    private final Set<String> coreDependencies = new LinkedHashSet<>();
    private final Set<String> nodeDependencies = new LinkedHashSet<>();
    private final Set<String> serviceDependencies = new LinkedHashSet<>();
    private final Set<String> runtimeDependencies = new LinkedHashSet<>();
    
    public void addCoreDependency(String artifact) {
        coreDependencies.add(artifact);
    }
    
    public void addNodeDependency(String artifact) {
        nodeDependencies.add(artifact);
    }
    
    public void addServiceDependency(String artifact) {
        serviceDependencies.add(artifact);
    }
    
    public void addRuntimeDependency(String artifact) {
        runtimeDependencies.add(artifact);
    }
    
    /**
     * Get all unique dependencies
     */
    public Set<String> getAllDependencies() {
        Set<String> all = new LinkedHashSet<>();
        all.addAll(coreDependencies);
        all.addAll(nodeDependencies);
        all.addAll(serviceDependencies);
        all.addAll(runtimeDependencies);
        return all;
    }
    
    /**
     * Generate Maven POM dependencies section
     */
    public String generateMavenDependencies() {
        StringBuilder xml = new StringBuilder();
        xml.append("    <dependencies>\n");
        
        for (String dep : getAllDependencies()) {
            String[] parts = dep.split(":");
            xml.append("        <dependency>\n");
            xml.append("            <groupId>").append(parts[0]).append("</groupId>\n");
            xml.append("            <artifactId>").append(parts[1]).append("</artifactId>\n");
            xml.append("        </dependency>\n");
        }
        
        xml.append("    </dependencies>\n");
        return xml.toString();
    }
}
```

### Code Generator - Main Class

```java
package io.wayang.codegen;

/**
 * Generates standalone agent code from workflow schema
 */
@ApplicationScoped
public class StandaloneAgentGenerator {
    
    @Inject
    DependencyAnalyzer dependencyAnalyzer;
    
    @Inject
    CodeTemplateEngine templateEngine;
    
    @Inject
    CodeOptimizer optimizer;
    
    /**
     * Generate standalone agent from workflow schema
     */
    public GeneratedAgent generate(WorkflowSchema schema, GenerationConfig config) {
        // 1. Analyze dependencies
        DependencyGraph dependencies = dependencyAnalyzer.analyze(schema);
        
        // 2. Generate main class
        String mainClass = generateMainClass(schema, config);
        
        // 3. Generate configuration
        String configuration = generateConfiguration(schema, config);
        
        // 4. Generate POM
        String pom = generatePom(schema, dependencies, config);
        
        // 5. Generate Dockerfile (optional)
        String dockerfile = config.isGenerateDocker() 
            ? generateDockerfile(schema, config) 
            : null;
        
        // 6. Optimize code (remove unused imports, etc.)
        if (config.isOptimize()) {
            mainClass = optimizer.optimize(mainClass);
        }
        
        return GeneratedAgent.builder()
                .mainClass(mainClass)
                .configuration(configuration)
                .pom(pom)
                .dockerfile(dockerfile)
                .dependencies(dependencies)
                .build();
    }
    
    private String generateMainClass(WorkflowSchema schema, GenerationConfig config) {
        Map<String, Object> context = new HashMap<>();
        context.put("schema", schema);
        context.put("config", config);
        context.put("packageName", config.getPackageName());
        context.put("className", config.getClassName());
        context.put("nodes", schema.getNodes());
        
        return templateEngine.render("standalone-agent-main.ftl", context);
    }
    
    private String generatePom(WorkflowSchema schema, 
                              DependencyGraph dependencies, 
                              GenerationConfig config) {
        Map<String, Object> context = new HashMap<>();
        context.put("groupId", config.getGroupId());
        context.put("artifactId", config.getArtifactId());
        context.put("version", config.getVersion());
        context.put("dependencies", dependencies.getAllDependencies());
        context.put("javaVersion", config.getJavaVersion());
        
        return templateEngine.render("standalone-pom.ftl", context);
    }
}
```

## Generated Standalone Agent Example

### Generated pom.xml (Minimal - Only RAG Node Used)

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.example</groupId>
    <artifactId>my-rag-agent</artifactId>
    <version>1.0.0</version>
    <packaging>jar</packaging>

    <properties>
        <maven.compiler.source>21</maven.compiler.source>
        <maven.compiler.target>21</maven.compiler.target>
        <quarkus.platform.version>3.8.1</quarkus.platform.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>io.quarkus.platform</groupId>
                <artifactId>quarkus-bom</artifactId>
                <version>${quarkus.platform.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <dependencies>
        <!-- ONLY REQUIRED CORE -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-api</artifactId>
            <version>1.0.0</version>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-runtime-core</artifactId>
            <version>1.0.0</version>
        </dependency>

        <!-- ONLY RAG NODE (user used this) -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-node-rag</artifactId>
            <version>1.0.0</version>
        </dependency>

        <!-- ONLY REQUIRED SERVICES FOR RAG -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-embedding</artifactId>
            <version>1.0.0</version>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-vector</artifactId>
            <version>1.0.0</version>
        </dependency>

        <!-- ONLY PgVector (user selected this) -->
        <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <version>42.7.1</version>
        </dependency>
        
        <dependency>
            <groupId>com.pgvector</groupId>
            <artifactId>pgvector-java</artifactId>
            <version>0.1.4</version>
        </dependency>

        <!-- ONLY Local Embedding (user selected this) -->
        <dependency>
            <groupId>ai.djl</groupId>
            <artifactId>api</artifactId>
            <version>0.26.0</version>
        </dependency>

        <!-- Minimal Quarkus -->
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-arc</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-resteasy-reactive</artifactId>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>io.quarkus.platform</groupId>
                <artifactId>quarkus-maven-plugin</artifactId>
                <version>${quarkus.platform.version}</version>
            </plugin>
        </plugins>
    </build>
</project>
```

### Generated Main Class (Minimal - Only RAG Logic)

```java
package com.example.agent;

import io.wayang.api.node.*;
import io.wayang.api.workflow.*;
import io.wayang.node.rag.RAGNode;
import io.wayang.service.embedding.EmbeddingService;
import io.wayang.service.vector.VectorStore;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;

/**
 * Generated standalone RAG agent
 * Generated from schema: my-rag-workflow.json
 * Generation time: 2025-01-15T10:30:00Z
 */
@ApplicationScoped
public class MyRAGAgent implements WorkflowExecutor {
    
    @Inject
    EmbeddingService embeddingService;
    
    @Inject
    VectorStore vectorStore;
    
    private final RAGNode ragNode;
    
    public MyRAGAgent() {
        // Initialize only RAG node
        this.ragNode = new RAGNode(embeddingService, vectorStore);
    }
    
    @Override
    public Result execute(ExecutionContext context) {
        // Simple execution - no orchestration needed for single node
        NodeContext nodeContext = NodeContext.from(context);
        return ragNode.execute(nodeContext);
    }
}
```

## Service Provider Interface (SPI) for Dynamic Loading

### wayang-api/src/main/java/io/wayang/api/spi/NodeProvider.java

```java
package io.wayang.api.spi;

/**
 * SPI for dynamic node loading
 * Implementations register via META-INF/services
 */
public interface NodeProvider {
    /**
     * Get node type identifier
     */
    String getNodeType();
    
    /**
     * Get node descriptor
     */
    NodeDescriptor getDescriptor();
    
    /**
     * Create node instance
     */
    Node createNode(NodeConfig config);
    
    /**
     * Check if this provider is available (all dependencies present)
     */
    default boolean isAvailable() {
        return true;
    }
}
```

### META-INF/services/io.wayang.api.spi.NodeProvider (in wayang-node-rag)

```
io.wayang.node.rag.RAGNodeProvider
```

### RAG Node Provider Implementation

```java
package io.wayang.node.rag;

import io.wayang.api.spi.NodeProvider;

/**
 * RAG node provider for SPI
 */
public class RAGNodeProvider implements NodeProvider {
    
    @Override
    public String getNodeType() {
        return "rag";
    }
    
    @Override
    public NodeDescriptor getDescriptor() {
        return NodeDescriptor.builder()
                .id("wayang.node.rag")
                .name("RAG Node")
                .version("1.0.0")
                .input("query", String.class, true)
                .input("topK", Integer.class, false)
                .output("context", String.class)
                .output("citations", List.class)
                .build();
    }
    
    @Override
    public Node createNode(NodeConfig config) {
        // Lazy load dependencies only when node is actually created
        return new RAGNode(config);
    }
    
    @Override
    public boolean isAvailable() {
        try {
            // Check if required classes are available
            Class.forName("io.wayang.service.embedding.EmbeddingService");
            Class.forName("io.wayang.service.vector.VectorStore");
            return true;
        } catch (ClassNotFoundException e) {
            return false;
        }
    }
}
```

## Platform Assembly (Approach 1 - Full Platform)

### wayang-platform-full/pom.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0">
    <modelVersion>4.0.0</modelVersion>

    <groupId>io.wayang</groupId>
    <artifactId>wayang-platform-full</artifactId>
    <version>1.0.0-SNAPSHOT</version>
    <packaging>jar</packaging>

    <name>Wayang Platform Full</name>
    <description>Full platform with all components (Approach 1)</description>

    <dependencies>
        <!-- Core (always included) -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-api</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-runtime-core</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-runtime-orchestrator</artifactId>
        </dependency>

        <!-- ALL Node types (dynamically loaded via SPI) -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-node-rag</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-node-agent</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-node-tool</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-node-guardrails</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-node-evaluator</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-node-critic</artifactId>
        </dependency>
        
        <!-- ALL Services -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-llm</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-embedding</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-vector</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-memory</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-service-tool</artifactId>
        </dependency>

        <!-- Designer Backend -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-designer-backend</artifactId>
        </dependency>

        <!-- Code Generator -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-codegen-core</artifactId>
        </dependency>

        <!-- Full Quarkus stack -->
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-arc</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-resteasy-reactive</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-resteasy-reactive-jackson</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-scheduler</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-micrometer-registry-prometheus</artifactId>
        </dependency>
        
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-opentelemetry</artifactId>
        </dependency>
    </dependencies>
</project>
```

## Dynamic Node Loading (Approach 1)

```java
package io.wayang.runtime;

/**
 * Dynamic node loader using SPI
 * Used in Approach 1 (Full Platform)
 */
@ApplicationScoped
public class DynamicNodeLoader {
    
    private final Map<String, NodeProvider> providers = new ConcurrentHashMap<>();
    
    @PostConstruct
    public void init() {
        // Load all available node providers via SPI
        ServiceLoader<NodeProvider> loader = ServiceLoader.load(NodeProvider.class);
        
        for (NodeProvider provider : loader) {
            if (provider.isAvailable()) {
                providers.put(provider.getNodeType(), provider);
                LOG.infof("Loaded node provider: %s", provider.getNodeType());
            } else {
                LOG.warnf("Node provider not available (missing dependencies): %s", 
                         provider.getNodeType());
            }
        }
        
        LOG.infof("Loaded %d node providers", providers.size());
    }
    
    /**
     * Create node instance from schema definition
     */
    public Node createNode(NodeDefinition definition) {
        NodeProvider provider = providers.get(definition.getType());
        
        if (provider == null) {
            throw new NodeException("No provider found for node type: " + definition.getType());
        }
        
        NodeConfig config = NodeConfig.from(definition);
        return provider.createNode(config);
    }
    
    /**
     * Get available node types
     */
    public Set<String> getAvailableNodeTypes() {
        return providers.keySet();
    }
}
```

## Summary: Key Differences

### Approach 1: Full Platform
```
Dependencies: ALL modules (~50MB+ JAR)
Loading: Dynamic via SPI
Use case: Multi-tenant SaaS, enterprise deployment
Startup: Slower (loads all providers)
Runtime: Flexible (any workflow can run)
```

### Approach 2: Standalone/Generated
```
Dependencies: ONLY used modules (~5-15MB JAR)
Loading: Static (code-generated)
Use case: Edge, microservices, mobile
Startup: Fast (only required classes)
Runtime: Fixed (specific workflow only)
```

This architecture allows you to:
1. **Full Platform**: Users design any workflow, all components available
2. **Standalone**: Code generator analyzes schema, includes only necessary dependencies

Would you like me to:
1. Show the complete code generator templates?
2. Detail the workflow schema format?
3. Provide more node implementation examples?
4. Show the Designer backend API that saves schemas?




# Wayang Code Generator - Complete Implementation with Mustache Templates

## Project Structure

```
wayang-codegen/
 pom.xml
 src/
    main/
       java/
          io/
              wayang/
                  codegen/
                      CodeGenerator.java
                      DependencyAnalyzer.java
                      TemplateEngine.java
                      SchemaAnalyzer.java
                      CodeOptimizer.java
                      model/
                         WorkflowSchema.java
                         NodeDefinition.java
                         EdgeDefinition.java
                         PropertyDefinition.java
                         DependencyGraph.java
                         GenerationConfig.java
                         GeneratedArtifact.java
                      generator/
                          JavaClassGenerator.java
                          PomGenerator.java
                          ConfigGenerator.java
                          DockerfileGenerator.java
                          ReadmeGenerator.java
       resources/
           templates/
               java/
                  main-class.mustache
                  node-executor.mustache
                  service-config.mustache
                  application-main.mustache
               pom/
                  pom.mustache
                  dependencies.mustache
                  plugins.mustache
               config/
                  application.properties.mustache
                  logback.xml.mustache
               docker/
                  Dockerfile.mustache
                  docker-compose.yml.mustache
               docs/
                   README.mustache
                   API.mustache
    test/
        java/
            io/
                wayang/
                    codegen/
                        CodeGeneratorTest.java
                        DependencyAnalyzerTest.java
```

## POM.xml for Code Generator Module

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>io.wayang</groupId>
        <artifactId>wayang-platform</artifactId>
        <version>1.0.0-SNAPSHOT</version>
    </parent>

    <artifactId>wayang-codegen</artifactId>
    <name>Wayang Code Generator</name>
    <description>Code generator for standalone agents</description>

    <properties>
        <mustache.version>0.9.11</mustache.version>
        <javaparser.version>3.25.8</javaparser.version>
        <commons-io.version>2.15.1</commons-io.version>
    </properties>

    <dependencies>
        <!-- Core API -->
        <dependency>
            <groupId>io.wayang</groupId>
            <artifactId>wayang-api</artifactId>
        </dependency>

        <!-- Quarkus -->
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-arc</artifactId>
        </dependency>

        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-resteasy-reactive-jackson</artifactId>
        </dependency>

        <!-- Mustache Templating -->
        <dependency>
            <groupId>com.github.spullara.mustache.java</groupId>
            <artifactId>compiler</artifactId>
            <version>${mustache.version}</version>
        </dependency>

        <!-- Java Parser for code analysis -->
        <dependency>
            <groupId>com.github.javaparser</groupId>
            <artifactId>javaparser-core</artifactId>
            <version>${javaparser.version}</version>
        </dependency>

        <!-- JSON Processing -->
        <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
        </dependency>

        <dependency>
            <groupId>com.fasterxml.jackson.dataformat</groupId>
            <artifactId>jackson-dataformat-yaml</artifactId>
        </dependency>

        <!-- Utilities -->
        <dependency>
            <groupId>commons-io</groupId>
            <artifactId>commons-io</artifactId>
            <version>${commons-io.version}</version>
        </dependency>

        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-text</artifactId>
            <version>1.11.0</version>
        </dependency>

        <!-- Testing -->
        <dependency>
            <groupId>io.quarkus</groupId>
            <artifactId>quarkus-junit5</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.assertj</groupId>
            <artifactId>assertj-core</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>
</project>
```

## Core Models

### WorkflowSchema.java

```java
package io.wayang.codegen.model;

import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * Workflow schema definition from visual designer
 */
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
@JsonIgnoreProperties(ignoreUnknown = true)
@JsonInclude(JsonInclude.Include.NON_NULL)
public class WorkflowSchema {
    
    /**
     * Workflow metadata
     */
    private String id;
    private String name;
    private String description;
    private String version;
    private String tenantId;
    
    /**
     * Node definitions
     */
    @Builder.Default
    private List<NodeDefinition> nodes = new ArrayList<>();
    
    /**
     * Edge definitions (connections between nodes)
     */
    @Builder.Default
    private List<EdgeDefinition> edges = new ArrayList<>();
    
    /**
     * Global workflow properties
     */
    @Builder.Default
    private Map<String, Object> properties = new HashMap<>();
    
    /**
     * Runtime configuration
     */
    private RuntimeConfig runtimeConfig;
    
    /**
     * Deployment target
     */
    private DeploymentTarget deploymentTarget;
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class RuntimeConfig {
        private String javaVersion;
        private String quarkusVersion;
        private boolean enableMetrics;
        private boolean enableTracing;
        private boolean enableHealthCheck;
        private int maxConcurrentExecutions;
        private String executionMode; // sync, async, streaming
    }
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class DeploymentTarget {
        private String type; // standalone-jar, docker, native, kubernetes
        private Map<String, String> configuration;
    }
}
```

### NodeDefinition.java

```java
package io.wayang.codegen.model;

import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * Node definition in workflow schema
 */
@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
@JsonIgnoreProperties(ignoreUnknown = true)
@JsonInclude(JsonInclude.Include.NON_NULL)
public class NodeDefinition {
    
    /**
     * Node identification
     */
    private String id;
    private String type; // rag, agent, tool, guardrails, etc.
    private String label;
    private String description;
    
    /**
     * Node configuration
     */
    @Builder.Default
    private Map<String, Object> properties = new HashMap<>();
    
    /**
     * Input/Output ports
     */
    @Builder.Default
    private List<PortDefinition> inputs = new ArrayList<>();
    
    @Builder.Default
    private List<PortDefinition> outputs = new ArrayList<>();
    
    /**
     * Position in visual designer (not used in generation)
     */
    private Position position;
    
    /**
     * Node-specific configuration based on type
     */
    private NodeTypeConfig typeConfig;
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class Position {
        private double x;
        private double y;
    }
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class PortDefinition {
        private String id;
        private String name;
        private String dataType;
        private boolean required;
        private Object defaultValue;
    }
}
```

### NodeTypeConfig.java

```java
package io.wayang.codegen.model;

import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.Map;

/**
 * Type-specific node configuration
 */
@Data
@NoArgsConstructor
@AllArgsConstructor
@JsonIgnoreProperties(ignoreUnknown = true)
@JsonInclude(JsonInclude.Include.NON_NULL)
public class NodeTypeConfig {
    
    // RAG specific
    private RAGConfig rag;
    
    // Agent specific
    private AgentConfig agent;
    
    // Tool specific
    private ToolConfig tool;
    
    // Guardrails specific
    private GuardrailsConfig guardrails;
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class RAGConfig {
        private String vectorStore; // pgvector, milvus, weaviate
        private String embeddingProvider; // local, openai, huggingface
        private String embeddingModel;
        private int dimension;
        private int chunkSize;
        private int chunkOverlap;
        private String retrievalStrategy; // semantic, lexical, hybrid
        private int topK;
        private boolean enableReranking;
    }
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class AgentConfig {
        private String llmProvider; // ollama, openai, anthropic
        private String model;
        private double temperature;
        private int maxTokens;
        private boolean enableStreaming;
        private String systemPrompt;
    }
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class ToolConfig {
        private String toolId;
        private String toolType; // rest-api, database, function, mcp
        private Map<String, Object> parameters;
        private int timeout;
        private int retries;
    }
    
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class GuardrailsConfig {
        private boolean detectPII;
        private boolean detectToxicity;
        private boolean detectHallucination;
        private String policyFile;
        private String[] allowedDomains;
    }
}
```

### DependencyGraph.java

```java
package io.wayang.codegen.model;

import lombok.Data;

import java.util.*;
import java.util.stream.Collectors;

/**
 * Dependency graph for generated agent
 */
@Data
public class DependencyGraph {
    
    private final Set<Dependency> coreDependencies = new LinkedHashSet<>();
    private final Set<Dependency> nodeDependencies = new LinkedHashSet<>();
    private final Set<Dependency> serviceDependencies = new LinkedHashSet<>();
    private final Set<Dependency> runtimeDependencies = new LinkedHashSet<>();
    private final Set<Dependency> quarkusDependencies = new LinkedHashSet<>();
    
    public void addCoreDependency(String groupId, String artifactId) {
        coreDependencies.add(new Dependency(groupId, artifactId, null, null));
    }
    
    public void addCoreDependency(String groupId, String artifactId, String version) {
        coreDependencies.add(new Dependency(groupId, artifactId, version, null));
    }
    
    public void addNodeDependency(String groupId, String artifactId) {
        nodeDependencies.add(new Dependency(groupId, artifactId, null, null));
    }
    
    public void addServiceDependency(String groupId, String artifactId) {
        serviceDependencies.add(new Dependency(groupId, artifactId, null, null));
    }
    
    public void addRuntimeDependency(String groupId, String artifactId, String version) {
        runtimeDependencies.add(new Dependency(groupId, artifactId, version, null));
    }
    
    public void addQuarkusDependency(String artifactId) {
        quarkusDependencies.add(new Dependency("io.quarkus", artifactId, null, null));
    }
    
    /**
     * Get all dependencies grouped by category
     */
    public Map<String, List<Dependency>> getAllDependenciesGrouped() {
        Map<String, List<Dependency>> grouped = new LinkedHashMap<>();
        grouped.put("core", new ArrayList<>(coreDependencies));
        grouped.put("nodes", new ArrayList<>(nodeDependencies));
        grouped.put("services", new ArrayList<>(serviceDependencies));
        grouped.put("runtime", new ArrayList<>(runtimeDependencies));
        grouped.put("quarkus", new ArrayList<>(quarkusDependencies));
        return grouped;
    }
    
    /**
     * Get all unique dependencies
     */
    public Set<Dependency> getAllDependencies() {
        Set<Dependency> all = new LinkedHashSet<>();
        all.addAll(coreDependencies);
        all.addAll(nodeDependencies);
        all.addAll(serviceDependencies);
        all.addAll(runtimeDependencies);
        all.addAll(quarkusDependencies);
        return all;
    }
    
    @Data
    public static class Dependency {
        private final String groupId;
        private final String artifactId;
        private final String version;
        private final String scope;
        
        public Dependency(String groupId, String artifactId, String version, String scope) {
            this.groupId = groupId;
            this.artifactId = artifactId;
            this.version = version;
            this.scope = scope;
        }
        
        @Override
        public boolean equals(Object o) {
            if (this == o) return true;
            if (o == null || getClass() != o.getClass()) return false;
            Dependency that = (Dependency) o;
            return Objects.equals(groupId, that.groupId) &&
                   Objects.equals(artifactId, that.artifactId);
        }
        
        @Override
        public int hashCode() {
            return Objects.hash(groupId, artifactId);
        }
    }
}
```

## Template Engine with Mustache

### TemplateEngine.java

```java
package io.wayang.codegen;

import com.github.mustachejava.DefaultMustacheFactory;
import com.github.mustachejava.Mustache;
import com.github.mustachejava.MustacheFactory;
import jakarta.enterprise.context.ApplicationScoped;
import org.jboss.logging.Logger;

import java.io.IOException;
import java.io.StringReader;
import java.io.StringWriter;
import java.io.Writer;
import java.util.Map;

/**
 * Template engine using Mustache
 */
@ApplicationScoped
public class TemplateEngine {
    
    private static final Logger LOG = Logger.getLogger(TemplateEngine.class);
    
    private final MustacheFactory mustacheFactory;
    
    public TemplateEngine() {
        this.mustacheFactory = new DefaultMustacheFactory("templates");
    }
    
    /**
     * Render template with context
     */
    public String render(String templateName, Map<String, Object> context) {
        try {
            Mustache mustache = mustacheFactory.compile(templateName);
            Writer writer = new StringWriter();
            mustache.execute(writer, context);
            writer.flush();
            return writer.toString();
        } catch (IOException e) {
            LOG.errorf(e, "Failed to render template: %s", templateName);
            throw new CodeGenerationException("Template rendering failed: " + templateName, e);
        }
    }
    
    /**
     * Render template from string
     */
    public String renderFromString(String template, Map<String, Object> context) {
        try {
            Mustache mustache = mustacheFactory.compile(new StringReader(template), "inline");
            Writer writer = new StringWriter();
            mustache.execute(writer, context);
            writer.flush();
            return writer.toString();
        } catch (IOException e) {
            LOG.error("Failed to render inline template", e);
            throw new CodeGenerationException("Inline template rendering failed", e);
        }
    }
    
    /**
     * Check if template exists
     */
    public boolean templateExists(String templateName) {
        try {
            mustacheFactory.compile(templateName);
            return true;
        } catch (Exception e) {
            return false;
        }
    }
}
```

## Dependency Analyzer

### DependencyAnalyzer.java

```java
package io.wayang.codegen;

import io.wayang.codegen.model.*;
import jakarta.enterprise.context.ApplicationScoped;
import org.jboss.logging.Logger;

/**
 * Analyzes workflow schema and determines required dependencies
 */
@ApplicationScoped
public class DependencyAnalyzer {
    
    private static final Logger LOG = Logger.getLogger(DependencyAnalyzer.class);
    
    private static final String WAYANG_VERSION = "1.0.0";
    
    /**
     * Analyze workflow schema and build dependency graph
     */
    public DependencyGraph analyze(WorkflowSchema schema) {
        LOG.infof("Analyzing dependencies for workflow: %s", schema.getName());
        
        DependencyGraph graph = new DependencyGraph();
        
        // Always required core dependencies
        addCoreDependencies(graph);
        
        // Analyze each node
        for (NodeDefinition node : schema.getNodes()) {
            analyzeNode(node, graph);
        }
        
        // Add Quarkus dependencies based on features
        addQuarkusDependencies(schema, graph);
        
        LOG.infof("Total dependencies: %d", graph.getAllDependencies().size());
        
        return graph;
    }
    
    private void addCoreDependencies(DependencyGraph graph) {
        // Core API (always needed)
        graph.addCoreDependency("io.wayang", "wayang-api", WAYANG_VERSION);
        
        // Runtime core (always needed)
        graph.addCoreDependency("io.wayang", "wayang-runtime-core", WAYANG_VERSION);
        
        // Minimal Quarkus
        graph.addQuarkusDependency("quarkus-arc");
        graph.addQuarkusDependency("quarkus-resteasy-reactive");
    }
    
    private void analyzeNode(NodeDefinition node, DependencyGraph graph) {
        LOG.debugf("Analyzing node: %s (type: %s)", node.getLabel(), node.getType());
        
        switch (node.getType().toLowerCase()) {
            case "rag" -> analyzeRAGNode(node, graph);
            case "agent" -> analyzeAgentNode(node, graph);
            case "tool" -> analyzeToolNode(node, graph);
            case "guardrails" -> analyzeGuardrailsNode(node, graph);
            case "evaluator" -> analyzeEvaluatorNode(node, graph);
            case "critic" -> analyzeCriticNode(node, graph);
            case "memory" -> analyzeMemoryNode(node, graph);
            case "decision" -> analyzeDecisionNode(node, graph);
            default -> LOG.warnf("Unknown node type: %s", node.getType());
        }
    }
    
    private void analyzeRAGNode(NodeDefinition node, DependencyGraph graph) {
        // RAG node itself
        graph.addNodeDependency("io.wayang", "wayang-node-rag");
        
        // Embedding service
        graph.addServiceDependency("io.wayang", "wayang-service-embedding");
        
        // Vector store service
        graph.addServiceDependency("io.wayang", "wayang-service-vector");
        
        NodeTypeConfig.RAGConfig ragConfig = node.getTypeConfig() != null 
            ? node.getTypeConfig().getRag() 
            : null;
        
        if (ragConfig != null) {
            // Vector store dependencies
            String vectorStore = ragConfig.getVectorStore();
            if (vectorStore != null) {
                switch (vectorStore.toLowerCase()) {
                    case "pgvector" -> {
                        graph.addRuntimeDependency("org.postgresql", "postgresql", "42.7.1");
                        graph.addRuntimeDependency("com.pgvector", "pgvector", "0.1.4");
                        graph.addQuarkusDependency("quarkus-jdbc-postgresql");
                        graph.addQuarkusDependency("quarkus-agroal");
                    }
                    case "milvus" -> {
                        graph.addRuntimeDependency("io.milvus", "milvus-sdk-java", "2.3.4");
                    }
                    case "weaviate" -> {
                        graph.addRuntimeDependency("io.weaviate", "client", "4.4.0");
                    }
                }
            }
            
            // Embedding provider dependencies
            String embeddingProvider = ragConfig.getEmbeddingProvider();
            if (embeddingProvider != null) {
                switch (embeddingProvider.toLowerCase()) {
                    case "local" -> {
                        graph.addRuntimeDependency("ai.djl", "api", "0.26.0");
                        graph.addRuntimeDependency("ai.djl.huggingface", "tokenizers", "0.26.0");
                        graph.addRuntimeDependency("ai.onnxruntime", "onnxruntime", "1.16.3");
                    }
                    case "openai" -> {
                        graph.addRuntimeDependency("com.theokanning.openai-gpt3-java", "service", "0.18.2");
                    }
                    case "huggingface" -> {
                        graph.addRuntimeDependency("ai.djl.huggingface", "tokenizers", "0.26.0");
                    }
                }
            }
        }
    }
    
    private void analyzeAgentNode(NodeDefinition node, DependencyGraph graph) {
        // Agent node
        graph.addNodeDependency("io.wayang", "wayang-node-agent");
        
        // LLM service
        graph.addServiceDependency("io.wayang", "wayang-service-llm");
        
        NodeTypeConfig.AgentConfig agentConfig = node.getTypeConfig() != null 
            ? node.getTypeConfig().getAgent() 
            : null;
        
        if (agentConfig != null) {
            String llmProvider = agentConfig.getLlmProvider();
            if (llmProvider != null) {
                switch (llmProvider.toLowerCase()) {
                    case "ollama" -> {
                        graph.addRuntimeDependency("io.github.ollama4j", "ollama4j", "1.0.79");
                    }
                    case "openai" -> {
                        graph.addRuntimeDependency("com.theokanning.openai-gpt3-java", "service", "0.18.2");
                    }
                    case "anthropic" -> {
                        graph.addRuntimeDependency("com.anthropic", "anthropic-java", "1.0.0");
                    }
                }
            }
            
            // If streaming enabled
            if (agentConfig.isEnableStreaming()) {
                graph.addQuarkusDependency("quarkus-resteasy-reactive-jackson");
                graph.addQuarkusDependency("quarkus-vertx");
            }
        }
    }
    
    private void analyzeToolNode(NodeDefinition node, DependencyGraph graph) {
        graph.addNodeDependency("io.wayang", "wayang-node-tool");
        graph.addServiceDependency("io.wayang", "wayang-service-tool");
        
        // HTTP client for REST APIs
        graph.addQuarkusDependency("quarkus-rest-client-reactive");
    }
    
    private void analyzeGuardrailsNode(NodeDefinition node, DependencyGraph graph) {
        graph.addNodeDependency("io.wayang", "wayang-node-guardrails");
        
        // NLP libraries for PII detection
        graph.addRuntimeDependency("org.apache.opennlp", "opennlp-tools", "2.3.1");
    }
    
    private void analyzeEvaluatorNode(NodeDefinition node, DependencyGraph graph) {
        graph.addNodeDependency("io.wayang", "wayang-node-evaluator");
        graph.addServiceDependency("io.wayang", "wayang-service-llm");
    }
    
    private void analyzeCriticNode(NodeDefinition node, DependencyGraph graph) {
        graph.addNodeDependency("io.wayang", "wayang-node-critic");
        graph.addServiceDependency("io.wayang", "wayang-service-llm");
    }
    
    private void analyzeMemoryNode(NodeDefinition node, DependencyGraph graph) {
        graph.addNodeDependency("io.wayang", "wayang-node-memory");
        graph.addServiceDependency("io.wayang", "wayang-service-memory");
        graph.addServiceDependency("io.wayang", "wayang-service-vector");
    }
    
    private void analyzeDecisionNode(NodeDefinition node, DependencyGraph graph) {
        graph.addNodeDependency("io.wayang", "wayang-node-decision");
        
        // CEL for expression evaluation
        graph.addRuntimeDependency("dev.cel", "cel", "0.4.4");
    }
    
    private void addQuarkusDependencies(WorkflowSchema schema, DependencyGraph graph) {
        WorkflowSchema.RuntimeConfig config = schema.getRuntimeConfig();
        
        if (config != null) {
            // Metrics
            if (config.isEnableMetrics()) {
                graph.addQuarkusDependency("quarkus-micrometer-registry-prometheus");
            }
            
            // Tracing
            if (config.isEnableTracing()) {
                graph.addQuarkusDependency("quarkus-opentelemetry");
            }
            
            // Health checks
            if (config.isEnableHealthCheck()) {
                graph.addQuarkusDependency("quarkus-smallrye-health");
            }
            
            // Async execution
            if ("async".equals(config.getExecutionMode())) {
                graph.addQuarkusDependency("quarkus-smallrye-context-propagation");
                graph.addQuarkusDependency("quarkus-smallrye-mutiny");
            }
        }
        
        // JSON processing (always needed)
        graph.addQuarkusDependency("quarkus-resteasy-reactive-jackson");
    }
}
```

## Mustache Templates

### templates/pom/pom.mustache

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>{{groupId}}</groupId>
    <artifactId>{{artifactId}}</artifactId>
    <version>{{version}}</version>
    <packaging>jar</packaging>

    <name>{{name}}</name>
    <description>{{description}}</description>

    <properties>
        <maven.compiler.source>{{javaVersion}}</maven.compiler.source>
        <maven.compiler.target>{{javaVersion}}</maven.compiler.target>
        <maven.compiler.release>{{javaVersion}}</maven.compiler.release>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        
        <quarkus.platform.version>{{quarkusVersion}}</quarkus.platform.version>
        <quarkus.platform.group-id>io.quarkus.platform</quarkus.platform.group-id>
        <quarkus.platform.artifact-id>quarkus-bom</quarkus.platform.artifact-id>
        
        <wayang.version>{{wayangVersion}}</wayang.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>${quarkus.platform.group-id}</groupId>
                <artifactId>${quarkus.platform.artifact-id}</artifactId>
                <version>${quarkus.platform.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <dependencies>
        <!-- Core Dependencies -->
        {{#dependencies.core}}
        <dependency>
            <groupId>{{groupId}}</groupId>
            <artifactId>{{artifactId}}</artifactId>
            {{#version}}
            <version>{{version}}</version>
            {{/version}}
            {{^version}}
            <version>${wayang.version}</version>
            {{/version}}
            {{#scope}}
            <scope>{{scope}}</scope>
            {{/scope}}
        </dependency>
        {{/dependencies.core}}

        <!-- Node Dependencies -->
        {{#dependencies.nodes}}
        <dependency>
            <groupId>{{groupId}}</groupId>
            <artifactId>{{artifactId}}</artifactId>
            <version>${wayang.version}</version>
        </dependency>
        {{/dependencies.nodes}}

        <!-- Service Dependencies -->
        {{#dependencies.services}}
        <dependency>
            <groupId>{{groupId}}</groupId>
            <artifactId>{{artifactId}}</artifactId>
            <version>${wayang.version}</version>
        </dependency>
        {{/dependencies.services}}

        <!-- Runtime Dependencies -->
        {{#dependencies.runtime}}
        <dependency>
            <groupId>{{groupId}}</groupId>
            <artifactId>{{artifactId}}</artifactId>
            {{#version}}
            <version>{{version}}</version>
            {{/version}}
        </dependency>
        {{/dependencies.runtime}}

        <!-- Quarkus Dependencies -->
        {{#dependencies.quarkus}}
        <dependency>
            <groupId>{{groupId}}</groupId>
            <artifactId>{{artifactId}}</artifactId>
        </dependency>
        {{/dependencies.quarkus}}
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>${quarkus.platform.group-id}</groupId>
                <artifactId>quarkus-maven-plugin</artifactId>
                <version>${quarkus.platform.version}</version>
                <extensions>true</extensions>
                <executions>
                    <execution>
                        <goals>
                            <goal>build</goal>
                            <goal>generate-code</goal>
                            <goal>generate-code-tests</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.12.1</version>
                <configuration>
                    <parameters>true</parameters>
                </configuration>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>3.2.3</version>
                <configuration>
                    <systemPropertyVariables>
                        <java.util.logging.manager>org.jboss.logmanager.LogManager</java.util.logging.manager>
                    </systemPropertyVariables>
                </configuration>
            </plugin>
        </plugins>
    </build>

    {{#enableNativeBuild}}
    <profiles>
        <profile>
            <id>native</id>
            <activation>
                <property>
                    <name>native</name>
                </property>
            </activation>
            <properties>
                <quarkus.package.type>native</quarkus.package.type>
            </properties>
        </profile>
    </profiles>
    {{/enableNativeBuild}}
</project>
```

### templates/java/main-class.mustache

```java
package {{packageName}};

import io.wayang.api.node.*;
import io.wayang.api.workflow.*;
import io.wayang.runtime.executor.WorkflowExecutor;
{{#imports}}
import {{.}};
{{/imports}}

import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.jboss.logging.Logger;

import java.util.Map;
import java.util.HashMap;

/**
 * Generated standalone agent: {{agentName}}
 * 
 * Generated from workflow: {{workflowName}}
 * Description: {{workflowDescription}}
 * Generated at: {{timestamp}}
 * 
 * This is a standalone agent with only the required dependencies.
 * 
 * Nodes included:
 {{#nodes}}
 * - {{label}} ({{type}})
 {{/nodes}}
 */
@ApplicationScoped
public class {{className}} implements WorkflowExecutor {
    
    private static final Logger LOG = Logger.getLogger({{className}}.class);
    
    {{#nodeFields}}
    @Inject
    {{type}} {{name}};
    {{/nodeFields}}
    
    {{#hasOrchestration}}
    private final Map<String, Node> nodeRegistry = new HashMap<>();
    {{/hasOrchestration}}
    
    @PostConstruct
    public void init() {
        LOG.infof("Initializing agent: {{agentName}}");
        
        {{#hasOrchestration}}
        // Register nodes
        {{#nodes}}
        nodeRegistry.put("{{id}}", {{fieldName}});
        {{/nodes}}
        {{/hasOrchestration}}
        
        LOG.info("Agent initialized successfully");
    }
    
    @Override
    public Result execute(ExecutionContext context) {
        LOG.infof("Executing workflow: {{workflowName}}");
        
        try {
            {{#isSingleNode}}
            // Single node execution - no orchestration needed
            NodeContext nodeContext = NodeContext.builder()
                {{#inputs}}
                .input("{{name}}", context.getInput("{{name}}"))
                {{/inputs}}
                .metadata(context.getMetadata())
                .build();
            
            NodeResult result = {{singleNodeField}}.execute(nodeContext);
            
            return Result.builder()
                .status(result.getStatus())
                .outputs(result.getOutputs())
                .build();
            {{/isSingleNode}}
            
            {{^isSingleNode}}
            // Multi-node orchestration
            Map<String, Object> executionState = new HashMap<>();
            
            {{#executionSteps}}
            // Step {{index}}: {{nodeName}}
            {
                LOG.debugf("Executing node: {{nodeName}}");
                
                NodeContext nodeContext = NodeContext.builder()
                    {{#inputs}}
                    .input("{{name}}", {{source}})
                    {{/inputs}}
                    .build();
                
                Node node = nodeRegistry.get("{{nodeId}}");
                NodeResult result = node.execute(nodeContext);
                
                if (!result.isSuccess()) {
                    throw new WorkflowExecutionException(
                        "Node execution failed: {{nodeName}}", 
                        result.getError()
                    );
                }
                
                // Store outputs for next nodes
                {{#outputs}}
                executionState.put("{{key}}", result.getOutput("{{outputName}}"));
                {{/outputs}}
            }
            {{/executionSteps}}
            
            // Build final result
            return Result.builder()
                .status(ExecutionStatus.SUCCESS)
                .outputs(executionState)
                .build();
            {{/isSingleNode}}
            
        } catch (Exception e) {
            LOG.error("Workflow execution failed", e);
            return Result.builder()
                .status(ExecutionStatus.FAILED)
                .error(e.getMessage())
                .build();
        }
    }
}
```

### templates/config/application.properties.mustache

```properties
# Generated Application Configuration
# Workflow: {{workflowName}}
# Generated: {{timestamp}}

# Application
quarkus.application.name={{artifactId}}
quarkus.application.version={{version}}

# HTTP
quarkus.http.port={{httpPort}}

# Logging
quarkus.log.level={{logLevel}}
quarkus.log.category."{{packageName}}".level=DEBUG
quarkus.log.console.enable=true

{{#enableMetrics}}
# Metrics
quarkus.micrometer.enabled=true
quarkus.micrometer.export.prometheus.enabled=true
quarkus.micrometer.export.prometheus.path=/metrics
{{/enableMetrics}}

{{#enableTracing}}
# Tracing
quarkus.otel.enabled=true
quarkus.otel.traces.enabled=true
quarkus.otel.service.name={{artifactId}}
{{/enableTracing}}

{{#enableHealthCheck}}
# Health
quarkus.smallrye-health.root-path=/health
{{/enableHealthCheck}}

{{#hasRAGNode}}
# RAG Configuration
wayang.rag.vector-store.provider={{ragConfig.vectorStore}}
wayang.rag.embedding.provider={{ragConfig.embeddingProvider}}
wayang.rag.embedding.model={{ragConfig.embeddingModel}}
wayang.rag.ingestion.chunk-size={{ragConfig.chunkSize}}
wayang.rag.ingestion.chunk-overlap={{ragConfig.chunkOverlap}}
wayang.rag.retrieval.strategy={{ragConfig.retrievalStrategy}}
wayang.rag.retrieval.top-k={{ragConfig.topK}}
wayang.rag.retrieval.enable-reranking={{ragConfig.enableReranking}}

{{#isPgVector}}
# PgVector Configuration
quarkus.datasource.db-kind=postgresql
quarkus.datasource.username=${DB_USERNAME:postgres}
quarkus.datasource.password=${DB_PASSWORD:postgres}
quarkus.datasource.jdbc.url=${DB_URL:jdbc:postgresql://localhost:5432/wayang}
{{/isPgVector}}
{{/hasRAGNode}}

{{#hasAgentNode}}
# Agent Configuration
wayang.agent.llm.provider={{agentConfig.llmProvider}}
wayang.agent.llm.model={{agentConfig.model}}
wayang.agent.llm.temperature={{agentConfig.temperature}}
wayang.agent.llm.max-tokens={{agentConfig.maxTokens}}
wayang.agent.llm.enable-streaming={{agentConfig.enableStreaming}}

{{#isOllama}}
# Ollama Configuration
wayang.agent.llm.ollama.url=${OLLAMA_URL:http://localhost:11434}
{{/isOllama}}

{{#isOpenAI}}
# OpenAI Configuration
wayang.agent.llm.openai.api-key=${OPENAI_API_KEY}
{{/isOpenAI}}
{{/hasAgentNode}}

{{#hasToolNode}}
# Tool Configuration
wayang.tool.gateway.timeout={{toolConfig.timeout}}
wayang.tool.gateway.retries={{toolConfig.retries}}
{{/hasToolNode}}

{{#hasGuardrailsNode}}
# Guardrails Configuration
wayang.guardrails.detect-pii={{guardrailsConfig.detectPII}}
wayang.guardrails.detect-toxicity={{guardrailsConfig.detectToxicity}}
wayang.guardrails.detect-hallucination={{guardrailsConfig.detectHallucination}}
{{/hasGuardrailsNode}}
```

### templates/docker/Dockerfile.mustache

```dockerfile
# Generated Dockerfile for {{agentName}}
# Multi-stage build for minimal image size

# Stage 1: Build
FROM maven:3.9-eclipse-temurin-{{javaVersion}} AS build

WORKDIR /build

# Copy pom and download dependencies
COPY pom.xml .
RUN mvn dependency:go-offline

# Copy source and build
COPY src ./src
RUN mvn clean package -DskipTests

# Stage 2: Runtime
FROM eclipse-temurin:{{javaVersion}}-jre-alpine

WORKDIR /app

# Copy artifact
COPY --from=build /build/target/*-runner.jar /app/app.jar

{{#hasRAGNode}}
# Install PostgreSQL client (if using pgvector)
RUN apk add --no-cache postgresql-client
{{/hasRAGNode}}

# Create non-root user
RUN addgroup -g 1001 wayang && \
    adduser -D -u 1001 -G wayang wayang

USER wayang

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:{{httpPort}}/health || exit 1

EXPOSE {{httpPort}}

ENTRYPOINT ["java", "-jar", "/app/app.jar"]
```

Would you like me to continue with:
1. **Code Generator Implementation** - Complete StandaloneAgentGenerator class
2. **Schema Analyzer** - Analyzes workflow execution order and data flow
3. **REST API** - Designer backend API for saving/loading schemas
4. **Example Usage** - Complete end-to-end examples
5. **Testing Infrastructure** - Unit and integration tests


# Wayang Code Generator - Complete Implementation (Continued)

## Code Generator Implementation

### StandaloneAgentGenerator.java

```java
package io.wayang.codegen;

import io.wayang.codegen.model.*;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.jboss.logging.Logger;

import java.time.Instant;
import java.util.*;
import java.util.stream.Collectors;

/**
 * Main code generator for standalone agents
 */
@ApplicationScoped
public class StandaloneAgentGenerator {
    
    private static final Logger LOG = Logger.getLogger(StandaloneAgentGenerator.class);
    
    @Inject
    SchemaAnalyzer schemaAnalyzer;
    
    @Inject
    DependencyAnalyzer dependencyAnalyzer;
    
    @Inject
    TemplateEngine templateEngine;
    
    @Inject
    CodeOptimizer codeOptimizer;
    
    /**
     * Generate complete standalone agent from workflow schema
     */
    public GeneratedArtifact generate(WorkflowSchema schema, GenerationConfig config) {
        LOG.infof("Generating standalone agent for workflow: %s", schema.getName());
        
        try {
            // 1. Analyze schema
            SchemaAnalysis analysis = schemaAnalyzer.analyze(schema);
            validateSchema(analysis);
            
            // 2. Analyze dependencies
            DependencyGraph dependencies = dependencyAnalyzer.analyze(schema);
            
            // 3. Build template context
            Map<String, Object> context = buildTemplateContext(schema, analysis, dependencies, config);
            
            // 4. Generate artifacts
            GeneratedArtifact artifact = GeneratedArtifact.builder()
                    .workflowId(schema.getId())
                    .workflowName(schema.getName())
                    .timestamp(Instant.now())
                    .build();
            
            // Generate main class
            String mainClass = generateMainClass(context);
            if (config.isOptimize()) {
                mainClass = codeOptimizer.optimize(mainClass);
            }
            artifact.addFile("src/main/java/" + toPath(config.getPackageName()) + 
                           "/" + config.getClassName() + ".java", mainClass);
            
            // Generate POM
            String pom = generatePom(schema, dependencies, config);
            artifact.addFile("pom.xml", pom);
            
            // Generate configuration
            String appProperties = generateConfiguration(context);
            artifact.addFile("src/main/resources/application.properties", appProperties);
            
            // Generate Dockerfile
            if (config.isGenerateDocker()) {
                String dockerfile = generateDockerfile(context);
                artifact.addFile("Dockerfile", dockerfile);
                
                String dockerCompose = generateDockerCompose(context);
                artifact.addFile("docker-compose.yml", dockerCompose);
            }
            
            // Generate README
            String readme = generateReadme(context);
            artifact.addFile("README.md", readme);
            
            // Generate .gitignore
            artifact.addFile(".gitignore", generateGitignore());
            
            // Generate build scripts
            if (config.isGenerateBuildScripts()) {
                artifact.addFile("build.sh", generateBuildScript("sh"));
                artifact.addFile("build.bat", generateBuildScript("bat"));
            }
            
            LOG.infof("Successfully generated %d files", artifact.getFiles().size());
            
            return artifact;
            
        } catch (Exception e) {
            LOG.error("Code generation failed", e);
            throw new CodeGenerationException("Failed to generate agent", e);
        }
    }
    
    /**
     * Build complete template context
     */
    private Map<String, Object> buildTemplateContext(WorkflowSchema schema,
                                                     SchemaAnalysis analysis,
                                                     DependencyGraph dependencies,
                                                     GenerationConfig config) {
        Map<String, Object> context = new HashMap<>();
        
        // Basic info
        context.put("workflowId", schema.getId());
        context.put("workflowName", schema.getName());
        context.put("workflowDescription", schema.getDescription());
        context.put("agentName", config.getArtifactId());
        context.put("timestamp", Instant.now().toString());
        
        // Package and class
        context.put("packageName", config.getPackageName());
        context.put("className", config.getClassName());
        context.put("groupId", config.getGroupId());
        context.put("artifactId", config.getArtifactId());
        context.put("version", config.getVersion());
        
        // Java and framework versions
        context.put("javaVersion", config.getJavaVersion());
        context.put("quarkusVersion", config.getQuarkusVersion());
        context.put("wayangVersion", config.getWayangVersion());
        
        // Dependencies
        context.put("dependencies", dependencies.getAllDependenciesGrouped());
        
        // Nodes
        context.put("nodes", buildNodeContext(schema.getNodes()));
        context.put("isSingleNode", schema.getNodes().size() == 1);
        
        // Execution steps
        if (schema.getNodes().size() > 1) {
            context.put("executionSteps", buildExecutionSteps(analysis));
            context.put("hasOrchestration", true);
        } else {
            context.put("singleNodeField", toFieldName(schema.getNodes().get(0)));
            context.put("hasOrchestration", false);
        }
        
        // Node fields for injection
        context.put("nodeFields", buildNodeFields(schema.getNodes()));
        
        // Imports
        context.put("imports", buildImports(schema.getNodes()));
        
        // Inputs/outputs
        context.put("inputs", extractWorkflowInputs(schema, analysis));
        context.put("outputs", extractWorkflowOutputs(schema, analysis));
        
        // Configuration flags
        WorkflowSchema.RuntimeConfig runtimeConfig = schema.getRuntimeConfig();
        if (runtimeConfig != null) {
            context.put("enableMetrics", runtimeConfig.isEnableMetrics());
            context.put("enableTracing", runtimeConfig.isEnableTracing());
            context.put("enableHealthCheck", runtimeConfig.isEnableHealthCheck());
            context.put("logLevel", config.getLogLevel());
            context.put("httpPort", config.getHttpPort());
        }
        
        // Node-specific configurations
        addNodeSpecificContext(schema.getNodes(), context);
        
        // Docker
        context.put("enableNativeBuild", config.isEnableNativeBuild());
        
        return context;
    }
    
    /**
     * Build node context for template
     */
    private List<Map<String, Object>> buildNodeContext(List<NodeDefinition> nodes) {
        return nodes.stream()
                .map(node -> {
                    Map<String, Object> nodeCtx = new HashMap<>();
                    nodeCtx.put("id", node.getId());
                    nodeCtx.put("type", node.getType());
                    nodeCtx.put("label", node.getLabel());
                    nodeCtx.put("fieldName", toFieldName(node));
                    return nodeCtx;
                })
                .collect(Collectors.toList());
    }
    
    /**
     * Build node fields for dependency injection
     */
    private List<Map<String, Object>> buildNodeFields(List<NodeDefinition> nodes) {
        return nodes.stream()
                .map(node -> {
                    Map<String, Object> field = new HashMap<>();
                    field.put("type", toNodeClassName(node.getType()));
                    field.put("name", toFieldName(node));
                    return field;
                })
                .collect(Collectors.toList());
    }
    
    /**
     * Build execution steps from analysis
     */
    private List<Map<String, Object>> buildExecutionSteps(SchemaAnalysis analysis) {
        List<Map<String, Object>> steps = new ArrayList<>();
        
        List<NodeDefinition> executionOrder = analysis.getExecutionOrder();
        Map<String, Set<String>> dataFlow = analysis.getDataFlow();
        
        for (int i = 0; i < executionOrder.size(); i++) {
            NodeDefinition node = executionOrder.get(i);
            Map<String, Object> step = new HashMap<>();
            
            step.put("index", i + 1);
            step.put("nodeId", node.getId());
            step.put("nodeName", node.getLabel());
            
            // Build inputs from previous nodes
            List<Map<String, Object>> inputs = new ArrayList<>();
            Set<String> sourceNodes = dataFlow.get(node.getId());
            
            if (sourceNodes != null) {
                for (String sourceId : sourceNodes) {
                    NodeDefinition sourceNode = findNodeById(executionOrder, sourceId);
                    if (sourceNode != null) {
                        for (NodeDefinition.PortDefinition input : node.getInputs()) {
                            Map<String, Object> inputMap = new HashMap<>();
                            inputMap.put("name", input.getName());
                            inputMap.put("source", "executionState.get(\"" + 
                                       sourceId + "_" + input.getName() + "\")");
                            inputs.add(inputMap);
                        }
                    }
                }
            } else if (i == 0) {
                // First node gets inputs from context
                for (NodeDefinition.PortDefinition input : node.getInputs()) {
                    Map<String, Object> inputMap = new HashMap<>();
                    inputMap.put("name", input.getName());
                    inputMap.put("source", "context.getInput(\"" + input.getName() + "\")");
                    inputs.add(inputMap);
                }
            }
            
            step.put("inputs", inputs);
            
            // Build outputs
            List<Map<String, Object>> outputs = new ArrayList<>();
            for (NodeDefinition.PortDefinition output : node.getOutputs()) {
                Map<String, Object> outputMap = new HashMap<>();
                outputMap.put("key", node.getId() + "_" + output.getName());
                outputMap.put("outputName", output.getName());
                outputs.add(outputMap);
            }
            step.put("outputs", outputs);
            
            steps.add(step);
        }
        
        return steps;
    }
    
    /**
     * Build imports based on node types
     */
    private List<String> buildImports(List<NodeDefinition> nodes) {
        Set<String> imports = new LinkedHashSet<>();
        
        for (NodeDefinition node : nodes) {
            switch (node.getType().toLowerCase()) {
                case "rag" -> {
                    imports.add("io.wayang.node.rag.RAGNode");
                    imports.add("io.wayang.service.embedding.EmbeddingService");
                    imports.add("io.wayang.service.vector.VectorStore");
                }
                case "agent" -> {
                    imports.add("io.wayang.node.agent.AgentNode");
                    imports.add("io.wayang.service.llm.LLMService");
                }
                case "tool" -> {
                    imports.add("io.wayang.node.tool.ToolNode");
                    imports.add("io.wayang.service.tool.ToolGateway");
                }
                case "guardrails" -> {
                    imports.add("io.wayang.node.guardrails.GuardrailsNode");
                }
                case "evaluator" -> {
                    imports.add("io.wayang.node.evaluator.EvaluatorNode");
                }
                case "critic" -> {
                    imports.add("io.wayang.node.critic.CriticNode");
                }
                case "memory" -> {
                    imports.add("io.wayang.node.memory.MemoryNode");
                    imports.add("io.wayang.service.memory.MemoryService");
                }
            }
        }
        
        return new ArrayList<>(imports);
    }
    
    /**
     * Add node-specific context for configuration
     */
    private void addNodeSpecificContext(List<NodeDefinition> nodes, Map<String, Object> context) {
        boolean hasRAG = false;
        boolean hasAgent = false;
        boolean hasTool = false;
        boolean hasGuardrails = false;
        
        Map<String, Object> ragConfig = new HashMap<>();
        Map<String, Object> agentConfig = new HashMap<>();
        Map<String, Object> toolConfig = new HashMap<>();
        Map<String, Object> guardrailsConfig = new HashMap<>();
        
        for (NodeDefinition node : nodes) {
            NodeTypeConfig typeConfig = node.getTypeConfig();
            if (typeConfig == null) continue;
            
            switch (node.getType().toLowerCase()) {
                case "rag" -> {
                    hasRAG = true;
                    NodeTypeConfig.RAGConfig rag = typeConfig.getRag();
                    if (rag != null) {
                        ragConfig.put("vectorStore", rag.getVectorStore());
                        ragConfig.put("embeddingProvider", rag.getEmbeddingProvider());
                        ragConfig.put("embeddingModel", rag.getEmbeddingModel());
                        ragConfig.put("chunkSize", rag.getChunkSize());
                        ragConfig.put("chunkOverlap", rag.getChunkOverlap());
                        ragConfig.put("retrievalStrategy", rag.getRetrievalStrategy());
                        ragConfig.put("topK", rag.getTopK());
                        ragConfig.put("enableReranking", rag.isEnableReranking());
                        
                        context.put("isPgVector", "pgvector".equalsIgnoreCase(rag.getVectorStore()));
                        context.put("isMilvus", "milvus".equalsIgnoreCase(rag.getVectorStore()));
                    }
                }
                case "agent" -> {
                    hasAgent = true;
                    NodeTypeConfig.AgentConfig agent = typeConfig.getAgent();
                    if (agent != null) {
                        agentConfig.put("llmProvider", agent.getLlmProvider());
                        agentConfig.put("model", agent.getModel());
                        agentConfig.put("temperature", agent.getTemperature());
                        agentConfig.put("maxTokens", agent.getMaxTokens());
                        agentConfig.put("enableStreaming", agent.isEnableStreaming());
                        
                        context.put("isOllama", "ollama".equalsIgnoreCase(agent.getLlmProvider()));
                        context.put("isOpenAI", "openai".equalsIgnoreCase(agent.getLlmProvider()));
                    }
                }
                case "tool" -> {
                    hasTool = true;
                    NodeTypeConfig.ToolConfig tool = typeConfig.getTool();
                    if (tool != null) {
                        toolConfig.put("timeout", tool.getTimeout());
                        toolConfig.put("retries", tool.getRetries());
                    }
                }
                case "guardrails" -> {
                    hasGuardrails = true;
                    NodeTypeConfig.GuardrailsConfig guardrails = typeConfig.getGuardrails();
                    if (guardrails != null) {
                        guardrailsConfig.put("detectPII", guardrails.isDetectPII());
                        guardrailsConfig.put("detectToxicity", guardrails.isDetectToxicity());
                        guardrailsConfig.put("detectHallucination", guardrails.isDetectHallucination());
                    }
                }
            }
        }
        
        context.put("hasRAGNode", hasRAG);
        context.put("hasAgentNode", hasAgent);
        context.put("hasToolNode", hasTool);
        context.put("hasGuardrailsNode", hasGuardrails);
        
        if (hasRAG) context.put("ragConfig", ragConfig);
        if (hasAgent) context.put("agentConfig", agentConfig);
        if (hasTool) context.put("toolConfig", toolConfig);
        if (hasGuardrails) context.put("guardrailsConfig", guardrailsConfig);
    }
    
    /**
     * Generate main class
     */
    private String generateMainClass(Map<String, Object> context) {
        return templateEngine.render("java/main-class.mustache", context);
    }
    
    /**
     * Generate POM
     */
    private String generatePom(WorkflowSchema schema, DependencyGraph dependencies, GenerationConfig config) {
        Map<String, Object> context = new HashMap<>();
        context.put("groupId", config.getGroupId());
        context.put("artifactId", config.getArtifactId());
        context.put("version", config.getVersion());
        context.put("name", schema.getName());
        context.put("description", schema.getDescription());
        context.put("javaVersion", config.getJavaVersion());
        context.put("quarkusVersion", config.getQuarkusVersion());
        context.put("wayangVersion", config.getWayangVersion());
        context.put("dependencies", dependencies.getAllDependenciesGrouped());
        context.put("enableNativeBuild", config.isEnableNativeBuild());
        
        return templateEngine.render("pom/pom.mustache", context);
    }
    
    /**
     * Generate configuration
     */
    private String generateConfiguration(Map<String, Object> context) {
        return templateEngine.render("config/application.properties.mustache", context);
    }
    
    /**
     * Generate Dockerfile
     */
    private String generateDockerfile(Map<String, Object> context) {
        return templateEngine.render("docker/Dockerfile.mustache", context);
    }
    
    /**
     * Generate docker-compose.yml
     */
    private String generateDockerCompose(Map<String, Object> context) {
        return templateEngine.render("docker/docker-compose.yml.mustache", context);
    }
    
    /**
     * Generate README
     */
    private String generateReadme(Map<String, Object> context) {
        return templateEngine.render("docs/README.mustache", context);
    }
    
    /**
     * Generate .gitignore
     */
    private String generateGitignore() {
        return """
                target/
                .idea/
                *.iml
                .vscode/
                .DS_Store
                *.log
                .quarkus/
                """;
    }
    
    /**
     * Generate build script
     */
    private String generateBuildScript(String type) {
        if ("sh".equals(type)) {
            return """
                    #!/bin/bash
                    echo "Building agent..."
                    mvn clean package
                    echo "Build complete!"
                    """;
        } else {
            return """
                    @echo off
                    echo Building agent...
                    mvn clean package
                    echo Build complete!
                    """;
        }
    }
    
    // Helper methods
    
    private void validateSchema(SchemaAnalysis analysis) {
        if (analysis.getErrors().size() > 0) {
            throw new CodeGenerationException("Schema validation failed: " + 
                                            String.join(", ", analysis.getErrors()));
        }
    }
    
    private String toPath(String packageName) {
        return packageName.replace('.', '/');
    }
    
    private String toFieldName(NodeDefinition node) {
        String name = node.getLabel().replaceAll("[^a-zA-Z0-9]", "");
        return Character.toLowerCase(name.charAt(0)) + name.substring(1) + "Node";
    }
    
    private String toNodeClassName(String nodeType) {
        return nodeType.substring(0, 1).toUpperCase() + 
               nodeType.substring(1).toLowerCase() + "Node";
    }
    
    private NodeDefinition findNodeById(List<NodeDefinition> nodes, String id) {
        return nodes.stream()
                .filter(n -> n.getId().equals(id))
                .findFirst()
                .orElse(null);
    }
    
    private List<Map<String, Object>> extractWorkflowInputs(WorkflowSchema schema, SchemaAnalysis analysis) {
        // Extract inputs from first node in execution order
        if (analysis.getExecutionOrder().isEmpty()) {
            return Collections.emptyList();
        }
        
        NodeDefinition firstNode = analysis.getExecutionOrder().get(0);
        return firstNode.getInputs().stream()
                .map(input -> {
                    Map<String, Object> inputMap = new HashMap<>();
                    inputMap.put("name", input.getName());
                    inputMap.put("type", input.getDataType());
                    inputMap.put("required", input.isRequired());
                    return inputMap;
                })
                .collect(Collectors.toList());
    }
    
    private List<Map<String, Object>> extractWorkflowOutputs(WorkflowSchema schema, SchemaAnalysis analysis) {
        // Extract outputs from last node in execution order
        if (analysis.getExecutionOrder().isEmpty()) {
            return Collections.emptyList();
        }
        
        NodeDefinition lastNode = analysis.getExecutionOrder().get(analysis.getExecutionOrder().size() - 1);
        return lastNode.getOutputs().stream()
                .map(output -> {
                    Map<String, Object> outputMap = new HashMap<>();
                    outputMap.put("name", output.getName());
                    outputMap.put("type", output.getDataType());
                    return outputMap;
                })
                .collect(Collectors.toList());
    }
}
```

## Schema Analyzer

### SchemaAnalyzer.java

```java
package io.wayang.codegen;

import io.wayang.codegen.model.*;
import jakarta.enterprise.context.ApplicationScoped;
import org.jboss.logging.Logger;

import java.util.*;
import java.util.stream.Collectors;

/**
 * Analyzes workflow schema for execution order and data flow
 */
@ApplicationScoped
public class SchemaAnalyzer {
    
    private static final Logger LOG = Logger.getLogger(SchemaAnalyzer.class);
    
    /**
     * Analyze workflow schema
     */
    public SchemaAnalysis analyze(WorkflowSchema schema) {
        LOG.infof("Analyzing schema: %s", schema.getName());
        
        SchemaAnalysis analysis = new SchemaAnalysis();
        
        // Validate basic structure
        validateBasicStructure(schema, analysis);
        
        if (!analysis.hasErrors()) {
            // Build dependency graph
            Map<String, Set<String>> dependencyGraph = buildDependencyGraph(schema);
            
            // Determine execution order (topological sort)
            List<NodeDefinition> executionOrder = determineExecutionOrder(schema, dependencyGraph);
            analysis.setExecutionOrder(executionOrder);
            
            // Analyze data flow
            Map<String, Set<String>> dataFlow = analyzeDataFlow(schema);
            analysis.setDataFlow(dataFlow);
            
            // Detect cycles
            if (hasCycle(dependencyGraph)) {
                analysis.addError("Workflow contains cycles");
            }
            
            // Validate connections
            validateConnections(schema, analysis);
        }
        
        LOG.infof("Analysis complete. Errors: %d, Warnings: %d", 
                 analysis.getErrors().size(), analysis.getWarnings().size());
        
        return analysis;
    }
    
    /**
     * Validate basic schema structure
     */
    private void validateBasicStructure(WorkflowSchema schema, SchemaAnalysis analysis) {
        // Check nodes
        if (schema.getNodes() == null || schema.getNodes().isEmpty()) {
            analysis.addError("Workflow must have at least one node");
            return;
        }
        
        // Check for duplicate node IDs
        Set<String> nodeIds = new HashSet<>();
        for (NodeDefinition node : schema.getNodes()) {
            if (!nodeIds.add(node.getId())) {
                analysis.addError("Duplicate node ID: " + node.getId());
            }
            
            // Validate node type
            if (node.getType() == null || node.getType().isBlank()) {
                analysis.addError("Node " + node.getId() + " has no type");
            }
        }
        
        // Check edges reference valid nodes
        if (schema.getEdges() != null) {
            for (EdgeDefinition edge : schema.getEdges()) {
                if (!nodeIds.contains(edge.getSourceId())) {
                    analysis.addError("Edge references unknown source node: " + edge.getSourceId());
                }
                if (!nodeIds.contains(edge.getTargetId())) {
                    analysis.addError("Edge references unknown target node: " + edge.getTargetId());
                }
            }
        }
    }
    
    /**
     * Build dependency graph from edges
     */
    private Map<String, Set<String>> buildDependencyGraph(WorkflowSchema schema) {
        Map<String, Set<String>> graph = new HashMap<>();
        
        // Initialize all nodes
        for (NodeDefinition node : schema.getNodes()) {
            graph.putIfAbsent(node.getId(), new HashSet<>());
        }
        
        // Add edges
        if (schema.getEdges() != null) {
            for (EdgeDefinition edge : schema.getEdges()) {
                graph.computeIfAbsent(edge.getTargetId(), k -> new HashSet<>())
                     .add(edge.getSourceId());
            }
        }
        
        return graph;
    }
    
    /**
     * Determine execution order using topological sort
     */
    private List<NodeDefinition> determineExecutionOrder(WorkflowSchema schema,
                                                         Map<String, Set<String>> dependencyGraph) {
        List<NodeDefinition> order = new ArrayList<>();
        Set<String> visited = new HashSet<>();
        Set<String> visiting = new HashSet<>();
        
        Map<String, NodeDefinition> nodeMap = schema.getNodes().stream()
                .collect(Collectors.toMap(NodeDefinition::getId, n -> n));
        
        // Find nodes with no dependencies (start nodes)
        List<String> startNodes = dependencyGraph.entrySet().stream()
                .filter(e -> e.getValue().isEmpty())
                .map(Map.Entry::getKey)
                .collect(Collectors.toList());
        
        // If no start nodes, use all nodes (single node or disconnected graph)
        if (startNodes.isEmpty()) {
            startNodes = new ArrayList<>(nodeMap.keySet());
        }
        
        // DFS from each start node
        for (String startNode : startNodes) {
            if (!visited.contains(startNode)) {
                topologicalSort(startNode, dependencyGraph, nodeMap, visited, visiting, order);
            }
        }
        
        // Reverse to get correct execution order
        Collections.reverse(order);
        
        return order;
    }
    
    /**
     * Topological sort helper (DFS)
     */
    private void topologicalSort(String nodeId,
                                 Map<String, Set<String>> graph,
                                 Map<String, NodeDefinition> nodeMap,
                                 Set<String> visited,
                                 Set<String> visiting,
                                 List<NodeDefinition> order) {
        visiting.add(nodeId);
        
        Set<String> dependencies = graph.get(nodeId);
        if (dependencies != null) {
            for (String depId : dependencies) {
                if (!visited.contains(depId)) {
                    topologicalSort(depId, graph, nodeMap, visited, visiting, order);
                }
            }
        }
        
        visiting.remove(nodeId);
        visited.add(nodeId);
        order.add(nodeMap.get(nodeId));
    }
    
    /**
     * Analyze data flow between nodes
     */
    private Map<String, Set<String>> analyzeDataFlow(WorkflowSchema schema) {
        Map<String, Set<String>> dataFlow = new HashMap<>();
        
        if (schema.getEdges() != null) {
            for (EdgeDefinition edge : schema.getEdges()) {
                dataFlow.computeIfAbsent(edge.getTargetId(), k -> new HashSet<>())
                       .add(edge.getSourceId());
            }
        }
        
        return dataFlow;
    }
    
    /**
     * Detect cycles in dependency graph
     */
    private boolean hasCycle(Map<String, Set<String>> graph) {
        Set<String> visited = new HashSet<>();
        Set<String> recursionStack = new HashSet<>();
        
        for (String node : graph.keySet()) {
            if (hasCycleUtil(node, graph, visited, recursionStack)) {
                return true;
            }
        }
        
        return false;
    }
    
    private boolean hasCycleUtil(String node,
                                 Map<String, Set<String>> graph,
                                 Set<String> visited,
                                 Set<String> recursionStack) {
        if (recursionStack.contains(node)) {
            return true;
        }
        
        if (visited.contains(node)) {
            return false;
        }
        
        visited.add(node);
        recursionStack.add(node);
        
        Set<String> dependencies = graph.get(node);
        if (dependencies != null) {
            for (String dep : dependencies) {
                if (hasCycleUtil(dep, graph, visited, recursionStack)) {
                    return true;
                }
            }
        }
        
        recursionStack.remove(node);
        return false;
    }
    
    /**
     * Validate node connections
     */
    private void validateConnections(WorkflowSchema schema, SchemaAnalysis analysis) {
        // Build map of edges by source port
        Map<String, List<EdgeDefinition>> edgesBySource = new HashMap<>();
        
        if (schema.getEdges() != null) {
            for (EdgeDefinition edge : schema.getEdges()) {
                String key = edge.getSourceId() + ":" + edge.getSourcePort();
                edgesBySource.computeIfAbsent(key, k -> new ArrayList<>()).add(edge);
            }
        }
        
        // Check data type compatibility
        Map<String, NodeDefinition> nodeMap = schema.getNodes().stream()
                .collect(Collectors.toMap(NodeDefinition::getId, n -> n));
        
        if (schema.getEdges() != null) {
            for (EdgeDefinition edge : schema.getEdges()) {
                NodeDefinition sourceNode = nodeMap.get(edge.getSourceId());
                NodeDefinition targetNode = nodeMap.get(edge.getTargetId());
                
                if (sourceNode != null && targetNode != null) {
                    validatePortConnection(sourceNode, targetNode, edge, analysis);
                }
            }
        }
    }
    
    private void validatePortConnection(NodeDefinition sourceNode,
                                       NodeDefinition targetNode,
                                       EdgeDefinition edge,
                                       SchemaAnalysis analysis) {
        // Find source output port
        Optional<NodeDefinition.PortDefinition> sourcePort = sourceNode.getOutputs().stream()
                .filter(p -> p.getId().equals(edge.getSourcePort()))
                .findFirst();
        
        // Find target input port
        Optional<NodeDefinition.PortDefinition> targetPort = targetNode.getInputs().stream()
                .filter(p -> p.getId().equals(edge.getTargetPort()))
                .findFirst();
        
        if (sourcePort.isEmpty()) {
            analysis.addWarning("Source port not found: " + edge.getSourcePort() + 
                              " on node " + sourceNode.getLabel());
        }
        
        if (targetPort.isEmpty()) {
            analysis.addWarning("Target port not found: " + edge.getTargetPort() + 
                              " on node " + targetNode.






