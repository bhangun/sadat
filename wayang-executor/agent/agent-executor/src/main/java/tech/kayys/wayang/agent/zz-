package tech.kayys.silat.agent.core;

import java.time.Instant;
import java.util.*;
import java.util.concurrent.CopyOnWriteArrayList;

/**
 * ============================================================================
 * AGENT CORE DOMAIN MODELS
 * ============================================================================
 * 
 * Core domain objects for agent execution including:
 * - AgentConfiguration: Agent settings and parameters
 * - AgentContext: Runtime execution context
 * - Message: Chat messages with roles
 * - LLMRequest/Response: LLM interaction objects
 * - ToolCall/ToolResult: Tool execution objects
 * - AgentExecutionResult: Final execution outcome
 */

// ==================== AGENT CONFIGURATION ====================

/**
 * Complete configuration for an agent instance
 * Immutable configuration object built via builder pattern
 */
public record AgentConfiguration(
    String agentId,
    String tenantId,
    String runId,
    String llmProvider,
    String llmModel,
    Double temperature,
    Integer maxTokens,
    boolean memoryEnabled,
    String memoryType,
    Integer memoryWindowSize,
    List<String> enabledTools,
    boolean allowToolCalls,
    String systemPrompt,
    boolean streaming,
    Integer maxIterations,
    Map<String, Object> additionalConfig
) {
    
    public AgentConfiguration {
        // Defensive copies for mutable fields
        enabledTools = List.copyOf(enabledTools != null ? enabledTools : List.of());
        additionalConfig = Map.copyOf(additionalConfig != null ? additionalConfig : Map.of());
    }

    public static Builder builder() {
        return new Builder();
    }

    public static class Builder {
        private String agentId;
        private String tenantId;
        private String runId;
        private String llmProvider = "openai";
        private String llmModel = "gpt-4";
        private Double temperature = 0.7;
        private Integer maxTokens = 2000;
        private boolean memoryEnabled = true;
        private String memoryType = "buffer";
        private Integer memoryWindowSize = 10;
        private List<String> enabledTools = new ArrayList<>();
        private boolean allowToolCalls = true;
        private String systemPrompt = "You are a helpful AI assistant.";
        private boolean streaming = false;
        private Integer maxIterations = 5;
        private Map<String, Object> additionalConfig = new HashMap<>();

        public Builder agentId(String agentId) {
            this.agentId = agentId;
            return this;
        }

        public Builder tenantId(String tenantId) {
            this.tenantId = tenantId;
            return this;
        }

        public Builder runId(String runId) {
            this.runId = runId;
            return this;
        }

        public Builder llmProvider(String llmProvider) {
            this.llmProvider = llmProvider;
            return this;
        }

        public Builder llmModel(String llmModel) {
            this.llmModel = llmModel;
            return this;
        }

        public Builder temperature(Double temperature) {
            this.temperature = temperature;
            return this;
        }

        public Builder maxTokens(Integer maxTokens) {
            this.maxTokens = maxTokens;
            return this;
        }

        public Builder memoryEnabled(boolean memoryEnabled) {
            this.memoryEnabled = memoryEnabled;
            return this;
        }

        public Builder memoryType(String memoryType) {
            this.memoryType = memoryType;
            return this;
        }

        public Builder memoryWindowSize(Integer memoryWindowSize) {
            this.memoryWindowSize = memoryWindowSize;
            return this;
        }

        public Builder enabledTools(List<String> enabledTools) {
            this.enabledTools = new ArrayList<>(enabledTools != null ? enabledTools : List.of());
            return this;
        }

        public Builder allowToolCalls(boolean allowToolCalls) {
            this.allowToolCalls = allowToolCalls;
            return this;
        }

        public Builder systemPrompt(String systemPrompt) {
            this.systemPrompt = systemPrompt;
            return this;
        }

        public Builder streaming(boolean streaming) {
            this.streaming = streaming;
            return this;
        }

        public Builder maxIterations(Integer maxIterations) {
            this.maxIterations = maxIterations;
            return this;
        }

        public Builder additionalConfig(Map<String, Object> additionalConfig) {
            this.additionalConfig = new HashMap<>(additionalConfig);
            return this;
        }

        public Builder config(String key, Object value) {
            this.additionalConfig.put(key, value);
            return this;
        }

        public AgentConfiguration build() {
            return new AgentConfiguration(
                agentId, tenantId, runId, llmProvider, llmModel,
                temperature, maxTokens, memoryEnabled, memoryType,
                memoryWindowSize, enabledTools, allowToolCalls,
                systemPrompt, streaming, maxIterations, additionalConfig
            );
        }
    }
}

// ==================== AGENT CONTEXT ====================

/**
 * Runtime context for agent execution
 * Mutable object that accumulates state during execution
 */
public class AgentContext {
    private final String sessionId;
    private final String runId;
    private final String nodeId;
    private final String tenantId;
    private final AgentConfiguration configuration;
    private final Map<String, Object> taskContext;
    
    // Mutable execution state
    private List<Message> memory;
    private final List<Message> messages;
    private List<tech.kayys.silat.agent.tools.Tool> tools;
    private final Map<String, Object> metadata;

    private AgentContext(Builder builder) {
        this.sessionId = builder.sessionId;
        this.runId = builder.runId;
        this.nodeId = builder.nodeId;
        this.tenantId = builder.tenantId;
        this.configuration = builder.configuration;
        this.taskContext = new HashMap<>(builder.taskContext);
        this.memory = new ArrayList<>();
        this.messages = new CopyOnWriteArrayList<>();
        this.tools = new ArrayList<>();
        this.metadata = new HashMap<>();
    }

    public static Builder builder() {
        return new Builder();
    }

    public String sessionId() { return sessionId; }
    public String runId() { return runId; }
    public String nodeId() { return nodeId; }
    public String tenantId() { return tenantId; }
    public AgentConfiguration configuration() { return configuration; }
    public Map<String, Object> taskContext() { return taskContext; }

    // Memory management
    public boolean hasMemory() { return memory != null && !memory.isEmpty(); }
    public List<Message> getMemory() { return new ArrayList<>(memory); }
    public void setMemory(List<Message> memory) { this.memory = new ArrayList<>(memory); }

    // Message management
    public List<Message> getMessages() { return new ArrayList<>(messages); }
    public void addMessage(Message message) { messages.add(message); }
    public void addMessage(LLMResponse response) { 
        messages.add(Message.assistant(
            response.content(),
            response.toolCalls()
        ));
    }
    public void addToolResult(ToolResult result) {
        messages.add(Message.tool(result.id(), result.output()));
    }

    // Tool management
    public boolean hasTools() { return tools != null && !tools.isEmpty(); }
    public List<tech.kayys.silat.agent.tools.Tool> getTools() { return new ArrayList<>(tools); }
    public void setTools(List<tech.kayys.silat.agent.tools.Tool> tools) { 
        this.tools = new ArrayList<>(tools); 
    }

    // Metadata
    public void setMetadata(String key, Object value) { metadata.put(key, value); }
    public Object getMetadata(String key) { return metadata.get(key); }
    public Map<String, Object> getAllMetadata() { return new HashMap<>(metadata); }

    public static class Builder {
        private String sessionId;
        private String runId;
        private String nodeId;
        private String tenantId;
        private AgentConfiguration configuration;
        private Map<String, Object> taskContext = Map.of();

        public Builder sessionId(String sessionId) {
            this.sessionId = sessionId;
            return this;
        }

        public Builder runId(String runId) {
            this.runId = runId;
            return this;
        }

        public Builder nodeId(String nodeId) {
            this.nodeId = nodeId;
            return this;
        }

        public Builder tenantId(String tenantId) {
            this.tenantId = tenantId;
            return this;
        }

        public Builder configuration(AgentConfiguration configuration) {
            this.configuration = configuration;
            return this;
        }

        public Builder taskContext(Map<String, Object> taskContext) {
            this.taskContext = taskContext;
            return this;
        }

        public AgentContext build() {
            return new AgentContext(this);
        }
    }
}

// ==================== MESSAGE ====================

/**
 * Represents a chat message with role and content
 * Supports tool calls and tool results
 */
public record Message(
    String role,
    String content,
    List<ToolCall> toolCalls,
    String toolCallId,
    Instant timestamp
) {
    
    public Message {
        toolCalls = toolCalls != null ? List.copyOf(toolCalls) : null;
        timestamp = timestamp != null ? timestamp : Instant.now();
    }

    public static Message system(String content) {
        return new Message("system", content, null, null, Instant.now());
    }

    public static Message user(String content) {
        return new Message("user", content, null, null, Instant.now());
    }

    public static Message assistant(String content) {
        return new Message("assistant", content, null, null, Instant.now());
    }

    public static Message assistant(String content, List<ToolCall> toolCalls) {
        return new Message("assistant", content, toolCalls, null, Instant.now());
    }

    public static Message tool(String toolCallId, String content) {
        return new Message("tool", content, null, toolCallId, Instant.now());
    }

    public boolean hasToolCalls() {
        return toolCalls != null && !toolCalls.isEmpty();
    }

    public boolean isSystem() { return "system".equals(role); }
    public boolean isUser() { return "user".equals(role); }
    public boolean isAssistant() { return "assistant".equals(role); }
    public boolean isTool() { return "tool".equals(role); }
}

// ==================== LLM REQUEST ====================

/**
 * Request to LLM provider
 */
public record LLMRequest(
    String provider,
    String model,
    List<Message> messages,
    Double temperature,
    Integer maxTokens,
    List<ToolDefinition> tools,
    boolean streaming,
    Map<String, Object> additionalParams
) {
    
    public LLMRequest {
        messages = List.copyOf(messages);
        tools = tools != null ? List.copyOf(tools) : List.of();
        additionalParams = additionalParams != null ? 
            Map.copyOf(additionalParams) : Map.of();
    }

    public static Builder builder() {
        return new Builder();
    }

    public static class Builder {
        private String provider;
        private String model;
        private List<Message> messages = List.of();
        private Double temperature = 0.7;
        private Integer maxTokens = 2000;
        private List<ToolDefinition> tools = List.of();
        private boolean streaming = false;
        private Map<String, Object> additionalParams = Map.of();

        public Builder provider(String provider) {
            this.provider = provider;
            return this;
        }

        public Builder model(String model) {
            this.model = model;
            return this;
        }

        public Builder messages(List<Message> messages) {
            this.messages = new ArrayList<>(messages);
            return this;
        }

        public Builder temperature(Double temperature) {
            this.temperature = temperature;
            return this;
        }

        public Builder maxTokens(Integer maxTokens) {
            this.maxTokens = maxTokens;
            return this;
        }

        public Builder tools(List<ToolDefinition> tools) {
            this.tools = new ArrayList<>(tools);
            return this;
        }

        public Builder streaming(boolean streaming) {
            this.streaming = streaming;
            return this;
        }

        public Builder additionalParams(Map<String, Object> additionalParams) {
            this.additionalParams = new HashMap<>(additionalParams);
            return this;
        }

        public LLMRequest build() {
            return new LLMRequest(
                provider, model, messages, temperature, maxTokens,
                tools, streaming, additionalParams
            );
        }
    }
}

// ==================== LLM RESPONSE ====================

/**
 * Response from LLM provider
 */
public record LLMResponse(
    String content,
    String finishReason,
    List<ToolCall> toolCalls,
    TokenUsage usage,
    Map<String, Object> metadata
) {
    
    public LLMResponse {
        toolCalls = toolCalls != null ? List.copyOf(toolCalls) : List.of();
        metadata = metadata != null ? Map.copyOf(metadata) : Map.of();
    }

    public boolean hasToolCalls() {
        return toolCalls != null && !toolCalls.isEmpty();
    }

    public static LLMResponse create(
            String content,
            String finishReason,
            TokenUsage usage) {
        return new LLMResponse(content, finishReason, List.of(), usage, Map.of());
    }

    public static LLMResponse withToolCalls(
            String content,
            List<ToolCall> toolCalls,
            TokenUsage usage) {
        return new LLMResponse(content, "tool_calls", toolCalls, usage, Map.of());
    }
}

// ==================== TOKEN USAGE ====================

/**
 * Token usage statistics
 */
public record TokenUsage(
    int promptTokens,
    int completionTokens,
    int totalTokens
) {
    
    public Map<String, Object> toMap() {
        return Map.of(
            "promptTokens", promptTokens,
            "completionTokens", completionTokens,
            "totalTokens", totalTokens
        );
    }

    public static TokenUsage of(int promptTokens, int completionTokens) {
        return new TokenUsage(
            promptTokens,
            completionTokens,
            promptTokens + completionTokens
        );
    }
}

// ==================== TOOL CALL ====================

/**
 * Tool call requested by LLM
 */
public record ToolCall(
    String id,
    String name,
    Map<String, Object> arguments
) {
    
    public ToolCall {
        arguments = Map.copyOf(arguments != null ? arguments : Map.of());
    }

    public static ToolCall create(String id, String name, Map<String, Object> arguments) {
        return new ToolCall(id, name, arguments);
    }
}

// ==================== TOOL RESULT ====================

/**
 * Result of tool execution
 */
public record ToolResult(
    String id,
    String name,
    String output,
    boolean success,
    String error,
    Map<String, Object> metadata
) {
    
    public ToolResult {
        metadata = metadata != null ? Map.copyOf(metadata) : Map.of();
    }

    public static ToolResult success(String id, String name, String output) {
        return new ToolResult(id, name, output, true, null, Map.of());
    }

    public static ToolResult error(String id, String name, String error) {
        return new ToolResult(id, name, null, false, error, Map.of());
    }
}

// ==================== TOOL DEFINITION ====================

/**
 * Tool definition for LLM function calling
 */
public record ToolDefinition(
    String name,
    String description,
    Map<String, Object> parameters
) {
    
    public ToolDefinition {
        parameters = Map.copyOf(parameters != null ? parameters : Map.of());
    }

    public static ToolDefinition create(
            String name,
            String description,
            Map<String, Object> parameters) {
        return new ToolDefinition(name, description, parameters);
    }
}

// ==================== AGENT EXECUTION RESULT ====================

/**
 * Final result of agent execution
 */
public record AgentExecutionResult(
    LLMResponse finalResponse,
    List<Message> messages,
    int iterations,
    boolean maxIterationsReached,
    Map<String, Object> metadata
) {
    
    public AgentExecutionResult {
        messages = List.copyOf(messages != null ? messages : List.of());
        metadata = Map.copyOf(metadata != null ? metadata : Map.of());
    }

    public static AgentExecutionResult completed(
            LLMResponse finalResponse,
            List<Message> messages,
            int iterations) {
        return new AgentExecutionResult(
            finalResponse,
            messages,
            iterations,
            false,
            Map.of()
        );
    }

    public static AgentExecutionResult maxIterationsReached(
            List<Message> messages,
            int iterations) {
        return new AgentExecutionResult(
            null,
            messages,
            iterations,
            true,
            Map.of("reason", "max_iterations_reached")
        );
    }

    public boolean hadToolCalls() {
        return messages.stream().anyMatch(Message::hasToolCalls);
    }

    public int countToolCalls() {
        return messages.stream()
            .filter(Message::hasToolCalls)
            .mapToInt(m -> m.toolCalls().size())
            .sum();
    }
}

package tech.kayys.silat.agent.memory;

import io.smallrye.mutiny.Uni;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import tech.kayys.silat.agent.core.Message;

import java.time.Instant;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.stream.Collectors;

/**
 * ============================================================================
 * AGENT MEMORY MANAGEMENT SYSTEM
 * ============================================================================
 * 
 * Provides multi-strategy memory management for agents:
 * 
 * Memory Types:
 * 1. Buffer Memory: Simple FIFO buffer with window size
 * 2. Summary Memory: Maintains conversation summaries
 * 3. Vector Memory: Semantic search over conversation history
 * 4. Entity Memory: Tracks entities mentioned in conversation
 * 
 * Storage:
 * - Short-term: In-memory cache for active sessions
 * - Long-term: Database persistence for conversation history
 * - Vector: Vector database for semantic retrieval
 * 
 * Architecture:
 * ┌────────────────────────────────────────────────────────┐
 * │           AgentMemoryManager                           │
 * ├────────────────────────────────────────────────────────┤
 * │  ┌──────────┐  ┌──────────┐  ┌─────────┐  ┌────────┐ │
 * │  │  Buffer  │  │ Summary  │  │ Vector  │  │ Entity │ │
 * │  │  Memory  │  │  Memory  │  │ Memory  │  │ Memory │ │
 * │  └──────────┘  └──────────┘  └─────────┘  └────────┘ │
 * │       │             │              │           │       │
 * │  ┌────▼─────────────▼──────────────▼───────────▼───┐ │
 * │  │          Memory Storage Backend                 │ │
 * │  │  (Cache + Database + Vector Store)              │ │
 * │  └──────────────────────────────────────────────────┘ │
 * └────────────────────────────────────────────────────────┘
 */

// ==================== MEMORY MANAGER INTERFACE ====================

/**
 * Main interface for agent memory operations
 */
public interface AgentMemoryManager {
    
    /**
     * Load memory for a session
     */
    Uni<List<Message>> loadMemory(
        String sessionId,
        String tenantId,
        String memoryType,
        Integer windowSize
    );
    
    /**
     * Save messages to memory
     */
    Uni<Void> saveMessages(
        String sessionId,
        String tenantId,
        List<Message> messages
    );
    
    /**
     * Clear memory for a session
     */
    Uni<Void> clearMemory(String sessionId, String tenantId);
    
    /**
     * Search memory semantically (for vector memory)
     */
    Uni<List<Message>> searchMemory(
        String sessionId,
        String tenantId,
        String query,
        int limit
    );
    
    /**
     * Get memory statistics
     */
    Uni<MemoryStats> getStats(String sessionId, String tenantId);
}

// ==================== MEMORY MANAGER IMPLEMENTATION ====================

@ApplicationScoped
public class DefaultAgentMemoryManager implements AgentMemoryManager {
    
    private static final Logger LOG = LoggerFactory.getLogger(DefaultAgentMemoryManager.class);
    
    @Inject
    MemoryStorageService storageService;
    
    @Inject
    MemoryStrategyFactory strategyFactory;
    
    @Inject
    MemoryCache memoryCache;

    @Override
    public Uni<List<Message>> loadMemory(
            String sessionId,
            String tenantId,
            String memoryType,
            Integer windowSize) {
        
        LOG.debug("Loading memory: session={}, type={}, window={}", 
            sessionId, memoryType, windowSize);

        // Try cache first
        return memoryCache.get(sessionId, tenantId)
            .flatMap(cached -> {
                if (cached != null && !cached.isEmpty()) {
                    LOG.debug("Memory loaded from cache: {} messages", cached.size());
                    return Uni.createFrom().item(cached);
                }
                
                // Load from storage
                return loadFromStorage(sessionId, tenantId, memoryType, windowSize);
            });
    }

    private Uni<List<Message>> loadFromStorage(
            String sessionId,
            String tenantId,
            String memoryType,
            Integer windowSize) {
        
        return strategyFactory.getStrategy(memoryType)
            .flatMap(strategy -> 
                storageService.loadMessages(sessionId, tenantId)
                    .map(messages -> strategy.process(messages, windowSize))
            )
            .onItem().invoke(messages -> {
                // Update cache
                memoryCache.put(sessionId, tenantId, messages);
                LOG.debug("Memory loaded from storage: {} messages", messages.size());
            })
            .onFailure().recoverWithItem(error -> {
                LOG.error("Failed to load memory: {}", error.getMessage());
                return List.of();
            });
    }

    @Override
    public Uni<Void> saveMessages(
            String sessionId,
            String tenantId,
            List<Message> messages) {
        
        if (messages == null || messages.isEmpty()) {
            return Uni.createFrom().voidItem();
        }

        LOG.debug("Saving {} messages for session: {}", messages.size(), sessionId);

        return storageService.saveMessages(sessionId, tenantId, messages)
            .onItem().invoke(v -> {
                // Update cache
                memoryCache.append(sessionId, tenantId, messages);
                LOG.debug("Messages saved successfully");
            })
            .onFailure().invoke(error -> 
                LOG.error("Failed to save messages: {}", error.getMessage(), error)
            );
    }

    @Override
    public Uni<Void> clearMemory(String sessionId, String tenantId) {
        LOG.info("Clearing memory for session: {}", sessionId);
        
        return storageService.clearMessages(sessionId, tenantId)
            .onItem().invoke(v -> memoryCache.invalidate(sessionId, tenantId));
    }

    @Override
    public Uni<List<Message>> searchMemory(
            String sessionId,
            String tenantId,
            String query,
            int limit) {
        
        LOG.debug("Searching memory: session={}, query={}", sessionId, query);
        
        return storageService.searchMessages(sessionId, tenantId, query, limit);
    }

    @Override
    public Uni<MemoryStats> getStats(String sessionId, String tenantId) {
        return storageService.getMessageCount(sessionId, tenantId)
            .map(count -> new MemoryStats(
                sessionId,
                tenantId,
                count,
                memoryCache.isCached(sessionId, tenantId)
            ));
    }
}

// ==================== MEMORY STRATEGIES ====================

/**
 * Base interface for memory processing strategies
 */
public interface MemoryStrategy {
    
    /**
     * Process raw messages according to strategy
     */
    List<Message> process(List<Message> messages, Integer windowSize);
    
    /**
     * Get strategy type
     */
    String getType();
}

/**
 * Buffer Memory Strategy
 * Simple FIFO window of recent messages
 */
@ApplicationScoped
public class BufferMemoryStrategy implements MemoryStrategy {
    
    private static final Logger LOG = LoggerFactory.getLogger(BufferMemoryStrategy.class);

    @Override
    public List<Message> process(List<Message> messages, Integer windowSize) {
        if (messages == null || messages.isEmpty()) {
            return List.of();
        }

        int window = windowSize != null ? windowSize : 10;
        int startIndex = Math.max(0, messages.size() - window);
        
        List<Message> result = messages.subList(startIndex, messages.size());
        LOG.debug("Buffer memory: {} -> {} messages", messages.size(), result.size());
        
        return new ArrayList<>(result);
    }

    @Override
    public String getType() {
        return "buffer";
    }
}

/**
 * Summary Memory Strategy
 * Maintains summaries of older conversations
 */
@ApplicationScoped
public class SummaryMemoryStrategy implements MemoryStrategy {
    
    private static final Logger LOG = LoggerFactory.getLogger(SummaryMemoryStrategy.class);
    
    @Inject
    LLMSummarizer summarizer;

    @Override
    public List<Message> process(List<Message> messages, Integer windowSize) {
        if (messages == null || messages.isEmpty()) {
            return List.of();
        }

        int window = windowSize != null ? windowSize : 10;
        
        if (messages.size() <= window) {
            return new ArrayList<>(messages);
        }

        // Keep recent messages, summarize older ones
        List<Message> older = messages.subList(0, messages.size() - window);
        List<Message> recent = messages.subList(messages.size() - window, messages.size());
        
        String summary = summarizer.summarize(older);
        
        List<Message> result = new ArrayList<>();
        result.add(Message.system("Previous conversation summary: " + summary));
        result.addAll(recent);
        
        LOG.debug("Summary memory: {} -> {} messages (with summary)", 
            messages.size(), result.size());
        
        return result;
    }

    @Override
    public String getType() {
        return "summary";
    }
}

/**
 * Vector Memory Strategy
 * Uses semantic similarity for retrieval
 */
@ApplicationScoped
public class VectorMemoryStrategy implements MemoryStrategy {
    
    private static final Logger LOG = LoggerFactory.getLogger(VectorMemoryStrategy.class);
    
    @Inject
    VectorSearchService vectorSearch;

    @Override
    public List<Message> process(List<Message> messages, Integer windowSize) {
        // Vector memory typically used with search, not direct loading
        // Return recent messages by default
        int window = windowSize != null ? windowSize : 10;
        int startIndex = Math.max(0, messages.size() - window);
        
        return new ArrayList<>(messages.subList(startIndex, messages.size()));
    }

    @Override
    public String getType() {
        return "vector";
    }
}

/**
 * Entity Memory Strategy
 * Tracks and maintains entity information
 */
@ApplicationScoped
public class EntityMemoryStrategy implements MemoryStrategy {
    
    private static final Logger LOG = LoggerFactory.getLogger(EntityMemoryStrategy.class);
    
    @Inject
    EntityExtractor entityExtractor;

    @Override
    public List<Message> process(List<Message> messages, Integer windowSize) {
        if (messages == null || messages.isEmpty()) {
            return List.of();
        }

        // Extract entities from conversation
        Map<String, String> entities = entityExtractor.extractEntities(messages);
        
        // Create context message with entity information
        if (!entities.isEmpty()) {
            String entityContext = "Known entities: " + 
                entities.entrySet().stream()
                    .map(e -> e.getKey() + "=" + e.getValue())
                    .collect(Collectors.joining(", "));
            
            List<Message> result = new ArrayList<>();
            result.add(Message.system(entityContext));
            
            // Add recent messages
            int window = windowSize != null ? windowSize : 10;
            int startIndex = Math.max(0, messages.size() - window);
            result.addAll(messages.subList(startIndex, messages.size()));
            
            return result;
        }

        // Fallback to buffer strategy
        int window = windowSize != null ? windowSize : 10;
        int startIndex = Math.max(0, messages.size() - window);
        return new ArrayList<>(messages.subList(startIndex, messages.size()));
    }

    @Override
    public String getType() {
        return "entity";
    }
}

// ==================== STRATEGY FACTORY ====================

@ApplicationScoped
public class MemoryStrategyFactory {
    
    private static final Logger LOG = LoggerFactory.getLogger(MemoryStrategyFactory.class);
    
    private final Map<String, MemoryStrategy> strategies = new ConcurrentHashMap<>();
    
    @Inject
    BufferMemoryStrategy bufferStrategy;
    
    @Inject
    SummaryMemoryStrategy summaryStrategy;
    
    @Inject
    VectorMemoryStrategy vectorStrategy;
    
    @Inject
    EntityMemoryStrategy entityStrategy;
    
    @jakarta.annotation.PostConstruct
    void init() {
        registerStrategy(bufferStrategy);
        registerStrategy(summaryStrategy);
        registerStrategy(vectorStrategy);
        registerStrategy(entityStrategy);
        
        LOG.info("Registered {} memory strategies", strategies.size());
    }
    
    public void registerStrategy(MemoryStrategy strategy) {
        strategies.put(strategy.getType(), strategy);
        LOG.debug("Registered memory strategy: {}", strategy.getType());
    }
    
    public Uni<MemoryStrategy> getStrategy(String type) {
        MemoryStrategy strategy = strategies.getOrDefault(type, bufferStrategy);
        return Uni.createFrom().item(strategy);
    }
}

// ==================== MEMORY CACHE ====================

/**
 * In-memory cache for active conversation sessions
 */
@ApplicationScoped
public class MemoryCache {
    
    private static final Logger LOG = LoggerFactory.getLogger(MemoryCache.class);
    private static final int MAX_CACHE_SIZE = 1000;
    private static final long CACHE_TTL_MS = 3600000; // 1 hour
    
    private final Map<String, CacheEntry> cache = new ConcurrentHashMap<>();

    public Uni<List<Message>> get(String sessionId, String tenantId) {
        String key = makeKey(sessionId, tenantId);
        CacheEntry entry = cache.get(key);
        
        if (entry != null && !entry.isExpired()) {
            entry.updateAccessTime();
            LOG.trace("Cache hit: {}", key);
            return Uni.createFrom().item(new ArrayList<>(entry.messages));
        }
        
        LOG.trace("Cache miss: {}", key);
        return Uni.createFrom().nullItem();
    }

    public void put(String sessionId, String tenantId, List<Message> messages) {
        String key = makeKey(sessionId, tenantId);
        
        // Evict old entries if cache is full
        if (cache.size() >= MAX_CACHE_SIZE) {
            evictOldest();
        }
        
        cache.put(key, new CacheEntry(new ArrayList<>(messages)));
        LOG.trace("Cache put: {} ({} messages)", key, messages.size());
    }

    public void append(String sessionId, String tenantId, List<Message> messages) {
        String key = makeKey(sessionId, tenantId);
        CacheEntry entry = cache.get(key);
        
        if (entry != null && !entry.isExpired()) {
            entry.messages.addAll(messages);
            entry.updateAccessTime();
            LOG.trace("Cache append: {} (+{} messages)", key, messages.size());
        } else {
            put(sessionId, tenantId, messages);
        }
    }

    public void invalidate(String sessionId, String tenantId) {
        String key = makeKey(sessionId, tenantId);
        cache.remove(key);
        LOG.trace("Cache invalidated: {}", key);
    }

    public boolean isCached(String sessionId, String tenantId) {
        String key = makeKey(sessionId, tenantId);
        CacheEntry entry = cache.get(key);
        return entry != null && !entry.isExpired();
    }

    private String makeKey(String sessionId, String tenantId) {
        return tenantId + ":" + sessionId;
    }

    private void evictOldest() {
        cache.entrySet().stream()
            .min(Comparator.comparing(e -> e.getValue().lastAccessTime))
            .ifPresent(entry -> {
                cache.remove(entry.getKey());
                LOG.debug("Evicted cache entry: {}", entry.getKey());
            });
    }

    private static class CacheEntry {
        final List<Message> messages;
        long lastAccessTime;
        final long creationTime;

        CacheEntry(List<Message> messages) {
            this.messages = messages;
            this.creationTime = System.currentTimeMillis();
            this.lastAccessTime = creationTime;
        }

        void updateAccessTime() {
            this.lastAccessTime = System.currentTimeMillis();
        }

        boolean isExpired() {
            return System.currentTimeMillis() - creationTime > CACHE_TTL_MS;
        }
    }
}

// ==================== SUPPORTING SERVICES ====================

/**
 * LLM-based conversation summarizer
 */
@ApplicationScoped
public class LLMSummarizer {
    
    private static final Logger LOG = LoggerFactory.getLogger(LLMSummarizer.class);
    
    public String summarize(List<Message> messages) {
        // In real implementation, call LLM to generate summary
        // For now, simple concatenation
        return messages.stream()
            .filter(m -> !m.isSystem())
            .map(m -> m.role() + ": " + truncate(m.content(), 100))
            .collect(Collectors.joining("; "));
    }
    
    private String truncate(String text, int maxLength) {
        if (text == null) return "";
        return text.length() > maxLength ? 
            text.substring(0, maxLength) + "..." : text;
    }
}

/**
 * Vector search service for semantic memory retrieval
 */
@ApplicationScoped
public class VectorSearchService {
    
    private static final Logger LOG = LoggerFactory.getLogger(VectorSearchService.class);
    
    // In real implementation, integrate with vector database
    // (Pinecone, Weaviate, Qdrant, etc.)
    
    public Uni<List<Message>> search(
            String sessionId,
            String tenantId,
            String query,
            int limit) {
        LOG.debug("Vector search: query={}, limit={}", query, limit);
        // Placeholder implementation
        return Uni.createFrom().item(List.of());
    }
}

/**
 * Entity extraction service
 */
@ApplicationScoped
public class EntityExtractor {
    
    private static final Logger LOG = LoggerFactory.getLogger(EntityExtractor.class);
    
    public Map<String, String> extractEntities(List<Message> messages) {
        // In real implementation, use NER or LLM to extract entities
        // For now, simple placeholder
        Map<String, String> entities = new HashMap<>();
        
        // Example: extract email addresses, names, etc.
        for (Message msg : messages) {
            if (msg.content() != null) {
                // Simple email detection
                if (msg.content().contains("@")) {
                    String[] words = msg.content().split("\\s+");
                    for (String word : words) {
                        if (word.contains("@")) {
                            entities.put("email", word);
                        }
                    }
                }
            }
        }
        
        return entities;
    }
}

// ==================== MEMORY STATS ====================

/**
 * Memory statistics
 */
public record MemoryStats(
    String sessionId,
    String tenantId,
    long messageCount,
    boolean cached
) {
    
    public Map<String, Object> toMap() {
        return Map.of(
            "sessionId", sessionId,
            "tenantId", tenantId,
            "messageCount", messageCount,
            "cached", cached
        );
    }
}

package tech.kayys.silat.agent.tools;

import io.smallrye.mutiny.Uni;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import tech.kayys.silat.agent.core.*;

import java.time.Instant;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.stream.Collectors;

/**
 * ============================================================================
 * AGENT TOOLS SYSTEM
 * ============================================================================
 * 
 * Comprehensive tool/function calling system for agents.
 * 
 * Features:
 * - Dynamic tool registration and discovery
 * - Multi-tenant tool isolation
 * - Parameter validation
 * - Async execution
 * - Error handling and retries
 * - Tool metrics and monitoring
 * 
 * Built-in Tools:
 * - Calculator: Mathematical operations
 * - WebSearch: Search the web
 * - DatabaseQuery: Query databases
 * - APICall: Call external APIs
 * - FileOperation: Read/write files
 * - CodeExecutor: Execute code snippets
 * 
 * Architecture:
 * ┌─────────────────────────────────────────────────────────┐
 * │                  Tool Registry                          │
 * ├─────────────────────────────────────────────────────────┤
 * │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌────────┐ │
 * │  │Calculator│  │WebSearch │  │Database  │  │ Custom │ │
 * │  │   Tool   │  │   Tool   │  │  Query   │  │  Tool  │ │
 * │  └──────────┘  └──────────┘  └──────────┘  └────────┘ │
 * │       │             │              │            │       │
 * │  ┌────▼─────────────▼──────────────▼────────────▼───┐ │
 * │  │         Tool Execution Engine                    │ │
 * │  └──────────────────────────────────────────────────┘ │
 * └─────────────────────────────────────────────────────────┘
 */

// ==================== TOOL INTERFACE ====================

/**
 * Base interface for all agent tools
 */
public interface Tool {
    
    /**
     * Get tool name (must be unique per tenant)
     */
    String name();
    
    /**
     * Get tool description for LLM
     */
    String description();
    
    /**
     * Get parameter schema (JSON Schema format)
     */
    Map<String, Object> parameterSchema();
    
    /**
     * Convert to LLM tool definition
     */
    default ToolDefinition toToolDefinition() {
        return ToolDefinition.create(name(), description(), parameterSchema());
    }
    
    /**
     * Validate tool arguments
     */
    Uni<Boolean> validate(Map<String, Object> arguments);
    
    /**
     * Execute the tool
     */
    Uni<String> execute(Map<String, Object> arguments, AgentContext context);
    
    /**
     * Get tool metadata
     */
    default Map<String, Object> metadata() {
        return Map.of(
            "name", name(),
            "description", description(),
            "version", "1.0.0"
        );
    }
    
    /**
     * Check if tool requires authentication
     */
    default boolean requiresAuth() {
        return false;
    }
    
    /**
     * Check if tool is async (long-running)
     */
    default boolean isAsync() {
        return false;
    }
}

// ==================== ABSTRACT TOOL BASE ====================

/**
 * Abstract base class for tools with common functionality
 */
public abstract class AbstractTool implements Tool {
    
    private static final Logger LOG = LoggerFactory.getLogger(AbstractTool.class);
    
    protected final String toolName;
    protected final String toolDescription;
    
    protected AbstractTool(String name, String description) {
        this.toolName = name;
        this.toolDescription = description;
    }
    
    @Override
    public String name() {
        return toolName;
    }
    
    @Override
    public String description() {
        return toolDescription;
    }
    
    @Override
    public Uni<Boolean> validate(Map<String, Object> arguments) {
        // Default validation: check required parameters
        Map<String, Object> schema = parameterSchema();
        
        if (schema.containsKey("required")) {
            @SuppressWarnings("unchecked")
            List<String> required = (List<String>) schema.get("required");
            
            for (String param : required) {
                if (!arguments.containsKey(param) || arguments.get(param) == null) {
                    LOG.warn("Missing required parameter: {}", param);
                    return Uni.createFrom().item(false);
                }
            }
        }
        
        return Uni.createFrom().item(true);
    }
    
    /**
     * Helper to get parameter value with type checking
     */
    protected <T> T getParam(Map<String, Object> args, String key, Class<T> type) {
        Object value = args.get(key);
        if (value == null) {
            return null;
        }
        
        if (type.isInstance(value)) {
            return type.cast(value);
        }
        
        throw new IllegalArgumentException(
            "Parameter " + key + " must be of type " + type.getSimpleName());
    }
    
    /**
     * Helper to get parameter with default value
     */
    protected <T> T getParamOrDefault(
            Map<String, Object> args,
            String key,
            T defaultValue) {
        Object value = args.get(key);
        if (value == null) {
            return defaultValue;
        }
        
        @SuppressWarnings("unchecked")
        T result = (T) value;
        return result;
    }
}

// ==================== TOOL REGISTRY ====================

/**
 * Central registry for managing tools
 */
public interface ToolRegistry {
    
    /**
     * Register a tool
     */
    void registerTool(Tool tool, String tenantId);
    
    /**
     * Get a specific tool
     */
    Uni<Tool> getTool(String name, String tenantId);
    
    /**
     * Get multiple tools
     */
    Uni<List<Tool>> getTools(List<String> names, String tenantId);
    
    /**
     * Get all tools for tenant
     */
    Uni<List<Tool>> getAllTools(String tenantId);
    
    /**
     * Unregister a tool
     */
    void unregisterTool(String name, String tenantId);
    
    /**
     * Check if tool exists
     */
    boolean hasTool(String name, String tenantId);
}

@ApplicationScoped
public class DefaultToolRegistry implements ToolRegistry {
    
    private static final Logger LOG = LoggerFactory.getLogger(DefaultToolRegistry.class);
    
    // Map: tenantId -> toolName -> Tool
    private final Map<String, Map<String, Tool>> tools = new ConcurrentHashMap<>();
    
    @Inject
    CalculatorTool calculatorTool;
    
    @Inject
    WebSearchTool webSearchTool;
    
    @Inject
    CurrentTimeTool currentTimeTool;
    
    @jakarta.annotation.PostConstruct
    void init() {
        LOG.info("Initializing tool registry");
        
        // Register built-in tools for all tenants
        // In production, this would be more dynamic
        registerGlobalTool(calculatorTool);
        registerGlobalTool(webSearchTool);
        registerGlobalTool(currentTimeTool);
        
        LOG.info("Registered {} global tools", 3);
    }
    
    private void registerGlobalTool(Tool tool) {
        // Register for a special "global" tenant
        registerTool(tool, "_global");
    }
    
    @Override
    public void registerTool(Tool tool, String tenantId) {
        tools.computeIfAbsent(tenantId, k -> new ConcurrentHashMap<>())
             .put(tool.name(), tool);
        
        LOG.info("Registered tool: {} for tenant: {}", tool.name(), tenantId);
    }
    
    @Override
    public Uni<Tool> getTool(String name, String tenantId) {
        // Check tenant-specific tools first
        Tool tool = tools.getOrDefault(tenantId, Map.of()).get(name);
        
        // Fall back to global tools
        if (tool == null) {
            tool = tools.getOrDefault("_global", Map.of()).get(name);
        }
        
        if (tool == null) {
            LOG.warn("Tool not found: {} for tenant: {}", name, tenantId);
        }
        
        return Uni.createFrom().item(tool);
    }
    
    @Override
    public Uni<List<Tool>> getTools(List<String> names, String tenantId) {
        List<Uni<Tool>> toolUnis = names.stream()
            .map(name -> getTool(name, tenantId))
            .collect(Collectors.toList());
        
        return Uni.combine().all().unis(toolUnis).combinedWith(
            results -> results.stream()
                .map(result -> (Tool) result)
                .filter(Objects::nonNull)
                .collect(Collectors.toList())
        );
    }
    
    @Override
    public Uni<List<Tool>> getAllTools(String tenantId) {
        List<Tool> result = new ArrayList<>();
        
        // Add global tools
        result.addAll(tools.getOrDefault("_global", Map.of()).values());
        
        // Add tenant-specific tools
        result.addAll(tools.getOrDefault(tenantId, Map.of()).values());
        
        return Uni.createFrom().item(result);
    }
    
    @Override
    public void unregisterTool(String name, String tenantId) {
        Map<String, Tool> tenantTools = tools.get(tenantId);
        if (tenantTools != null) {
            tenantTools.remove(name);
            LOG.info("Unregistered tool: {} for tenant: {}", name, tenantId);
        }
    }
    
    @Override
    public boolean hasTool(String name, String tenantId) {
        return tools.getOrDefault(tenantId, Map.of()).containsKey(name) ||
               tools.getOrDefault("_global", Map.of()).containsKey(name);
    }
}

// ==================== BUILT-IN TOOLS ====================

/**
 * Calculator Tool
 * Performs mathematical calculations
 */
@ApplicationScoped
public class CalculatorTool extends AbstractTool {
    
    private static final Logger LOG = LoggerFactory.getLogger(CalculatorTool.class);
    
    public CalculatorTool() {
        super("calculator", "Performs mathematical calculations. " +
              "Supports basic arithmetic, trigonometry, and more.");
    }
    
    @Override
    public Map<String, Object> parameterSchema() {
        return Map.of(
            "type", "object",
            "properties", Map.of(
                "expression", Map.of(
                    "type", "string",
                    "description", "Mathematical expression to evaluate"
                )
            ),
            "required", List.of("expression")
        );
    }
    
    @Override
    public Uni<String> execute(Map<String, Object> arguments, AgentContext context) {
        String expression = getParam(arguments, "expression", String.class);
        
        LOG.debug("Calculating: {}", expression);
        
        return Uni.createFrom().deferred(() -> {
            try {
                // Use a safe math evaluator (not eval!)
                double result = evaluateExpression(expression);
                return Uni.createFrom().item(String.valueOf(result));
            } catch (Exception e) {
                LOG.error("Calculation error: {}", e.getMessage());
                return Uni.createFrom().item("Error: " + e.getMessage());
            }
        });
    }
    
    private double evaluateExpression(String expression) {
        // Simple implementation - in production use a proper math library
        // like exp4j or JEP
        try {
            // Handle basic operations
            expression = expression.trim();
            
            if (expression.contains("+")) {
                String[] parts = expression.split("\\+");
                return Double.parseDouble(parts[0].trim()) + 
                       Double.parseDouble(parts[1].trim());
            } else if (expression.contains("-")) {
                String[] parts = expression.split("-");
                return Double.parseDouble(parts[0].trim()) - 
                       Double.parseDouble(parts[1].trim());
            } else if (expression.contains("*")) {
                String[] parts = expression.split("\\*");
                return Double.parseDouble(parts[0].trim()) * 
                       Double.parseDouble(parts[1].trim());
            } else if (expression.contains("/")) {
                String[] parts = expression.split("/");
                return Double.parseDouble(parts[0].trim()) / 
                       Double.parseDouble(parts[1].trim());
            } else {
                return Double.parseDouble(expression);
            }
        } catch (Exception e) {
            throw new IllegalArgumentException("Invalid expression: " + expression);
        }
    }
}

/**
 * Web Search Tool
 * Searches the web for information
 */
@ApplicationScoped
public class WebSearchTool extends AbstractTool {
    
    private static final Logger LOG = LoggerFactory.getLogger(WebSearchTool.class);
    
    public WebSearchTool() {
        super("web_search", "Searches the web for current information. " +
              "Use this when you need up-to-date information or facts.");
    }
    
    @Override
    public Map<String, Object> parameterSchema() {
        return Map.of(
            "type", "object",
            "properties", Map.of(
                "query", Map.of(
                    "type", "string",
                    "description", "Search query"
                ),
                "num_results", Map.of(
                    "type", "integer",
                    "description", "Number of results to return",
                    "default", 5
                )
            ),
            "required", List.of("query")
        );
    }
    
    @Override
    public Uni<String> execute(Map<String, Object> arguments, AgentContext context) {
        String query = getParam(arguments, "query", String.class);
        Integer numResults = getParamOrDefault(arguments, "num_results", 5);
        
        LOG.debug("Searching web: {} (limit: {})", query, numResults);
        
        return performWebSearch(query, numResults)
            .map(results -> formatSearchResults(results));
    }
    
    private Uni<List<SearchResult>> performWebSearch(String query, int limit) {
        // In production, integrate with actual search API
        // (Google Custom Search, Bing API, etc.)
        
        // Placeholder implementation
        return Uni.createFrom().item(List.of(
            new SearchResult(
                "Example Result",
                "https://example.com",
                "This is an example search result for: " + query
            )
        ));
    }
    
    private String formatSearchResults(List<SearchResult> results) {
        if (results.isEmpty()) {
            return "No results found.";
        }
        
        return results.stream()
            .map(r -> String.format("Title: %s\nURL: %s\nSnippet: %s",
                r.title(), r.url(), r.snippet()))
            .collect(Collectors.joining("\n\n"));
    }
    
    private record SearchResult(String title, String url, String snippet) {}
}

/**
 * Current Time Tool
 * Returns current date and time
 */
@ApplicationScoped
public class CurrentTimeTool extends AbstractTool {
    
    public CurrentTimeTool() {
        super("current_time", "Returns the current date and time. " +
              "Useful when you need to know what time it is now.");
    }
    
    @Override
    public Map<String, Object> parameterSchema() {
        return Map.of(
            "type", "object",
            "properties", Map.of(
                "timezone", Map.of(
                    "type", "string",
                    "description", "Timezone (e.g., 'UTC', 'America/New_York')",
                    "default", "UTC"
                ),
                "format", Map.of(
                    "type", "string",
                    "description", "Output format: 'iso' or 'human'",
                    "default", "iso"
                )
            ),
            "required", List.of()
        );
    }
    
    @Override
    public Uni<String> execute(Map<String, Object> arguments, AgentContext context) {
        String timezone = getParamOrDefault(arguments, "timezone", "UTC");
        String format = getParamOrDefault(arguments, "format", "iso");
        
        Instant now = Instant.now();
        
        if ("human".equals(format)) {
            return Uni.createFrom().item(
                "Current time: " + now.toString() + " (" + timezone + ")");
        } else {
            return Uni.createFrom().item(now.toString());
        }
    }
}

/**
 * Database Query Tool
 * Executes safe database queries
 */
@ApplicationScoped
public class DatabaseQueryTool extends AbstractTool {
    
    private static final Logger LOG = LoggerFactory.getLogger(DatabaseQueryTool.class);
    
    public DatabaseQueryTool() {
        super("database_query", "Executes read-only database queries. " +
              "Can query tables and retrieve data.");
    }
    
    @Override
    public Map<String, Object> parameterSchema() {
        return Map.of(
            "type", "object",
            "properties", Map.of(
                "query", Map.of(
                    "type", "string",
                    "description", "SQL SELECT query (read-only)"
                ),
                "database", Map.of(
                    "type", "string",
                    "description", "Database name",
                    "default", "default"
                )
            ),
            "required", List.of("query")
        );
    }
    
    @Override
    public Uni<Boolean> validate(Map<String, Object> arguments) {
        return super.validate(arguments)
            .flatMap(valid -> {
                if (!valid) return Uni.createFrom().item(false);
                
                String query = getParam(arguments, "query", String.class);
                
                // Ensure it's a SELECT query
                if (!query.trim().toUpperCase().startsWith("SELECT")) {
                    LOG.warn("Only SELECT queries are allowed");
                    return Uni.createFrom().item(false);
                }
                
                return Uni.createFrom().item(true);
            });
    }
    
    @Override
    public Uni<String> execute(Map<String, Object> arguments, AgentContext context) {
        String query = getParam(arguments, "query", String.class);
        String database = getParamOrDefault(arguments, "database", "default");
        
        LOG.debug("Executing query on {}: {}", database, query);
        
        // In production, execute actual database query
        // For now, return placeholder
        return Uni.createFrom().item(
            "Query executed successfully. Results: [placeholder]");
    }
    
    @Override
    public boolean requiresAuth() {
        return true; // Requires database credentials
    }
}

/**
 * API Call Tool
 * Makes HTTP requests to external APIs
 */
@ApplicationScoped
public class APICallTool extends AbstractTool {
    
    private static final Logger LOG = LoggerFactory.getLogger(APICallTool.class);
    
    public APICallTool() {
        super("api_call", "Makes HTTP requests to external APIs. " +
              "Supports GET, POST, PUT, DELETE methods.");
    }
    
    @Override
    public Map<String, Object> parameterSchema() {
        return Map.of(
            "type", "object",
            "properties", Map.of(
                "url", Map.of(
                    "type", "string",
                    "description", "API endpoint URL"
                ),
                "method", Map.of(
                    "type", "string",
                    "description", "HTTP method",
                    "enum", List.of("GET", "POST", "PUT", "DELETE"),
                    "default", "GET"
                ),
                "headers", Map.of(
                    "type", "object",
                    "description", "HTTP headers"
                ),
                "body", Map.of(
                    "type", "object",
                    "description", "Request body (for POST/PUT)"
                )
            ),
            "required", List.of("url")
        );
    }
    
    @Override
    public Uni<String> execute(Map<String, Object> arguments, AgentContext context) {
        String url = getParam(arguments, "url", String.class);
        String method = getParamOrDefault(arguments, "method", "GET");
        
        LOG.debug("API call: {} {}", method, url);
        
        // In production, use proper HTTP client
        // For now, return placeholder
        return Uni.createFrom().item(
            "API call to " + url + " completed. Response: [placeholder]");
    }
    
    @Override
    public boolean isAsync() {
        return true; // HTTP calls can be long-running
    }
}

// ==================== TOOL EXECUTION METRICS ====================

/**
 * Metrics collector for tool executions
 */
@ApplicationScoped
public class ToolMetricsCollector {
    
    private static final Logger LOG = LoggerFactory.getLogger(ToolMetricsCollector.class);
    
    private final Map<String, ToolMetrics> metrics = new ConcurrentHashMap<>();
    
    public void recordExecution(String toolName, boolean success) {
        metrics.computeIfAbsent(toolName, k -> new ToolMetrics(toolName))
               .recordExecution(success);
    }
    
    public ToolMetrics getMetrics(String toolName) {
        return metrics.get(toolName);
    }
    
    public Map<String, ToolMetrics> getAllMetrics() {
        return new HashMap<>(metrics);
    }
    
    public static class ToolMetrics {
        private final String toolName;
        private final java.util.concurrent.atomic.AtomicLong totalExecutions = 
            new java.util.concurrent.atomic.AtomicLong();
        private final java.util.concurrent.atomic.AtomicLong successfulExecutions = 
            new java.util.concurrent.atomic.AtomicLong();
        private final java.util.concurrent.atomic.AtomicLong failedExecutions = 
            new java.util.concurrent.atomic.AtomicLong();
        
        public ToolMetrics(String toolName) {
            this.toolName = toolName;
        }
        
        public void recordExecution(boolean success) {
            totalExecutions.incrementAndGet();
            if (success) {
                successfulExecutions.incrementAndGet();
            } else {
                failedExecutions.incrementAndGet();
            }
        }
        
        public Map<String, Object> toMap() {
            return Map.of(
                "toolName", toolName,
                "totalExecutions", totalExecutions.get(),
                "successfulExecutions", successfulExecutions.get(),
                "failedExecutions", failedExecutions.get(),
                "successRate", calculateSuccessRate()
            );
        }
        
        private double calculateSuccessRate() {
            long total = totalExecutions.get();
            if (total == 0) return 0.0;
            return (double) successfulExecutions.get() / total * 100.0;
        }
    }
}



package tech.kayys.silat.agent.model;

import io.smallrye.mutiny.Uni;
import jakarta.enterprise.context.ApplicationScoped;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import tech.kayys.silat.agent.core.*;

import java.util.*;
import java.util.concurrent.ConcurrentHashMap;

/**
 * ============================================================================
 * LLM PROVIDER SYSTEM
 * ============================================================================
 * 
 * Multi-provider LLM integration supporting:
 * - OpenAI (GPT-4, GPT-3.5)
 * - Anthropic (Claude)
 * - Azure OpenAI
 * - Google (Gemini)
 * - Local models (Ollama, LM Studio)
 * - Custom providers
 * 
 * Features:
 * - Provider abstraction layer
 * - Function/tool calling support
 * - Streaming responses
 * - Token usage tracking
 * - Automatic retries
 * - Rate limiting
 * - Cost tracking
 * 
 * Architecture:
 * ┌───────────────────────────────────────────────────────────┐
 * │              LLM Provider Registry                        │
 * ├───────────────────────────────────────────────────────────┤
 * │  ┌─────────┐  ┌─────────┐  ┌───────┐  ┌──────────────┐ │
 * │  │ OpenAI  │  │ Claude  │  │ Azure │  │   Custom     │ │
 * │  │Provider │  │Provider │  │OpenAI │  │   Provider   │ │
 * │  └─────────┘  └─────────┘  └───────┘  └──────────────┘ │
 * │       │            │            │             │          │
 * │  ┌────▼────────────▼────────────▼─────────────▼──────┐  │
 * │  │         Provider Abstraction Layer               │  │
 * │  │  (Rate Limiting, Retries, Metrics)               │  │
 * │  └──────────────────────────────────────────────────┘  │
 * └───────────────────────────────────────────────────────────┘
 */

// ==================== LLM PROVIDER INTERFACE ====================

/**
 * Base interface for LLM providers
 */
public interface LLMProvider {
    
    /**
     * Get provider name
     */
    String name();
    
    /**
     * Complete a chat conversation
     */
    Uni<LLMResponse> complete(LLMRequest request);
    
    /**
     * Stream completion (for real-time responses)
     */
    io.smallrye.mutiny.Multi<String> stream(LLMRequest request);
    
    /**
     * Check if provider supports function calling
     */
    boolean supportsFunctionCalling();
    
    /**
     * Get supported models
     */
    List<String> supportedModels();
    
    /**
     * Check if model is available
     */
    boolean supportsModel(String model);
    
    /**
     * Get provider configuration
     */
    Map<String, Object> getConfig();
}

// ==================== ABSTRACT PROVIDER BASE ====================

/**
 * Abstract base for LLM providers with common functionality
 */
public abstract class AbstractLLMProvider implements LLMProvider {
    
    private static final Logger LOG = LoggerFactory.getLogger(AbstractLLMProvider.class);
    
    protected final String providerName;
    protected final Map<String, Object> config;
    
    protected AbstractLLMProvider(String name, Map<String, Object> config) {
        this.providerName = name;
        this.config = new HashMap<>(config);
    }
    
    @Override
    public String name() {
        return providerName;
    }
    
    @Override
    public Map<String, Object> getConfig() {
        return new HashMap<>(config);
    }
    
    @Override
    public boolean supportsModel(String model) {
        return supportedModels().contains(model);
    }
    
    /**
     * Validate request before sending
     */
    protected void validateRequest(LLMRequest request) {
        if (request.messages() == null || request.messages().isEmpty()) {
            throw new IllegalArgumentException("Messages cannot be empty");
        }
        
        if (!supportsModel(request.model())) {
            throw new IllegalArgumentException(
                "Model " + request.model() + " not supported by " + name());
        }
        
        if (!request.tools().isEmpty() && !supportsFunctionCalling()) {
            throw new IllegalArgumentException(
                "Provider " + name() + " does not support function calling");
        }
    }
    
    /**
     * Convert messages to provider-specific format
     */
    protected abstract Object convertMessages(List<Message> messages);
    
    /**
     * Convert tools to provider-specific format
     */
    protected abstract Object convertTools(List<ToolDefinition> tools);
    
    /**
     * Parse provider response to standard format
     */
    protected abstract LLMResponse parseResponse(Object response);
}

// ==================== OPENAI PROVIDER ====================

@ApplicationScoped
public class OpenAIProvider extends AbstractLLMProvider {
    
    private static final Logger LOG = LoggerFactory.getLogger(OpenAIProvider.class);
    
    private final String apiKey;
    private final String baseUrl;
    
    public OpenAIProvider() {
        super("openai", Map.of(
            "baseUrl", "https://api.openai.com/v1",
            "timeout", 60
        ));
        
        // Load from environment or configuration
        this.apiKey = System.getenv("OPENAI_API_KEY");
        this.baseUrl = config.getOrDefault("baseUrl", 
            "https://api.openai.com/v1").toString();
    }
    
    @Override
    public Uni<LLMResponse> complete(LLMRequest request) {
        validateRequest(request);
        
        LOG.debug("OpenAI completion: model={}, messages={}, tools={}", 
            request.model(), request.messages().size(), request.tools().size());
        
        return Uni.createFrom().deferred(() -> {
            try {
                // Build OpenAI API request
                Map<String, Object> apiRequest = buildApiRequest(request);
                
                // Call OpenAI API
                return callOpenAIAPI(apiRequest)
                    .map(this::parseResponse)
                    .onItem().invoke(response -> 
                        LOG.debug("OpenAI response: tokens={}", 
                            response.usage().totalTokens())
                    );
                    
            } catch (Exception e) {
                LOG.error("OpenAI API error: {}", e.getMessage(), e);
                return Uni.createFrom().failure(e);
            }
        });
    }
    
    @Override
    public io.smallrye.mutiny.Multi<String> stream(LLMRequest request) {
        validateRequest(request);
        
        // Streaming implementation
        return io.smallrye.mutiny.Multi.createFrom().items(
            "Streaming not yet implemented for OpenAI"
        );
    }
    
    @Override
    public boolean supportsFunctionCalling() {
        return true;
    }
    
    @Override
    public List<String> supportedModels() {
        return List.of(
            "gpt-4",
            "gpt-4-turbo",
            "gpt-4o",
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-16k"
        );
    }
    
    private Map<String, Object> buildApiRequest(LLMRequest request) {
        Map<String, Object> apiRequest = new HashMap<>();
        
        apiRequest.put("model", request.model());
        apiRequest.put("messages", convertMessages(request.messages()));
        apiRequest.put("temperature", request.temperature());
        apiRequest.put("max_tokens", request.maxTokens());
        
        if (!request.tools().isEmpty()) {
            apiRequest.put("tools", convertTools(request.tools()));
            apiRequest.put("tool_choice", "auto");
        }
        
        if (request.streaming()) {
            apiRequest.put("stream", true);
        }
        
        return apiRequest;
    }
    
    @Override
    protected Object convertMessages(List<Message> messages) {
        // Convert to OpenAI message format
        return messages.stream()
            .map(msg -> {
                Map<String, Object> apiMsg = new HashMap<>();
                apiMsg.put("role", msg.role());
                apiMsg.put("content", msg.content());
                
                if (msg.hasToolCalls()) {
                    apiMsg.put("tool_calls", convertToolCalls(msg.toolCalls()));
                }
                
                if (msg.toolCallId() != null) {
                    apiMsg.put("tool_call_id", msg.toolCallId());
                }
                
                return apiMsg;
            })
            .toList();
    }
    
    private List<Map<String, Object>> convertToolCalls(List<ToolCall> toolCalls) {
        return toolCalls.stream()
            .map(tc -> Map.of(
                "id", tc.id(),
                "type", "function",
                "function", Map.of(
                    "name", tc.name(),
                    "arguments", tc.arguments()
                )
            ))
            .toList();
    }
    
    @Override
    protected Object convertTools(List<ToolDefinition> tools) {
        return tools.stream()
            .map(tool -> Map.of(
                "type", "function",
                "function", Map.of(
                    "name", tool.name(),
                    "description", tool.description(),
                    "parameters", tool.parameters()
                )
            ))
            .toList();
    }
    
    @Override
    protected LLMResponse parseResponse(Object response) {
        // Parse OpenAI response format
        @SuppressWarnings("unchecked")
        Map<String, Object> responseMap = (Map<String, Object>) response;
        
        @SuppressWarnings("unchecked")
        List<Map<String, Object>> choices = 
            (List<Map<String, Object>>) responseMap.get("choices");
        
        @SuppressWarnings("unchecked")
        Map<String, Object> firstChoice = choices.get(0);
        
        @SuppressWarnings("unchecked")
        Map<String, Object> message = 
            (Map<String, Object>) firstChoice.get("message");
        
        String content = (String) message.getOrDefault("content", "");
        String finishReason = (String) firstChoice.get("finish_reason");
        
        // Parse tool calls if present
        List<ToolCall> toolCalls = parseToolCalls(message);
        
        // Parse token usage
        @SuppressWarnings("unchecked")
        Map<String, Object> usage = 
            (Map<String, Object>) responseMap.get("usage");
        TokenUsage tokenUsage = parseTokenUsage(usage);
        
        if (!toolCalls.isEmpty()) {
            return LLMResponse.withToolCalls(content, toolCalls, tokenUsage);
        } else {
            return LLMResponse.create(content, finishReason, tokenUsage);
        }
    }
    
    private List<ToolCall> parseToolCalls(Map<String, Object> message) {
        @SuppressWarnings("unchecked")
        List<Map<String, Object>> toolCalls = 
            (List<Map<String, Object>>) message.get("tool_calls");
        
        if (toolCalls == null) {
            return List.of();
        }
        
        return toolCalls.stream()
            .map(tc -> {
                @SuppressWarnings("unchecked")
                Map<String, Object> function = 
                    (Map<String, Object>) tc.get("function");
                
                return ToolCall.create(
                    (String) tc.get("id"),
                    (String) function.get("name"),
                    parseArguments((String) function.get("arguments"))
                );
            })
            .toList();
    }
    
    @SuppressWarnings("unchecked")
    private Map<String, Object> parseArguments(String argumentsJson) {
        // Parse JSON arguments
        // In production, use proper JSON library
        try {
            return new HashMap<>(); // Placeholder
        } catch (Exception e) {
            LOG.error("Failed to parse arguments: {}", argumentsJson);
            return Map.of();
        }
    }
    
    private TokenUsage parseTokenUsage(Map<String, Object> usage) {
        int promptTokens = ((Number) usage.get("prompt_tokens")).intValue();
        int completionTokens = ((Number) usage.get("completion_tokens")).intValue();
        
        return TokenUsage.of(promptTokens, completionTokens);
    }
    
    private Uni<Object> callOpenAIAPI(Map<String, Object> request) {
        // In production, use proper HTTP client
        // For now, return mock response
        
        Map<String, Object> mockResponse = Map.of(
            "id", "chatcmpl-123",
            "object", "chat.completion",
            "created", System.currentTimeMillis() / 1000,
            "model", request.get("model"),
            "choices", List.of(
                Map.of(
                    "index", 0,
                    "message", Map.of(
                        "role", "assistant",
                        "content", "This is a mock response from OpenAI"
                    ),
                    "finish_reason", "stop"
                )
            ),
            "usage", Map.of(
                "prompt_tokens", 10,
                "completion_tokens", 20,
                "total_tokens", 30
            )
        );
        
        return Uni.createFrom().item(mockResponse);
    }
}

// ==================== ANTHROPIC PROVIDER ====================

@ApplicationScoped
public class AnthropicProvider extends AbstractLLMProvider {
    
    private static final Logger LOG = LoggerFactory.getLogger(AnthropicProvider.class);
    
    private final String apiKey;
    
    public AnthropicProvider() {
        super("anthropic", Map.of(
            "baseUrl", "https://api.anthropic.com/v1",
            "timeout", 60
        ));
        
        this.apiKey = System.getenv("ANTHROPIC_API_KEY");
    }
    
    @Override
    public Uni<LLMResponse> complete(LLMRequest request) {
        validateRequest(request);
        
        LOG.debug("Anthropic completion: model={}, messages={}", 
            request.model(), request.messages().size());
        
        // Similar to OpenAI but with Anthropic API format
        return Uni.createFrom().deferred(() -> {
            Map<String, Object> apiRequest = buildApiRequest(request);
            return callAnthropicAPI(apiRequest)
                .map(this::parseResponse);
        });
    }
    
    @Override
    public io.smallrye.mutiny.Multi<String> stream(LLMRequest request) {
        return io.smallrye.mutiny.Multi.createFrom().items(
            "Streaming not yet implemented for Anthropic"
        );
    }
    
    @Override
    public boolean supportsFunctionCalling() {
        return true; // Claude supports tool use
    }
    
    @Override
    public List<String> supportedModels() {
        return List.of(
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307",
            "claude-2.1",
            "claude-2.0"
        );
    }
    
    private Map<String, Object> buildApiRequest(LLMRequest request) {
        // Anthropic API format
        Map<String, Object> apiRequest = new HashMap<>();
        
        apiRequest.put("model", request.model());
        apiRequest.put("messages", convertMessages(request.messages()));
        apiRequest.put("max_tokens", request.maxTokens());
        
        if (!request.tools().isEmpty()) {
            apiRequest.put("tools", convertTools(request.tools()));
        }
        
        return apiRequest;
    }
    
    @Override
    protected Object convertMessages(List<Message> messages) {
        // Convert to Anthropic format
        return messages.stream()
            .filter(msg -> !msg.isSystem()) // System messages handled separately
            .map(msg -> Map.of(
                "role", msg.role(),
                "content", msg.content()
            ))
            .toList();
    }
    
    @Override
    protected Object convertTools(List<ToolDefinition> tools) {
        // Anthropic tool format
        return tools.stream()
            .map(tool -> Map.of(
                "name", tool.name(),
                "description", tool.description(),
                "input_schema", tool.parameters()
            ))
            .toList();
    }
    
    @Override
    protected LLMResponse parseResponse(Object response) {
        // Parse Anthropic response
        @SuppressWarnings("unchecked")
        Map<String, Object> responseMap = (Map<String, Object>) response;
        
        @SuppressWarnings("unchecked")
        List<Map<String, Object>> content = 
            (List<Map<String, Object>>) responseMap.get("content");
        
        String textContent = extractTextContent(content);
        List<ToolCall> toolCalls = extractToolUse(content);
        
        @SuppressWarnings("unchecked")
        Map<String, Object> usage = 
            (Map<String, Object>) responseMap.get("usage");
        TokenUsage tokenUsage = TokenUsage.of(
            ((Number) usage.get("input_tokens")).intValue(),
            ((Number) usage.get("output_tokens")).intValue()
        );
        
        String finishReason = (String) responseMap.get("stop_reason");
        
        if (!toolCalls.isEmpty()) {
            return LLMResponse.withToolCalls(textContent, toolCalls, tokenUsage);
        } else {
            return LLMResponse.create(textContent, finishReason, tokenUsage);
        }
    }
    
    private String extractTextContent(List<Map<String, Object>> content) {
        return content.stream()
            .filter(block -> "text".equals(block.get("type")))
            .map(block -> (String) block.get("text"))
            .findFirst()
            .orElse("");
    }
    
    private List<ToolCall> extractToolUse(List<Map<String, Object>> content) {
        return content.stream()
            .filter(block -> "tool_use".equals(block.get("type")))
            .map(block -> ToolCall.create(
                (String) block.get("id"),
                (String) block.get("name"),
                (Map<String, Object>) block.get("input")
            ))
            .toList();
    }
    
    private Uni<Object> callAnthropicAPI(Map<String, Object> request) {
        // Mock response
        Map<String, Object> mockResponse = Map.of(
            "id", "msg_123",
            "type", "message",
            "role", "assistant",
            "content", List.of(
                Map.of(
                    "type", "text",
                    "text", "This is a mock response from Claude"
                )
            ),
            "model", request.get("model"),
            "stop_reason", "end_turn",
            "usage", Map.of(
                "input_tokens", 10,
                "output_tokens", 20
            )
        );
        
        return Uni.createFrom().item(mockResponse);
    }
}

// ==================== PROVIDER REGISTRY ====================

@ApplicationScoped
public class LLMProviderRegistry {
    
    private static final Logger LOG = LoggerFactory.getLogger(LLMProviderRegistry.class);
    
    private final Map<String, LLMProvider> providers = new ConcurrentHashMap<>();
    
    @jakarta.inject.Inject
    OpenAIProvider openAIProvider;
    
    @jakarta.inject.Inject
    AnthropicProvider anthropicProvider;
    
    @jakarta.annotation.PostConstruct
    void init() {
        registerProvider(openAIProvider);
        registerProvider(anthropicProvider);
        
        LOG.info("Registered {} LLM providers", providers.size());
    }
    
    public void registerProvider(LLMProvider provider) {
        providers.put(provider.name(), provider);
        LOG.info("Registered LLM provider: {}", provider.name());
    }
    
    public Uni<LLMProvider> getProvider(String name) {
        LLMProvider provider = providers.get(name.toLowerCase());
        
        if (provider == null) {
            LOG.error("Provider not found: {}", name);
            return Uni.createFrom().failure(
                new IllegalArgumentException("Provider not found: " + name));
        }
        
        return Uni.createFrom().item(provider);
    }
    
    public List<String> getAvailableProviders() {
        return new ArrayList<>(providers.keySet());
    }
    
    public Map<String, List<String>> getAllSupportedModels() {
        Map<String, List<String>> result = new HashMap<>();
        
        providers.forEach((name, provider) -> 
            result.put(name, provider.supportedModels())
        );
        
        return result;
    }
}

package tech.kayys.silat.agent.services;

import io.smallrye.mutiny.Uni;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import tech.kayys.silat.agent.core.*;
import tech.kayys.silat.agent.model.TokenUsage;

import java.time.Duration;
import java.time.Instant;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicLong;

/**
 * ============================================================================
 * AGENT SUPPORT SERVICES
 * ============================================================================
 * 
 * Supporting services for agent operations:
 * - Configuration management
 * - Context management
 * - Metrics collection
 * - Storage services
 */

// ==================== CONFIGURATION SERVICE ====================

/**
 * Service for managing agent configurations
 */
@ApplicationScoped
public class AgentConfigurationService {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentConfigurationService.class);
    
    private final Map<String, AgentConfiguration> configCache = new ConcurrentHashMap<>();
    
    @Inject
    ConfigurationRepository configRepository;
    
    /**
     * Load agent configuration
     */
    public Uni<AgentConfiguration> loadConfiguration(
            String agentId,
            String tenantId) {
        
        String key = makeKey(agentId, tenantId);
        
        // Check cache first
        AgentConfiguration cached = configCache.get(key);
        if (cached != null) {
            LOG.debug("Configuration loaded from cache: {}", key);
            return Uni.createFrom().item(cached);
        }
        
        // Load from repository
        return configRepository.findByAgentId(agentId, tenantId)
            .onItem().invoke(config -> {
                if (config != null) {
                    configCache.put(key, config);
                    LOG.debug("Configuration loaded from repository: {}", key);
                }
            })
            .onFailure().invoke(error -> 
                LOG.error("Failed to load configuration: {}", error.getMessage())
            );
    }
    
    /**
     * Save agent configuration
     */
    public Uni<Void> saveConfiguration(AgentConfiguration config) {
        String key = makeKey(config.agentId(), config.tenantId());
        
        return configRepository.save(config)
            .onItem().invoke(v -> {
                configCache.put(key, config);
                LOG.info("Configuration saved: {}", key);
            });
    }
    
    /**
     * Delete agent configuration
     */
    public Uni<Void> deleteConfiguration(String agentId, String tenantId) {
        String key = makeKey(agentId, tenantId);
        
        return configRepository.delete(agentId, tenantId)
            .onItem().invoke(v -> {
                configCache.remove(key);
                LOG.info("Configuration deleted: {}", key);
            });
    }
    
    private String makeKey(String agentId, String tenantId) {
        return tenantId + ":" + agentId;
    }
}

// ==================== CONTEXT MANAGER ====================

/**
 * Manages agent execution contexts
 */
@ApplicationScoped
public class AgentContextManager {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentContextManager.class);
    
    // Active contexts for running agents
    private final Map<String, AgentContext> activeContexts = new ConcurrentHashMap<>();
    
    /**
     * Create and register a new context
     */
    public AgentContext createContext(
            String sessionId,
            String runId,
            String nodeId,
            String tenantId,
            AgentConfiguration config,
            Map<String, Object> taskContext) {
        
        AgentContext context = AgentContext.builder()
            .sessionId(sessionId)
            .runId(runId)
            .nodeId(nodeId)
            .tenantId(tenantId)
            .configuration(config)
            .taskContext(taskContext)
            .build();
        
        String key = makeKey(sessionId, runId);
        activeContexts.put(key, context);
        
        LOG.debug("Created context: {}", key);
        return context;
    }
    
    /**
     * Get active context
     */
    public Optional<AgentContext> getContext(String sessionId, String runId) {
        String key = makeKey(sessionId, runId);
        return Optional.ofNullable(activeContexts.get(key));
    }
    
    /**
     * Remove context (cleanup after execution)
     */
    public void removeContext(String sessionId, String runId) {
        String key = makeKey(sessionId, runId);
        activeContexts.remove(key);
        LOG.debug("Removed context: {}", key);
    }
    
    /**
     * Get all active contexts for monitoring
     */
    public Map<String, AgentContext> getActiveContexts() {
        return new HashMap<>(activeContexts);
    }
    
    /**
     * Get active context count
     */
    public int getActiveContextCount() {
        return activeContexts.size();
    }
    
    private String makeKey(String sessionId, String runId) {
        return sessionId + ":" + runId;
    }
}

// ==================== METRICS COLLECTOR ====================

/**
 * Collects and aggregates agent execution metrics
 */
@ApplicationScoped
public class AgentMetricsCollector {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentMetricsCollector.class);
    
    private final Map<String, NodeMetrics> nodeMetrics = new ConcurrentHashMap<>();
    private final Map<String, ProviderMetrics> providerMetrics = new ConcurrentHashMap<>();
    
    /**
     * Record agent execution
     */
    public void recordExecution(String nodeId, Duration duration, boolean success) {
        nodeMetrics.computeIfAbsent(nodeId, k -> new NodeMetrics(nodeId))
                   .recordExecution(duration, success);
        
        LOG.trace("Recorded execution for node: {} ({}ms, {})", 
            nodeId, duration.toMillis(), success ? "success" : "failure");
    }
    
    /**
     * Record token usage
     */
    public void recordTokenUsage(String provider, String model, TokenUsage usage) {
        String key = provider + ":" + model;
        
        providerMetrics.computeIfAbsent(key, k -> new ProviderMetrics(provider, model))
                       .recordTokens(usage);
        
        LOG.trace("Recorded token usage: {} tokens for {}", 
            usage.totalTokens(), key);
    }
    
    /**
     * Record tool execution
     */
    public void recordToolExecution(String toolName, boolean success) {
        // Delegate to tool metrics collector
        LOG.trace("Recorded tool execution: {} ({})", 
            toolName, success ? "success" : "failure");
    }
    
    /**
     * Get metrics for a specific node
     */
    public NodeMetrics getNodeMetrics(String nodeId) {
        return nodeMetrics.get(nodeId);
    }
    
    /**
     * Get all node metrics
     */
    public Map<String, NodeMetrics> getAllNodeMetrics() {
        return new HashMap<>(nodeMetrics);
    }
    
    /**
     * Get provider metrics
     */
    public ProviderMetrics getProviderMetrics(String provider, String model) {
        return providerMetrics.get(provider + ":" + model);
    }
    
    /**
     * Get all provider metrics
     */
    public Map<String, ProviderMetrics> getAllProviderMetrics() {
        return new HashMap<>(providerMetrics);
    }
    
    /**
     * Get aggregated statistics
     */
    public AgentStatistics getStatistics() {
        long totalExecutions = nodeMetrics.values().stream()
            .mapToLong(m -> m.getTotalExecutions())
            .sum();
        
        long successfulExecutions = nodeMetrics.values().stream()
            .mapToLong(m -> m.getSuccessfulExecutions())
            .sum();
        
        long totalTokens = providerMetrics.values().stream()
            .mapToLong(m -> m.getTotalTokens())
            .sum();
        
        double avgDuration = nodeMetrics.values().stream()
            .filter(m -> m.getTotalExecutions() > 0)
            .mapToDouble(NodeMetrics::getAverageDuration)
            .average()
            .orElse(0.0);
        
        return new AgentStatistics(
            totalExecutions,
            successfulExecutions,
            totalTokens,
            avgDuration
        );
    }
    
    /**
     * Node-specific metrics
     */
    public static class NodeMetrics {
        private final String nodeId;
        private final AtomicLong totalExecutions = new AtomicLong();
        private final AtomicLong successfulExecutions = new AtomicLong();
        private final AtomicLong failedExecutions = new AtomicLong();
        private final List<Long> durations = new ArrayList<>();
        
        public NodeMetrics(String nodeId) {
            this.nodeId = nodeId;
        }
        
        public void recordExecution(Duration duration, boolean success) {
            totalExecutions.incrementAndGet();
            
            if (success) {
                successfulExecutions.incrementAndGet();
            } else {
                failedExecutions.incrementAndGet();
            }
            
            synchronized (durations) {
                durations.add(duration.toMillis());
                
                // Keep only last 1000 measurements
                if (durations.size() > 1000) {
                    durations.remove(0);
                }
            }
        }
        
        public long getTotalExecutions() {
            return totalExecutions.get();
        }
        
        public long getSuccessfulExecutions() {
            return successfulExecutions.get();
        }
        
        public long getFailedExecutions() {
            return failedExecutions.get();
        }
        
        public double getSuccessRate() {
            long total = totalExecutions.get();
            if (total == 0) return 0.0;
            return (double) successfulExecutions.get() / total * 100.0;
        }
        
        public double getAverageDuration() {
            synchronized (durations) {
                if (durations.isEmpty()) return 0.0;
                return durations.stream()
                    .mapToLong(Long::longValue)
                    .average()
                    .orElse(0.0);
            }
        }
        
        public Map<String, Object> toMap() {
            return Map.of(
                "nodeId", nodeId,
                "totalExecutions", getTotalExecutions(),
                "successfulExecutions", getSuccessfulExecutions(),
                "failedExecutions", getFailedExecutions(),
                "successRate", getSuccessRate(),
                "averageDurationMs", getAverageDuration()
            );
        }
    }
    
    /**
     * Provider-specific metrics
     */
    public static class ProviderMetrics {
        private final String provider;
        private final String model;
        private final AtomicLong totalRequests = new AtomicLong();
        private final AtomicLong totalPromptTokens = new AtomicLong();
        private final AtomicLong totalCompletionTokens = new AtomicLong();
        private final AtomicLong totalTokens = new AtomicLong();
        
        public ProviderMetrics(String provider, String model) {
            this.provider = provider;
            this.model = model;
        }
        
        public void recordTokens(TokenUsage usage) {
            totalRequests.incrementAndGet();
            totalPromptTokens.addAndGet(usage.promptTokens());
            totalCompletionTokens.addAndGet(usage.completionTokens());
            totalTokens.addAndGet(usage.totalTokens());
        }
        
        public long getTotalRequests() {
            return totalRequests.get();
        }
        
        public long getTotalTokens() {
            return totalTokens.get();
        }
        
        public long getAverageTokensPerRequest() {
            long requests = totalRequests.get();
            if (requests == 0) return 0;
            return totalTokens.get() / requests;
        }
        
        public Map<String, Object> toMap() {
            return Map.of(
                "provider", provider,
                "model", model,
                "totalRequests", getTotalRequests(),
                "totalPromptTokens", totalPromptTokens.get(),
                "totalCompletionTokens", totalCompletionTokens.get(),
                "totalTokens", getTotalTokens(),
                "averageTokensPerRequest", getAverageTokensPerRequest()
            );
        }
    }
}

/**
 * Aggregated agent statistics
 */
record AgentStatistics(
    long totalExecutions,
    long successfulExecutions,
    long totalTokens,
    double averageDurationMs
) {
    
    public double successRate() {
        if (totalExecutions == 0) return 0.0;
        return (double) successfulExecutions / totalExecutions * 100.0;
    }
    
    public Map<String, Object> toMap() {
        return Map.of(
            "totalExecutions", totalExecutions,
            "successfulExecutions", successfulExecutions,
            "totalTokens", totalTokens,
            "averageDurationMs", averageDurationMs,
            "successRate", successRate()
        );
    }
}

// ==================== STORAGE SERVICE ====================

/**
 * Service for persisting agent memory and messages
 */
@ApplicationScoped
public class MemoryStorageService {
    
    private static final Logger LOG = LoggerFactory.getLogger(MemoryStorageService.class);
    
    @Inject
    MessageRepository messageRepository;
    
    /**
     * Load messages for a session
     */
    public Uni<List<Message>> loadMessages(String sessionId, String tenantId) {
        LOG.debug("Loading messages: session={}, tenant={}", sessionId, tenantId);
        
        return messageRepository.findBySession(sessionId, tenantId)
            .onItem().invoke(messages -> 
                LOG.debug("Loaded {} messages", messages.size())
            )
            .onFailure().invoke(error -> 
                LOG.error("Failed to load messages: {}", error.getMessage())
            );
    }
    
    /**
     * Save messages
     */
    public Uni<Void> saveMessages(
            String sessionId,
            String tenantId,
            List<Message> messages) {
        
        LOG.debug("Saving {} messages for session: {}", messages.size(), sessionId);
        
        return messageRepository.save(sessionId, tenantId, messages)
            .onItem().invoke(v -> 
                LOG.debug("Messages saved successfully")
            )
            .onFailure().invoke(error -> 
                LOG.error("Failed to save messages: {}", error.getMessage())
            );
    }
    
    /**
     * Clear messages for a session
     */
    public Uni<Void> clearMessages(String sessionId, String tenantId) {
        LOG.info("Clearing messages: session={}", sessionId);
        
        return messageRepository.deleteBySession(sessionId, tenantId);
    }
    
    /**
     * Search messages semantically
     */
    public Uni<List<Message>> searchMessages(
            String sessionId,
            String tenantId,
            String query,
            int limit) {
        
        LOG.debug("Searching messages: query={}, limit={}", query, limit);
        
        return messageRepository.search(sessionId, tenantId, query, limit);
    }
    
    /**
     * Get message count for a session
     */
    public Uni<Long> getMessageCount(String sessionId, String tenantId) {
        return messageRepository.count(sessionId, tenantId);
    }
}

// ==================== REPOSITORY INTERFACES ====================

/**
 * Repository for agent configurations
 */
public interface ConfigurationRepository {
    
    Uni<AgentConfiguration> findByAgentId(String agentId, String tenantId);
    
    Uni<Void> save(AgentConfiguration config);
    
    Uni<Void> delete(String agentId, String tenantId);
    
    Uni<List<AgentConfiguration>> findByTenant(String tenantId);
}

/**
 * Repository for message persistence
 */
public interface MessageRepository {
    
    Uni<List<Message>> findBySession(String sessionId, String tenantId);
    
    Uni<Void> save(String sessionId, String tenantId, List<Message> messages);
    
    Uni<Void> deleteBySession(String sessionId, String tenantId);
    
    Uni<List<Message>> search(String sessionId, String tenantId, String query, int limit);
    
    Uni<Long> count(String sessionId, String tenantId);
}

// ==================== IN-MEMORY IMPLEMENTATIONS ====================

/**
 * In-memory implementation of ConfigurationRepository
 * For production, replace with actual database implementation
 */
@ApplicationScoped
public class InMemoryConfigurationRepository implements ConfigurationRepository {
    
    private static final Logger LOG = LoggerFactory.getLogger(InMemoryConfigurationRepository.class);
    
    private final Map<String, AgentConfiguration> storage = new ConcurrentHashMap<>();
    
    @Override
    public Uni<AgentConfiguration> findByAgentId(String agentId, String tenantId) {
        String key = makeKey(agentId, tenantId);
        return Uni.createFrom().item(storage.get(key));
    }
    
    @Override
    public Uni<Void> save(AgentConfiguration config) {
        String key = makeKey(config.agentId(), config.tenantId());
        storage.put(key, config);
        LOG.debug("Saved configuration: {}", key);
        return Uni.createFrom().voidItem();
    }
    
    @Override
    public Uni<Void> delete(String agentId, String tenantId) {
        String key = makeKey(agentId, tenantId);
        storage.remove(key);
        LOG.debug("Deleted configuration: {}", key);
        return Uni.createFrom().voidItem();
    }
    
    @Override
    public Uni<List<AgentConfiguration>> findByTenant(String tenantId) {
        List<AgentConfiguration> result = storage.values().stream()
            .filter(config -> tenantId.equals(config.tenantId()))
            .toList();
        return Uni.createFrom().item(result);
    }
    
    private String makeKey(String agentId, String tenantId) {
        return tenantId + ":" + agentId;
    }
}

/**
 * In-memory implementation of MessageRepository
 * For production, replace with actual database implementation
 */
@ApplicationScoped
public class InMemoryMessageRepository implements MessageRepository {
    
    private static final Logger LOG = LoggerFactory.getLogger(InMemoryMessageRepository.class);
    
    // Map: sessionKey -> List<Message>
    private final Map<String, List<Message>> storage = new ConcurrentHashMap<>();
    
    @Override
    public Uni<List<Message>> findBySession(String sessionId, String tenantId) {
        String key = makeKey(sessionId, tenantId);
        List<Message> messages = storage.getOrDefault(key, List.of());
        return Uni.createFrom().item(new ArrayList<>(messages));
    }
    
    @Override
    public Uni<Void> save(String sessionId, String tenantId, List<Message> messages) {
        String key = makeKey(sessionId, tenantId);
        
        // Append to existing messages
        storage.compute(key, (k, existing) -> {
            if (existing == null) {
                return new ArrayList<>(messages);
            } else {
                List<Message> updated = new ArrayList<>(existing);
                updated.addAll(messages);
                return updated;
            }
        });
        
        LOG.debug("Saved {} messages for session: {}", messages.size(), key);
        return Uni.createFrom().voidItem();
    }
    
    @Override
    public Uni<Void> deleteBySession(String sessionId, String tenantId) {
        String key = makeKey(sessionId, tenantId);
        storage.remove(key);
        LOG.debug("Deleted messages for session: {}", key);
        return Uni.createFrom().voidItem();
    }
    
    @Override
    public Uni<List<Message>> search(String sessionId, String tenantId, String query, int limit) {
        // Simple substring search for in-memory implementation
        // In production, use proper vector search
        String key = makeKey(sessionId, tenantId);
        List<Message> messages = storage.getOrDefault(key, List.of());
        
        List<Message> results = messages.stream()
            .filter(msg -> msg.content() != null && 
                          msg.content().toLowerCase().contains(query.toLowerCase()))
            .limit(limit)
            .toList();
        
        return Uni.createFrom().item(results);
    }
    
    @Override
    public Uni<Long> count(String sessionId, String tenantId) {
        String key = makeKey(sessionId, tenantId);
        List<Message> messages = storage.getOrDefault(key, List.of());
        return Uni.createFrom().item((long) messages.size());
    }
    
    private String makeKey(String sessionId, String tenantId) {
        return tenantId + ":" + sessionId;
    }
}



package tech.kayys.silat.agent.persistence;

import io.quarkus.hibernate.reactive.panache.PanacheRepositoryBase;
import io.smallrye.mutiny.Uni;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.persistence.*;
import org.hibernate.annotations.CreationTimestamp;
import org.hibernate.annotations.UpdateTimestamp;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import tech.kayys.silat.agent.core.*;
import tech.kayys.silat.agent.services.*;

import java.time.Instant;
import java.util.*;
import java.util.stream.Collectors;

/**
 * ============================================================================
 * DATABASE PERSISTENCE LAYER
 * ============================================================================
 * 
 * Production-ready persistence using Hibernate Reactive Panache.
 * 
 * Features:
 * - Multi-tenant data isolation
 * - Optimistic locking
 * - Audit trails
 * - Efficient queries with indexes
 * - Transaction management
 * - Connection pooling
 * 
 * Database Schema:
 * - agent_configurations: Agent settings
 * - conversation_sessions: Session metadata
 * - conversation_messages: Message history
 * - agent_executions: Execution audit log
 * - vector_embeddings: Semantic search (optional)
 */

// ==================== ENTITY CLASSES ====================

/**
 * Agent Configuration Entity
 */
@Entity
@Table(
    name = "agent_configurations",
    indexes = {
        @Index(name = "idx_agent_tenant", columnList = "agent_id,tenant_id"),
        @Index(name = "idx_tenant", columnList = "tenant_id")
    },
    uniqueConstraints = {
        @UniqueConstraint(columnNames = {"agent_id", "tenant_id"})
    }
)
public class AgentConfigurationEntity {
    
    @Id
    @GeneratedValue(strategy = GenerationType.UUID)
    private String id;
    
    @Column(name = "agent_id", nullable = false, length = 255)
    private String agentId;
    
    @Column(name = "tenant_id", nullable = false, length = 255)
    private String tenantId;
    
    @Column(name = "llm_provider", length = 100)
    private String llmProvider;
    
    @Column(name = "llm_model", length = 100)
    private String llmModel;
    
    @Column(name = "temperature")
    private Double temperature;
    
    @Column(name = "max_tokens")
    private Integer maxTokens;
    
    @Column(name = "memory_enabled")
    private Boolean memoryEnabled;
    
    @Column(name = "memory_type", length = 50)
    private String memoryType;
    
    @Column(name = "memory_window_size")
    private Integer memoryWindowSize;
    
    @Column(name = "enabled_tools", columnDefinition = "TEXT")
    private String enabledTools; // JSON array
    
    @Column(name = "allow_tool_calls")
    private Boolean allowToolCalls;
    
    @Column(name = "system_prompt", columnDefinition = "TEXT")
    private String systemPrompt;
    
    @Column(name = "streaming")
    private Boolean streaming;
    
    @Column(name = "max_iterations")
    private Integer maxIterations;
    
    @Column(name = "additional_config", columnDefinition = "TEXT")
    private String additionalConfig; // JSON object
    
    @Version
    private Long version;
    
    @CreationTimestamp
    @Column(name = "created_at", nullable = false, updatable = false)
    private Instant createdAt;
    
    @UpdateTimestamp
    @Column(name = "updated_at")
    private Instant updatedAt;
    
    // Getters and setters
    public String getId() { return id; }
    public void setId(String id) { this.id = id; }
    
    public String getAgentId() { return agentId; }
    public void setAgentId(String agentId) { this.agentId = agentId; }
    
    public String getTenantId() { return tenantId; }
    public void setTenantId(String tenantId) { this.tenantId = tenantId; }
    
    public String getLlmProvider() { return llmProvider; }
    public void setLlmProvider(String llmProvider) { this.llmProvider = llmProvider; }
    
    public String getLlmModel() { return llmModel; }
    public void setLlmModel(String llmModel) { this.llmModel = llmModel; }
    
    public Double getTemperature() { return temperature; }
    public void setTemperature(Double temperature) { this.temperature = temperature; }
    
    public Integer getMaxTokens() { return maxTokens; }
    public void setMaxTokens(Integer maxTokens) { this.maxTokens = maxTokens; }
    
    public Boolean getMemoryEnabled() { return memoryEnabled; }
    public void setMemoryEnabled(Boolean memoryEnabled) { this.memoryEnabled = memoryEnabled; }
    
    public String getMemoryType() { return memoryType; }
    public void setMemoryType(String memoryType) { this.memoryType = memoryType; }
    
    public Integer getMemoryWindowSize() { return memoryWindowSize; }
    public void setMemoryWindowSize(Integer memoryWindowSize) { 
        this.memoryWindowSize = memoryWindowSize; 
    }
    
    public String getEnabledTools() { return enabledTools; }
    public void setEnabledTools(String enabledTools) { this.enabledTools = enabledTools; }
    
    public Boolean getAllowToolCalls() { return allowToolCalls; }
    public void setAllowToolCalls(Boolean allowToolCalls) { 
        this.allowToolCalls = allowToolCalls; 
    }
    
    public String getSystemPrompt() { return systemPrompt; }
    public void setSystemPrompt(String systemPrompt) { this.systemPrompt = systemPrompt; }
    
    public Boolean getStreaming() { return streaming; }
    public void setStreaming(Boolean streaming) { this.streaming = streaming; }
    
    public Integer getMaxIterations() { return maxIterations; }
    public void setMaxIterations(Integer maxIterations) { this.maxIterations = maxIterations; }
    
    public String getAdditionalConfig() { return additionalConfig; }
    public void setAdditionalConfig(String additionalConfig) { 
        this.additionalConfig = additionalConfig; 
    }
    
    public Long getVersion() { return version; }
    public Instant getCreatedAt() { return createdAt; }
    public Instant getUpdatedAt() { return updatedAt; }
}

/**
 * Conversation Session Entity
 */
@Entity
@Table(
    name = "conversation_sessions",
    indexes = {
        @Index(name = "idx_session_tenant", columnList = "session_id,tenant_id"),
        @Index(name = "idx_session_created", columnList = "created_at"),
        @Index(name = "idx_session_updated", columnList = "updated_at")
    }
)
public class ConversationSessionEntity {
    
    @Id
    @GeneratedValue(strategy = GenerationType.UUID)
    private String id;
    
    @Column(name = "session_id", nullable = false, length = 255)
    private String sessionId;
    
    @Column(name = "tenant_id", nullable = false, length = 255)
    private String tenantId;
    
    @Column(name = "agent_id", length = 255)
    private String agentId;
    
    @Column(name = "user_id", length = 255)
    private String userId;
    
    @Column(name = "message_count")
    private Integer messageCount = 0;
    
    @Column(name = "total_tokens")
    private Long totalTokens = 0L;
    
    @Column(name = "session_metadata", columnDefinition = "TEXT")
    private String sessionMetadata; // JSON
    
    @Column(name = "active")
    private Boolean active = true;
    
    @CreationTimestamp
    @Column(name = "created_at", nullable = false, updatable = false)
    private Instant createdAt;
    
    @UpdateTimestamp
    @Column(name = "updated_at")
    private Instant updatedAt;
    
    @Column(name = "closed_at")
    private Instant closedAt;
    
    // Getters and setters
    public String getId() { return id; }
    public void setId(String id) { this.id = id; }
    
    public String getSessionId() { return sessionId; }
    public void setSessionId(String sessionId) { this.sessionId = sessionId; }
    
    public String getTenantId() { return tenantId; }
    public void setTenantId(String tenantId) { this.tenantId = tenantId; }
    
    public String getAgentId() { return agentId; }
    public void setAgentId(String agentId) { this.agentId = agentId; }
    
    public String getUserId() { return userId; }
    public void setUserId(String userId) { this.userId = userId; }
    
    public Integer getMessageCount() { return messageCount; }
    public void setMessageCount(Integer messageCount) { this.messageCount = messageCount; }
    
    public Long getTotalTokens() { return totalTokens; }
    public void setTotalTokens(Long totalTokens) { this.totalTokens = totalTokens; }
    
    public String getSessionMetadata() { return sessionMetadata; }
    public void setSessionMetadata(String sessionMetadata) { 
        this.sessionMetadata = sessionMetadata; 
    }
    
    public Boolean getActive() { return active; }
    public void setActive(Boolean active) { this.active = active; }
    
    public Instant getCreatedAt() { return createdAt; }
    public Instant getUpdatedAt() { return updatedAt; }
    public Instant getClosedAt() { return closedAt; }
    public void setClosedAt(Instant closedAt) { this.closedAt = closedAt; }
}

/**
 * Conversation Message Entity
 */
@Entity
@Table(
    name = "conversation_messages",
    indexes = {
        @Index(name = "idx_message_session", columnList = "session_id,sequence_number"),
        @Index(name = "idx_message_tenant", columnList = "tenant_id"),
        @Index(name = "idx_message_timestamp", columnList = "timestamp")
    }
)
public class ConversationMessageEntity {
    
    @Id
    @GeneratedValue(strategy = GenerationType.UUID)
    private String id;
    
    @Column(name = "session_id", nullable = false, length = 255)
    private String sessionId;
    
    @Column(name = "tenant_id", nullable = false, length = 255)
    private String tenantId;
    
    @Column(name = "sequence_number", nullable = false)
    private Integer sequenceNumber;
    
    @Column(name = "role", nullable = false, length = 50)
    private String role;
    
    @Column(name = "content", columnDefinition = "TEXT")
    private String content;
    
    @Column(name = "tool_calls", columnDefinition = "TEXT")
    private String toolCalls; // JSON array
    
    @Column(name = "tool_call_id", length = 255)
    private String toolCallId;
    
    @Column(name = "timestamp", nullable = false)
    private Instant timestamp;
    
    @Column(name = "token_count")
    private Integer tokenCount;
    
    // Getters and setters
    public String getId() { return id; }
    public void setId(String id) { this.id = id; }
    
    public String getSessionId() { return sessionId; }
    public void setSessionId(String sessionId) { this.sessionId = sessionId; }
    
    public String getTenantId() { return tenantId; }
    public void setTenantId(String tenantId) { this.tenantId = tenantId; }
    
    public Integer getSequenceNumber() { return sequenceNumber; }
    public void setSequenceNumber(Integer sequenceNumber) { 
        this.sequenceNumber = sequenceNumber; 
    }
    
    public String getRole() { return role; }
    public void setRole(String role) { this.role = role; }
    
    public String getContent() { return content; }
    public void setContent(String content) { this.content = content; }
    
    public String getToolCalls() { return toolCalls; }
    public void setToolCalls(String toolCalls) { this.toolCalls = toolCalls; }
    
    public String getToolCallId() { return toolCallId; }
    public void setToolCallId(String toolCallId) { this.toolCallId = toolCallId; }
    
    public Instant getTimestamp() { return timestamp; }
    public void setTimestamp(Instant timestamp) { this.timestamp = timestamp; }
    
    public Integer getTokenCount() { return tokenCount; }
    public void setTokenCount(Integer tokenCount) { this.tokenCount = tokenCount; }
}

/**
 * Agent Execution Audit Entity
 */
@Entity
@Table(
    name = "agent_executions",
    indexes = {
        @Index(name = "idx_exec_run", columnList = "run_id"),
        @Index(name = "idx_exec_tenant", columnList = "tenant_id"),
        @Index(name = "idx_exec_status", columnList = "status"),
        @Index(name = "idx_exec_started", columnList = "started_at")
    }
)
public class AgentExecutionEntity {
    
    @Id
    @GeneratedValue(strategy = GenerationType.UUID)
    private String id;
    
    @Column(name = "run_id", nullable = false, length = 255)
    private String runId;
    
    @Column(name = "node_id", nullable = false, length = 255)
    private String nodeId;
    
    @Column(name = "tenant_id", nullable = false, length = 255)
    private String tenantId;
    
    @Column(name = "session_id", length = 255)
    private String sessionId;
    
    @Column(name = "agent_id", length = 255)
    private String agentId;
    
    @Column(name = "status", length = 50)
    private String status;
    
    @Column(name = "iterations")
    private Integer iterations;
    
    @Column(name = "tool_calls_count")
    private Integer toolCallsCount;
    
    @Column(name = "prompt_tokens")
    private Integer promptTokens;
    
    @Column(name = "completion_tokens")
    private Integer completionTokens;
    
    @Column(name = "total_tokens")
    private Integer totalTokens;
    
    @Column(name = "duration_ms")
    private Long durationMs;
    
    @Column(name = "llm_provider", length = 100)
    private String llmProvider;
    
    @Column(name = "llm_model", length = 100)
    private String llmModel;
    
    @Column(name = "error_message", columnDefinition = "TEXT")
    private String errorMessage;
    
    @Column(name = "started_at", nullable = false)
    private Instant startedAt;
    
    @Column(name = "completed_at")
    private Instant completedAt;
    
    // Getters and setters
    public String getId() { return id; }
    public void setId(String id) { this.id = id; }
    
    public String getRunId() { return runId; }
    public void setRunId(String runId) { this.runId = runId; }
    
    public String getNodeId() { return nodeId; }
    public void setNodeId(String nodeId) { this.nodeId = nodeId; }
    
    public String getTenantId() { return tenantId; }
    public void setTenantId(String tenantId) { this.tenantId = tenantId; }
    
    public String getSessionId() { return sessionId; }
    public void setSessionId(String sessionId) { this.sessionId = sessionId; }
    
    public String getAgentId() { return agentId; }
    public void setAgentId(String agentId) { this.agentId = agentId; }
    
    public String getStatus() { return status; }
    public void setStatus(String status) { this.status = status; }
    
    public Integer getIterations() { return iterations; }
    public void setIterations(Integer iterations) { this.iterations = iterations; }
    
    public Integer getToolCallsCount() { return toolCallsCount; }
    public void setToolCallsCount(Integer toolCallsCount) { 
        this.toolCallsCount = toolCallsCount; 
    }
    
    public Integer getPromptTokens() { return promptTokens; }
    public void setPromptTokens(Integer promptTokens) { this.promptTokens = promptTokens; }
    
    public Integer getCompletionTokens() { return completionTokens; }
    public void setCompletionTokens(Integer completionTokens) { 
        this.completionTokens = completionTokens; 
    }
    
    public Integer getTotalTokens() { return totalTokens; }
    public void setTotalTokens(Integer totalTokens) { this.totalTokens = totalTokens; }
    
    public Long getDurationMs() { return durationMs; }
    public void setDurationMs(Long durationMs) { this.durationMs = durationMs; }
    
    public String getLlmProvider() { return llmProvider; }
    public void setLlmProvider(String llmProvider) { this.llmProvider = llmProvider; }
    
    public String getLlmModel() { return llmModel; }
    public void setLlmModel(String llmModel) { this.llmModel = llmModel; }
    
    public String getErrorMessage() { return errorMessage; }
    public void setErrorMessage(String errorMessage) { this.errorMessage = errorMessage; }
    
    public Instant getStartedAt() { return startedAt; }
    public void setStartedAt(Instant startedAt) { this.startedAt = startedAt; }
    
    public Instant getCompletedAt() { return completedAt; }
    public void setCompletedAt(Instant completedAt) { this.completedAt = completedAt; }
}

// ==================== PANACHE REPOSITORIES ====================

/**
 * Repository for Agent Configurations
 */
@ApplicationScoped
public class AgentConfigurationRepository 
        implements PanacheRepositoryBase<AgentConfigurationEntity, String> {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentConfigurationRepository.class);
    
    public Uni<AgentConfigurationEntity> findByAgentAndTenant(
            String agentId, 
            String tenantId) {
        return find("agentId = ?1 and tenantId = ?2", agentId, tenantId)
            .firstResult();
    }
    
    public Uni<List<AgentConfigurationEntity>> findByTenant(String tenantId) {
        return list("tenantId", tenantId);
    }
    
    public Uni<Boolean> deleteByAgentAndTenant(String agentId, String tenantId) {
        return delete("agentId = ?1 and tenantId = ?2", agentId, tenantId)
            .map(count -> count > 0);
    }
}

/**
 * Repository for Conversation Sessions
 */
@ApplicationScoped
public class ConversationSessionRepository 
        implements PanacheRepositoryBase<ConversationSessionEntity, String> {
    
    public Uni<ConversationSessionEntity> findBySessionAndTenant(
            String sessionId,
            String tenantId) {
        return find("sessionId = ?1 and tenantId = ?2", sessionId, tenantId)
            .firstResult();
    }
    
    public Uni<List<ConversationSessionEntity>> findActiveSessions(String tenantId) {
        return list("tenantId = ?1 and active = true", tenantId);
    }
    
    public Uni<Long> countActiveSessions(String tenantId) {
        return count("tenantId = ?1 and active = true", tenantId);
    }
}

/**
 * Repository for Conversation Messages
 */
@ApplicationScoped
public class ConversationMessageRepository 
        implements PanacheRepositoryBase<ConversationMessageEntity, String> {
    
    public Uni<List<ConversationMessageEntity>> findBySession(
            String sessionId,
            String tenantId) {
        return list("sessionId = ?1 and tenantId = ?2 order by sequenceNumber", 
            sessionId, tenantId);
    }
    
    public Uni<List<ConversationMessageEntity>> findBySessionWithLimit(
            String sessionId,
            String tenantId,
            int limit) {
        return find(
            "sessionId = ?1 and tenantId = ?2 order by sequenceNumber desc",
            sessionId, tenantId
        ).page(0, limit).list();
    }
    
    public Uni<Integer> getNextSequenceNumber(String sessionId, String tenantId) {
        return find("sessionId = ?1 and tenantId = ?2", sessionId, tenantId)
            .count()
            .map(count -> count.intValue());
    }
    
    public Uni<Boolean> deleteBySession(String sessionId, String tenantId) {
        return delete("sessionId = ?1 and tenantId = ?2", sessionId, tenantId)
            .map(count -> count > 0);
    }
}

/**
 * Repository for Agent Executions
 */
@ApplicationScoped
public class AgentExecutionRepository 
        implements PanacheRepositoryBase<AgentExecutionEntity, String> {
    
    public Uni<List<AgentExecutionEntity>> findByRun(String runId) {
        return list("runId", runId);
    }
    
    public Uni<List<AgentExecutionEntity>> findByTenant(
            String tenantId,
            int page,
            int size) {
        return find("tenantId = ?1 order by startedAt desc", tenantId)
            .page(page, size)
            .list();
    }
    
    public Uni<Long> countByStatus(String tenantId, String status) {
        return count("tenantId = ?1 and status = ?2", tenantId, status);
    }
}

// ==================== PRODUCTION REPOSITORY IMPLEMENTATIONS ====================

/**
 * Production ConfigurationRepository using database
 */
@ApplicationScoped
public class DatabaseConfigurationRepository implements ConfigurationRepository {
    
    private static final Logger LOG = LoggerFactory.getLogger(DatabaseConfigurationRepository.class);
    
    @jakarta.inject.Inject
    AgentConfigurationRepository repository;
    
    @jakarta.inject.Inject
    JsonMapper jsonMapper;
    
    @Override
    public Uni<AgentConfiguration> findByAgentId(String agentId, String tenantId) {
        return repository.findByAgentAndTenant(agentId, tenantId)
            .map(entity -> entity != null ? toConfiguration(entity) : null);
    }
    
    @Override
    public Uni<Void> save(AgentConfiguration config) {
        return repository.findByAgentAndTenant(config.agentId(), config.tenantId())
            .flatMap(existing -> {
                AgentConfigurationEntity entity = existing != null ? 
                    existing : new AgentConfigurationEntity();
                
                updateEntity(entity, config);
                
                return repository.persistOrUpdate(entity)
                    .replaceWithVoid();
            });
    }
    
    @Override
    public Uni<Void> delete(String agentId, String tenantId) {
        return repository.deleteByAgentAndTenant(agentId, tenantId)
            .replaceWithVoid();
    }
    
    @Override
    public Uni<List<AgentConfiguration>> findByTenant(String tenantId) {
        return repository.findByTenant(tenantId)
            .map(entities -> entities.stream()
                .map(this::toConfiguration)
                .collect(Collectors.toList()));
    }
    
    private AgentConfiguration toConfiguration(AgentConfigurationEntity entity) {
        return AgentConfiguration.builder()
            .agentId(entity.getAgentId())
            .tenantId(entity.getTenantId())
            .llmProvider(entity.getLlmProvider())
            .llmModel(entity.getLlmModel())
            .temperature(entity.getTemperature())
            .maxTokens(entity.getMaxTokens())
            .memoryEnabled(entity.getMemoryEnabled())
            .memoryType(entity.getMemoryType())
            .memoryWindowSize(entity.getMemoryWindowSize())
            .enabledTools(jsonMapper.fromJsonArray(entity.getEnabledTools()))
            .allowToolCalls(entity.getAllowToolCalls())
            .systemPrompt(entity.getSystemPrompt())
            .streaming(entity.getStreaming())
            .maxIterations(entity.getMaxIterations())
            .additionalConfig(jsonMapper.fromJsonObject(entity.getAdditionalConfig()))
            .build();
    }
    
    private void updateEntity(AgentConfigurationEntity entity, AgentConfiguration config) {
        entity.setAgentId(config.agentId());
        entity.setTenantId(config.tenantId());
        entity.setLlmProvider(config.llmProvider());
        entity.setLlmModel(config.llmModel());
        entity.setTemperature(config.temperature());
        entity.setMaxTokens(config.maxTokens());
        entity.setMemoryEnabled(config.memoryEnabled());
        entity.setMemoryType(config.memoryType());
        entity.setMemoryWindowSize(config.memoryWindowSize());
        entity.setEnabledTools(jsonMapper.toJsonArray(config.enabledTools()));
        entity.setAllowToolCalls(config.allowToolCalls());
        entity.setSystemPrompt(config.systemPrompt());
        entity.setStreaming(config.streaming());
        entity.setMaxIterations(config.maxIterations());
        entity.setAdditionalConfig(jsonMapper.toJsonObject(config.additionalConfig()));
    }
}

/**
 * Production MessageRepository using database
 */
@ApplicationScoped
public class DatabaseMessageRepository implements MessageRepository {
    
    private static final Logger LOG = LoggerFactory.getLogger(DatabaseMessageRepository.class);
    
    @jakarta.inject.Inject
    ConversationMessageRepository messageRepo;
    
    @jakarta.inject.Inject
    ConversationSessionRepository sessionRepo;
    
    @jakarta.inject.Inject
    JsonMapper jsonMapper;
    
    @Override
    public Uni<List<Message>> findBySession(String sessionId, String tenantId) {
        return messageRepo.findBySession(sessionId, tenantId)
            .map(entities -> entities.stream()
                .map(this::toMessage)
                .collect(Collectors.toList()));
    }
    
    @Override
    public Uni<Void> save(String sessionId, String tenantId, List<Message> messages) {
        // Ensure session exists
        return sessionRepo.findBySessionAndTenant(sessionId, tenantId)
            .flatMap(session -> {
                if (session == null) {
                    session = createNewSession(sessionId, tenantId);
                    return sessionRepo.persist(session)
                        .flatMap(s -> saveMessages(s, messages));
                } else {
                    return saveMessages(session, messages);
                }
            });
    }
    
    private Uni<Void> saveMessages(
            ConversationSessionEntity session,
            List<Message> messages) {
        
        return messageRepo.getNextSequenceNumber(
                session.getSessionId(), 
                session.getTenantId())
            .flatMap(startSeq -> {
                List<ConversationMessageEntity> entities = new ArrayList<>();
                
                for (int i = 0; i < messages.size(); i++) {
                    Message msg = messages.get(i);
                    ConversationMessageEntity entity = toEntity(
                        msg, 
                        session.getSessionId(),
                        session.getTenantId(),
                        startSeq + i
                    );
                    entities.add(entity);
                }
                
                return messageRepo.persist(entities)
                    .flatMap(v -> updateSessionStats(session, messages.size()))
                    .replaceWithVoid();
            });
    }
    
    @Override
    public Uni<Void> deleteBySession(String sessionId, String tenantId) {
        return messageRepo.deleteBySession(sessionId, tenantId)
            .flatMap(deleted -> 
                sessionRepo.findBySessionAndTenant(sessionId, tenantId)
                    .flatMap(session -> {
                        if (session != null) {
                            session.setActive(false);
                            session.setClosedAt(Instant.now());
                            return sessionRepo.persist(session);
                        }
                        return Uni.createFrom().voidItem();
                    })
            )
            .replaceWithVoid();
    }
    
    @Override
    public Uni<List<Message>> search(
            String sessionId,
            String tenantId,
            String query,
            int limit) {
        // Simple content search
        // In production, use full-text search or vector search
        return messageRepo.findBySession(sessionId, tenantId)
            .map(entities -> entities.stream()
                .filter(e -> e.getContent() != null && 
                            e.getContent().toLowerCase().contains(query.toLowerCase()))
                .limit(limit)
                .map(this::toMessage)
                .collect(Collectors.toList()));
    }
    
    @Override
    public Uni<Long> count(String sessionId, String tenantId) {
        return messageRepo.count("sessionId = ?1 and tenantId = ?2", sessionId, tenantId);
    }
    
    private ConversationSessionEntity createNewSession(String sessionId, String tenantId) {
        ConversationSessionEntity session = new ConversationSessionEntity();
        session.setSessionId(sessionId);
        session.setTenantId(tenantId);
        session.setActive(true);
        return session;
    }
    
    private Uni<Void> updateSessionStats(ConversationSessionEntity session, int messageCount) {
        session.setMessageCount(session.getMessageCount() + messageCount);
        return sessionRepo.persist(session).replaceWithVoid();
    }
    
    private Message toMessage(ConversationMessageEntity entity) {
        List<ToolCall> toolCalls = entity.getToolCalls() != null ?
            jsonMapper.fromJsonToolCalls(entity.getToolCalls()) : null;
        
        return new Message(
entity.getRole(),
entity.getContent(),
toolCalls,
entity.getToolCallId(),
entity.getTimestamp()</parameter>
<parameter name="new_str">        return new Message(
entity.getRole(),
entity.getContent(),
toolCalls,
entity.getToolCallId(),
entity.getTimestamp()
);
}
private ConversationMessageEntity toEntity(
        Message msg,
        String sessionId,
        String tenantId,
        int sequenceNumber) {
    
    ConversationMessageEntity entity = new ConversationMessageEntity();
    entity.setSessionId(sessionId);
    entity.setTenantId(tenantId);
    entity.setSequenceNumber(sequenceNumber);
    entity.setRole(msg.role());
    entity.setContent(msg.content());
    entity.setToolCalls(msg.hasToolCalls() ? 
        jsonMapper.toJsonToolCalls(msg.toolCalls()) : null);
    entity.setToolCallId(msg.toolCallId());
    entity.setTimestamp(msg.timestamp());
    
    return entity;
}
}
// ==================== JSON MAPPER ====================
/**

Helper for JSON serialization/deserialization
*/
@ApplicationScoped
public class JsonMapper {
private static final Logger LOG = LoggerFactory.getLogger(JsonMapper.class);
// In production, use proper JSON library (Jackson, Gson, etc.)
public String toJsonArray(List<String> list) {
if (list == null || list.isEmpty()) return "[]";
return "["" + String.join("","", list) + ""]";
}
public List<String> fromJsonArray(String json) {
if (json == null || json.equals("[]")) return List.of();
 // Simple parsing - use proper JSON library in production
 json = json.replaceAll("[\\[\\]\"]", "");
 return Arrays.asList(json.split(","));
}
public String toJsonObject(Map<String, Object> map) {
if (map == null || map.isEmpty()) return "{}";
 // Simple serialization - use proper JSON library
 return "{}";
}
public Map<String, Object> fromJsonObject(String json) {
if (json == null || json.equals("{}")) return Map.of();
 // Simple parsing - use proper JSON library
 return Map.of();
}
public String toJsonToolCalls(List<ToolCall> toolCalls) {
if (toolCalls == null || toolCalls.isEmpty()) return "[]";
 // Serialize tool calls
 return "[]";
}
public List<ToolCall> fromJsonToolCalls(String json) {
if (json == null || json.equals("[]")) return List.of();
 // Deserialize tool calls
 return List.of();
}
}


package tech.kayys.silat.agent.security;

import io.quarkus.security.UnauthorizedException;
import io.smallrye.mutiny.Uni;
import jakarta.annotation.Priority;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import jakarta.ws.rs.Priorities;
import jakarta.ws.rs.container.*;
import jakarta.ws.rs.core.Context;
import jakarta.ws.rs.core.Response;
import jakarta.ws.rs.ext.Provider;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.security.MessageDigest;
import java.time.Instant;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * ============================================================================
 * SECURITY AND AUTHENTICATION LAYER
 * ============================================================================
 * 
 * Production-ready security features:
 * - API key authentication
 * - Rate limiting per tenant/user
 * - Request validation and sanitization
 * - Tool execution sandboxing
 * - Audit logging
 * - Secret management
 * - Token-based authentication (JWT)
 * 
 * Architecture:
 * ┌────────────────────────────────────────────────────────┐
 * │              Security Filter Chain                      │
 * ├────────────────────────────────────────────────────────┤
 * │  Authentication → Authorization → Rate Limiting         │
 * │       ↓                ↓               ↓               │
 * │  API Key Check → Tenant Check → Quota Check            │
 * └────────────────────────────────────────────────────────┘
 */

// ==================== AUTHENTICATION FILTER ====================

/**
 * API Key Authentication Filter
 */
@Provider
@Priority(Priorities.AUTHENTICATION)
public class ApiKeyAuthenticationFilter implements ContainerRequestFilter {
    
    private static final Logger LOG = LoggerFactory.getLogger(ApiKeyAuthenticationFilter.class);
    private static final String API_KEY_HEADER = "X-API-Key";
    private static final String TENANT_ID_HEADER = "X-Tenant-ID";
    
    @Inject
    ApiKeyValidator apiKeyValidator;
    
    @Inject
    SecurityContext securityContext;
    
    @Override
    public void filter(ContainerRequestContext requestContext) {
        String path = requestContext.getUriInfo().getPath();
        
        // Skip authentication for health checks and public endpoints
        if (isPublicEndpoint(path)) {
            return;
        }
        
        String apiKey = requestContext.getHeaderString(API_KEY_HEADER);
        String tenantId = requestContext.getHeaderString(TENANT_ID_HEADER);
        
        if (apiKey == null || apiKey.isEmpty()) {
            LOG.warn("Missing API key for request: {}", path);
            throw new UnauthorizedException("API key required");
        }
        
        if (tenantId == null || tenantId.isEmpty()) {
            LOG.warn("Missing tenant ID for request: {}", path);
            throw new UnauthorizedException("Tenant ID required");
        }
        
        // Validate API key
        ApiKeyValidationResult validation = apiKeyValidator
            .validate(apiKey, tenantId)
            .await().indefinitely();
        
        if (!validation.isValid()) {
            LOG.warn("Invalid API key for tenant: {}", tenantId);
            throw new UnauthorizedException("Invalid API key");
        }
        
        // Check if key is active
        if (!validation.isActive()) {
            LOG.warn("Inactive API key used for tenant: {}", tenantId);
            throw new UnauthorizedException("API key is inactive");
        }
        
        // Set security context
        securityContext.setPrincipal(new AgentPrincipal(
            validation.userId(),
            tenantId,
            validation.roles(),
            validation.permissions()
        ));
        
        LOG.trace("Authenticated request for tenant: {} user: {}", 
            tenantId, validation.userId());
    }
    
    private boolean isPublicEndpoint(String path) {
        return path.startsWith("/health") || 
               path.startsWith("/metrics") ||
               path.startsWith("/q/");
    }
}

// ==================== RATE LIMITING ====================

/**
 * Rate Limiting Filter
 * Implements token bucket algorithm
 */
@Provider
@Priority(Priorities.AUTHORIZATION + 1)
public class RateLimitingFilter implements ContainerRequestFilter {
    
    private static final Logger LOG = LoggerFactory.getLogger(RateLimitingFilter.class);
    
    @Inject
    RateLimiter rateLimiter;
    
    @Inject
    SecurityContext securityContext;
    
    @Override
    public void filter(ContainerRequestContext requestContext) {
        AgentPrincipal principal = securityContext.getPrincipal();
        
        if (principal == null) {
            return; // Skip if not authenticated
        }
        
        String key = makeRateLimitKey(principal);
        
        if (!rateLimiter.allowRequest(key)) {
            LOG.warn("Rate limit exceeded for: {}", key);
            requestContext.abortWith(
                Response.status(429) // Too Many Requests
                    .entity(Map.of(
                        "error", "rate_limit_exceeded",
                        "message", "Too many requests. Please try again later."
                    ))
                    .build()
            );
        }
    }
    
    private String makeRateLimitKey(AgentPrincipal principal) {
        return principal.tenantId() + ":" + principal.userId();
    }
}

// ==================== RATE LIMITER ====================

/**
 * Token Bucket Rate Limiter
 */
@ApplicationScoped
public class RateLimiter {
    
    private static final Logger LOG = LoggerFactory.getLogger(RateLimiter.class);
    
    // Configuration per tenant (can be loaded from database)
    private static final int DEFAULT_CAPACITY = 100; // requests
    private static final int DEFAULT_REFILL_RATE = 10; // requests per second
    
    private final Map<String, TokenBucket> buckets = new ConcurrentHashMap<>();
    
    /**
     * Check if request is allowed
     */
    public boolean allowRequest(String key) {
        TokenBucket bucket = buckets.computeIfAbsent(
            key, 
            k -> new TokenBucket(DEFAULT_CAPACITY, DEFAULT_REFILL_RATE)
        );
        
        return bucket.tryConsume();
    }
    
    /**
     * Get rate limit status
     */
    public RateLimitStatus getStatus(String key) {
        TokenBucket bucket = buckets.get(key);
        if (bucket == null) {
            return new RateLimitStatus(DEFAULT_CAPACITY, DEFAULT_CAPACITY, 0);
        }
        
        return new RateLimitStatus(
            DEFAULT_CAPACITY,
            bucket.getAvailableTokens(),
            bucket.getRequestCount()
        );
    }
    
    /**
     * Reset rate limit for a key
     */
    public void reset(String key) {
        buckets.remove(key);
        LOG.info("Rate limit reset for: {}", key);
    }
    
    /**
     * Token Bucket implementation
     */
    private static class TokenBucket {
        private final int capacity;
        private final int refillRate;
        private final AtomicInteger tokens;
        private volatile long lastRefillTimestamp;
        private final AtomicInteger requestCount = new AtomicInteger(0);
        
        TokenBucket(int capacity, int refillRate) {
            this.capacity = capacity;
            this.refillRate = refillRate;
            this.tokens = new AtomicInteger(capacity);
            this.lastRefillTimestamp = System.currentTimeMillis();
        }
        
        synchronized boolean tryConsume() {
            refill();
            
            if (tokens.get() > 0) {
                tokens.decrementAndGet();
                requestCount.incrementAndGet();
                return true;
            }
            
            return false;
        }
        
        private void refill() {
            long now = System.currentTimeMillis();
            long elapsed = now - lastRefillTimestamp;
            
            if (elapsed > 1000) { // 1 second
                int tokensToAdd = (int) (elapsed / 1000) * refillRate;
                int newTokens = Math.min(capacity, tokens.get() + tokensToAdd);
                tokens.set(newTokens);
                lastRefillTimestamp = now;
            }
        }
        
        int getAvailableTokens() {
            return tokens.get();
        }
        
        int getRequestCount() {
            return requestCount.get();
        }
    }
}

record RateLimitStatus(
    int capacity,
    int available,
    int totalRequests
) {}

// ==================== API KEY VALIDATOR ====================

/**
 * Validates API keys against database
 */
@ApplicationScoped
public class ApiKeyValidator {
    
    private static final Logger LOG = LoggerFactory.getLogger(ApiKeyValidator.class);
    
    @Inject
    ApiKeyRepository apiKeyRepository;
    
    // Cache for validated keys (with TTL)
    private final Map<String, CachedValidation> cache = new ConcurrentHashMap<>();
    private static final long CACHE_TTL_MS = 300000; // 5 minutes
    
    /**
     * Validate API key
     */
    public Uni<ApiKeyValidationResult> validate(String apiKey, String tenantId) {
        String cacheKey = hashApiKey(apiKey) + ":" + tenantId;
        
        // Check cache first
        CachedValidation cached = cache.get(cacheKey);
        if (cached != null && !cached.isExpired()) {
            LOG.trace("API key validation cache hit");
            return Uni.createFrom().item(cached.result);
        }
        
        // Validate against database
        return apiKeyRepository.findByKey(apiKey, tenantId)
            .map(entity -> {
                if (entity == null) {
                    return ApiKeyValidationResult.invalid();
                }
                
                ApiKeyValidationResult result = new ApiKeyValidationResult(
                    true,
                    entity.isActive(),
                    entity.getUserId(),
                    entity.getRoles(),
                    entity.getPermissions()
                );
                
                // Cache result
                cache.put(cacheKey, new CachedValidation(result));
                
                // Update last used timestamp
                apiKeyRepository.updateLastUsed(entity.getId())
                    .subscribe().with(
                        v -> LOG.trace("Updated API key last used"),
                        error -> LOG.warn("Failed to update API key last used", error)
                    );
                
                return result;
            })
            .onFailure().recoverWithItem(error -> {
                LOG.error("API key validation failed", error);
                return ApiKeyValidationResult.invalid();
            });
    }
    
    /**
     * Hash API key for cache lookup (don't store raw keys)
     */
    private String hashApiKey(String apiKey) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            byte[] hash = digest.digest(apiKey.getBytes());
            return Base64.getEncoder().encodeToString(hash);
        } catch (Exception e) {
            return apiKey; // Fallback
        }
    }
    
    private static class CachedValidation {
        final ApiKeyValidationResult result;
        final long timestamp;
        
        CachedValidation(ApiKeyValidationResult result) {
            this.result = result;
            this.timestamp = System.currentTimeMillis();
        }
        
        boolean isExpired() {
            return System.currentTimeMillis() - timestamp > CACHE_TTL_MS;
        }
    }
}

record ApiKeyValidationResult(
    boolean isValid,
    boolean isActive,
    String userId,
    List<String> roles,
    List<String> permissions
) {
    static ApiKeyValidationResult invalid() {
        return new ApiKeyValidationResult(false, false, null, List.of(), List.of());
    }
}

// ==================== SECURITY CONTEXT ====================

/**
 * Thread-safe security context
 */
@ApplicationScoped
public class SecurityContext {
    
    private final ThreadLocal<AgentPrincipal> principalHolder = new ThreadLocal<>();
    
    public void setPrincipal(AgentPrincipal principal) {
        principalHolder.set(principal);
    }
    
    public AgentPrincipal getPrincipal() {
        return principalHolder.get();
    }
    
    public void clear() {
        principalHolder.remove();
    }
    
    public String getCurrentTenantId() {
        AgentPrincipal principal = getPrincipal();
        return principal != null ? principal.tenantId() : null;
    }
    
    public String getCurrentUserId() {
        AgentPrincipal principal = getPrincipal();
        return principal != null ? principal.userId() : null;
    }
    
    public boolean hasPermission(String permission) {
        AgentPrincipal principal = getPrincipal();
        return principal != null && principal.permissions().contains(permission);
    }
    
    public boolean hasRole(String role) {
        AgentPrincipal principal = getPrincipal();
        return principal != null && principal.roles().contains(role);
    }
}

record AgentPrincipal(
    String userId,
    String tenantId,
    List<String> roles,
    List<String> permissions
) {}

// ==================== TOOL EXECUTION SANDBOX ====================

/**
 * Sandbox for safe tool execution
 */
@ApplicationScoped
public class ToolExecutionSandbox {
    
    private static final Logger LOG = LoggerFactory.getLogger(ToolExecutionSandbox.class);
    
    @Inject
    SecurityContext securityContext;
    
    /**
     * Execute tool with security checks
     */
    public <T> Uni<T> executeSecurely(
            String toolName,
            java.util.function.Supplier<Uni<T>> execution) {
        
        // Check if tool is allowed for current user
        if (!isToolAllowed(toolName)) {
            LOG.warn("Tool execution denied: {} for user: {}", 
                toolName, securityContext.getCurrentUserId());
            return Uni.createFrom().failure(
                new SecurityException("Tool execution not permitted: " + toolName));
        }
        
        // Check rate limits for tool
        if (!checkToolRateLimit(toolName)) {
            LOG.warn("Tool rate limit exceeded: {}", toolName);
            return Uni.createFrom().failure(
                new SecurityException("Tool rate limit exceeded"));
        }
        
        // Execute with timeout
        return execution.get()
            .ifNoItem().after(Duration.ofSeconds(30))
            .failWith(new java.util.concurrent.TimeoutException("Tool execution timeout"))
            .onItem().invoke(result -> 
                auditToolExecution(toolName, true, null)
            )
            .onFailure().invoke(error -> 
                auditToolExecution(toolName, false, error.getMessage())
            );
    }
    
    private boolean isToolAllowed(String toolName) {
        // Check permissions for tool
        String permission = "tool:" + toolName;
        return securityContext.hasPermission(permission) || 
               securityContext.hasPermission("tool:*");
    }
    
    private boolean checkToolRateLimit(String toolName) {
        // Implement tool-specific rate limiting
        return true; // Placeholder
    }
    
    private void auditToolExecution(String toolName, boolean success, String error) {
        // Log tool execution for audit
        LOG.info("Tool execution: tool={}, user={}, tenant={}, success={}, error={}", 
            toolName,
            securityContext.getCurrentUserId(),
            securityContext.getCurrentTenantId(),
            success,
            error
        );
    }
}

// ==================== SECRET MANAGEMENT ====================

/**
 * Secure secret management
 */
@ApplicationScoped
public class SecretManager {
    
    private static final Logger LOG = LoggerFactory.getLogger(SecretManager.class);
    
    @Inject
    SecretRepository secretRepository;
    
    // In-memory cache for secrets (encrypted at rest)
    private final Map<String, CachedSecret> cache = new ConcurrentHashMap<>();
    
    /**
     * Get secret value
     */
    public Uni<String> getSecret(String key, String tenantId) {
        String cacheKey = tenantId + ":" + key;
        
        // Check cache
        CachedSecret cached = cache.get(cacheKey);
        if (cached != null && !cached.isExpired()) {
            return Uni.createFrom().item(decrypt(cached.encryptedValue));
        }
        
        // Load from database
        return secretRepository.findByKey(key, tenantId)
            .map(entity -> {
                if (entity == null) {
                    LOG.warn("Secret not found: {}", key);
                    return null;
                }
                
                String decrypted = decrypt(entity.getEncryptedValue());
                
                // Cache encrypted value
                cache.put(cacheKey, new CachedSecret(entity.getEncryptedValue()));
                
                return decrypted;
            });
    }
    
    /**
     * Store secret
     */
    public Uni<Void> setSecret(String key, String value, String tenantId) {
        String encrypted = encrypt(value);
        
        return secretRepository.save(key, encrypted, tenantId)
            .onItem().invoke(v -> {
                // Update cache
                String cacheKey = tenantId + ":" + key;
                cache.put(cacheKey, new CachedSecret(encrypted));
                LOG.info("Secret stored: {}", key);
            });
    }
    
    /**
     * Delete secret
     */
    public Uni<Void> deleteSecret(String key, String tenantId) {
        String cacheKey = tenantId + ":" + key;
        cache.remove(cacheKey);
        
        return secretRepository.delete(key, tenantId);
    }
    
    /**
     * Encrypt value
     * In production, use proper encryption (AES-256, KMS, etc.)
     */
    private String encrypt(String value) {
        // Placeholder - implement proper encryption
        return Base64.getEncoder().encodeToString(value.getBytes());
    }
    
    /**
     * Decrypt value
     */
    private String decrypt(String encrypted) {
        // Placeholder - implement proper decryption
        return new String(Base64.getDecoder().decode(encrypted));
    }
    
    private static class CachedSecret {
        final String encryptedValue;
        final long timestamp;
        
        CachedSecret(String encryptedValue) {
            this.encryptedValue = encryptedValue;
            this.timestamp = System.currentTimeMillis();
        }
        
        boolean isExpired() {
            return System.currentTimeMillis() - timestamp > 3600000; // 1 hour
        }
    }
}

// ==================== AUDIT LOGGER ====================

/**
 * Audit logging for security events
 */
@ApplicationScoped
public class SecurityAuditLogger {
    
    private static final Logger LOG = LoggerFactory.getLogger(SecurityAuditLogger.class);
    
    @Inject
    AuditLogRepository auditLogRepository;
    
    /**
     * Log authentication event
     */
    public void logAuthentication(
            String userId,
            String tenantId,
            boolean success,
            String ipAddress) {
        
        AuditLogEntry entry = new AuditLogEntry(
            "AUTHENTICATION",
            userId,
            tenantId,
            success ? "SUCCESS" : "FAILURE",
            Map.of("ipAddress", ipAddress),
            Instant.now()
        );
        
        persistAuditLog(entry);
    }
    
    /**
     * Log authorization event
     */
    public void logAuthorization(
            String userId,
            String tenantId,
            String resource,
            String action,
            boolean granted) {
        
        AuditLogEntry entry = new AuditLogEntry(
            "AUTHORIZATION",
            userId,
            tenantId,
            granted ? "GRANTED" : "DENIED",
            Map.of("resource", resource, "action", action),
            Instant.now()
        );
        
        persistAuditLog(entry);
    }
    
    /**
     * Log data access
     */
    public void logDataAccess(
            String userId,
            String tenantId,
            String resourceType,
            String resourceId,
            String action) {
        
        AuditLogEntry entry = new AuditLogEntry(
            "DATA_ACCESS",
            userId,
            tenantId,
            action,
            Map.of("resourceType", resourceType, "resourceId", resourceId),
            Instant.now()
        );
        
        persistAuditLog(entry);
    }
    
    private void persistAuditLog(AuditLogEntry entry) {
        auditLogRepository.save(entry)
            .subscribe().with(
                v -> LOG.trace("Audit log saved: {}", entry.eventType()),
                error -> LOG.error("Failed to save audit log", error)
            );
    }
}

record AuditLogEntry(
    String eventType,
    String userId,
    String tenantId,
    String outcome,
    Map<String, String> details,
    Instant timestamp
) {}

// ==================== REPOSITORY INTERFACES ====================

interface ApiKeyRepository {
    Uni<ApiKeyEntity> findByKey(String apiKey, String tenantId);
    Uni<Void> updateLastUsed(String id);
}

interface SecretRepository {
    Uni<SecretEntity> findByKey(String key, String tenantId);
    Uni<Void> save(String key, String encryptedValue, String tenantId);
    Uni<Void> delete(String key, String tenantId);
}

interface AuditLogRepository {
    Uni<Void> save(AuditLogEntry entry);
}

// Placeholder entities
class ApiKeyEntity {
    private String id;
    private String userId;
    private boolean active;
    private List<String> roles;
    private List<String> permissions;
    
    public String getId() { return id; }
    public String getUserId() { return userId; }
    public boolean isActive() { return active; }
    public List<String> getRoles() { return roles; }
    public List<String> getPermissions() { return permissions; }
}

class SecretEntity {
    private String key;
    private String encryptedValue;
    
    public String getKey() { return key; }
    public String getEncryptedValue() { return encryptedValue; }
}


package tech.kayys.silat.agent.observability;

import io.micrometer.core.instrument.*;
import io.micrometer.core.instrument.Timer;
import io.opentelemetry.api.trace.*;
import io.opentelemetry.context.Context;
import io.smallrye.faulttolerance.api.CircuitBreakerName;
import io.smallrye.mutiny.Uni;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.eclipse.microprofile.faulttolerance.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.time.Instant;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;

/**
 * ============================================================================
 * OBSERVABILITY AND RESILIENCE LAYER
 * ============================================================================
 * 
 * Production-ready observability and resilience:
 * - Metrics (Micrometer/Prometheus)
 * - Distributed tracing (OpenTelemetry)
 * - Circuit breakers (Resilience4j)
 * - Bulkheads (isolation)
 * - Retries with backoff
 * - Timeouts
 * - Health checks
 * 
 * Architecture:
 * ┌────────────────────────────────────────────────────────┐
 * │           Observability & Resilience                    │
 * ├────────────────────────────────────────────────────────┤
 * │  ┌─────────┐  ┌─────────┐  ┌──────────┐  ┌─────────┐ │
 * │  │ Metrics │  │ Tracing │  │ Circuit  │  │ Health  │ │
 * │  │         │  │         │  │ Breaker  │  │ Check   │ │
 * │  └─────────┘  └─────────┘  └──────────┘  └─────────┘ │
 * └────────────────────────────────────────────────────────┘
 */

// ==================== METRICS INSTRUMENTATION ====================

/**
 * Metrics collector using Micrometer
 */
@ApplicationScoped
public class AgentMetricsInstrumentation {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentMetricsInstrumentation.class);
    
    private final MeterRegistry meterRegistry;
    
    // Counters
    private final Counter agentExecutionsTotal;
    private final Counter agentExecutionsSuccess;
    private final Counter agentExecutionsFailed;
    private final Counter tokensUsedTotal;
    private final Counter toolCallsTotal;
    
    // Gauges
    private final Map<String, AtomicDouble> activeExecutions = new ConcurrentHashMap<>();
    
    // Timers
    private final Map<String, Timer> executionTimers = new ConcurrentHashMap<>();
    private final Map<String, Timer> llmTimers = new ConcurrentHashMap<>();
    private final Map<String, Timer> toolTimers = new ConcurrentHashMap<>();
    
    @Inject
    public AgentMetricsInstrumentation(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        
        // Initialize counters
        this.agentExecutionsTotal = Counter.builder("agent.executions.total")
            .description("Total number of agent executions")
            .register(meterRegistry);
        
        this.agentExecutionsSuccess = Counter.builder("agent.executions.success")
            .description("Number of successful agent executions")
            .register(meterRegistry);
        
        this.agentExecutionsFailed = Counter.builder("agent.executions.failed")
            .description("Number of failed agent executions")
            .register(meterRegistry);
        
        this.tokensUsedTotal = Counter.builder("agent.tokens.used.total")
            .description("Total number of tokens used")
            .register(meterRegistry);
        
        this.toolCallsTotal = Counter.builder("agent.toolcalls.total")
            .description("Total number of tool calls")
            .register(meterRegistry);
        
        LOG.info("Agent metrics instrumentation initialized");
    }
    
    /**
     * Record agent execution start
     */
    public void recordExecutionStart(String nodeId, String tenantId) {
        agentExecutionsTotal.increment();
        
        String key = makeKey(nodeId, tenantId);
        activeExecutions.computeIfAbsent(key, k -> {
            AtomicDouble gauge = new AtomicDouble(0);
            Gauge.builder("agent.executions.active", gauge, AtomicDouble::get)
                .tag("node", nodeId)
                .tag("tenant", tenantId)
                .description("Number of active agent executions")
                .register(meterRegistry);
            return gauge;
        }).incrementAndGet();
    }
    
    /**
     * Record agent execution completion
     */
    public void recordExecutionComplete(
            String nodeId,
            String tenantId,
            Duration duration,
            boolean success) {
        
        if (success) {
            agentExecutionsSuccess.increment();
        } else {
            agentExecutionsFailed.increment();
        }
        
        // Decrement active executions
        String key = makeKey(nodeId, tenantId);
        AtomicDouble gauge = activeExecutions.get(key);
        if (gauge != null) {
            gauge.decrementAndGet();
        }
        
        // Record duration
        Timer timer = executionTimers.computeIfAbsent(key, k ->
            Timer.builder("agent.execution.duration")
                .tag("node", nodeId)
                .tag("tenant", tenantId)
                .description("Agent execution duration")
                .register(meterRegistry)
        );
        
        timer.record(duration);
    }
    
    /**
     * Record token usage
     */
    public void recordTokenUsage(
            String provider,
            String model,
            int promptTokens,
            int completionTokens,
            int totalTokens) {
        
        tokensUsedTotal.increment(totalTokens);
        
        Counter.builder("agent.tokens.prompt")
            .tag("provider", provider)
            .tag("model", model)
            .register(meterRegistry)
            .increment(promptTokens);
        
        Counter.builder("agent.tokens.completion")
            .tag("provider", provider)
            .tag("model", model)
            .register(meterRegistry)
            .increment(completionTokens);
    }
    
    /**
     * Record LLM call duration
     */
    public void recordLLMCall(String provider, String model, Duration duration) {
        String key = provider + ":" + model;
        
        Timer timer = llmTimers.computeIfAbsent(key, k ->
            Timer.builder("agent.llm.call.duration")
                .tag("provider", provider)
                .tag("model", model)
                .description("LLM API call duration")
                .register(meterRegistry)
        );
        
        timer.record(duration);
    }
    
    /**
     * Record tool call
     */
    public void recordToolCall(String toolName, boolean success, Duration duration) {
        toolCallsTotal.increment();
        
        Counter.builder("agent.toolcalls." + (success ? "success" : "failed"))
            .tag("tool", toolName)
            .register(meterRegistry)
            .increment();
        
        Timer timer = toolTimers.computeIfAbsent(toolName, k ->
            Timer.builder("agent.tool.call.duration")
                .tag("tool", toolName)
                .description("Tool call duration")
                .register(meterRegistry)
        );
        
        timer.record(duration);
    }
    
    private String makeKey(String nodeId, String tenantId) {
        return tenantId + ":" + nodeId;
    }
}

// ==================== DISTRIBUTED TRACING ====================

/**
 * OpenTelemetry tracing instrumentation
 */
@ApplicationScoped
public class AgentTracingInstrumentation {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentTracingInstrumentation.class);
    
    private final Tracer tracer;
    
    @Inject
    public AgentTracingInstrumentation(Tracer tracer) {
        this.tracer = tracer;
    }
    
    /**
     * Create span for agent execution
     */
    public Span startExecutionSpan(String runId, String nodeId, String tenantId) {
        Span span = tracer.spanBuilder("agent.execution")
            .setAttribute("run.id", runId)
            .setAttribute("node.id", nodeId)
            .setAttribute("tenant.id", tenantId)
            .startSpan();
        
        LOG.trace("Started execution span: {}", span.getSpanContext().getSpanId());
        return span;
    }
    
    /**
     * Create span for LLM call
     */
    public Span startLLMSpan(String provider, String model, int messageCount) {
        Span span = tracer.spanBuilder("agent.llm.call")
            .setAttribute("llm.provider", provider)
            .setAttribute("llm.model", model)
            .setAttribute("llm.message_count", messageCount)
            .startSpan();
        
        return span;
    }
    
    /**
     * Create span for tool execution
     */
    public Span startToolSpan(String toolName, Map<String, Object> arguments) {
        Span span = tracer.spanBuilder("agent.tool.call")
            .setAttribute("tool.name", toolName)
            .setAttribute("tool.argument_count", arguments.size())
            .startSpan();
        
        return span;
    }
    
    /**
     * Create span for memory operation
     */
    public Span startMemorySpan(String operation, String sessionId) {
        Span span = tracer.spanBuilder("agent.memory." + operation)
            .setAttribute("session.id", sessionId)
            .startSpan();
        
        return span;
    }
    
    /**
     * Add event to current span
     */
    public void addEvent(String name, Map<String, String> attributes) {
        Span currentSpan = Span.current();
        if (currentSpan != null && currentSpan.isRecording()) {
            currentSpan.addEvent(name, 
                io.opentelemetry.api.common.Attributes.builder()
                    .putAll(convertToAttributes(attributes))
                    .build()
            );
        }
    }
    
    /**
     * Record exception in current span
     */
    public void recordException(Throwable exception) {
        Span currentSpan = Span.current();
        if (currentSpan != null && currentSpan.isRecording()) {
            currentSpan.recordException(exception);
            currentSpan.setStatus(StatusCode.ERROR, exception.getMessage());
        }
    }
    
    /**
     * Execute with tracing
     */
    public <T> Uni<T> traceExecution(
            String spanName,
            Map<String, String> attributes,
            java.util.function.Supplier<Uni<T>> execution) {
        
        Span span = tracer.spanBuilder(spanName)
            .setAllAttributes(convertToAttributes(attributes))
            .startSpan();
        
        try (var scope = span.makeCurrent()) {
            return execution.get()
                .onItem().invoke(item -> {
                    span.setStatus(StatusCode.OK);
                    span.end();
                })
                .onFailure().invoke(error -> {
                    span.recordException(error);
                    span.setStatus(StatusCode.ERROR, error.getMessage());
                    span.end();
                });
        }
    }
    
    private io.opentelemetry.api.common.Attributes convertToAttributes(
            Map<String, String> map) {
        
        var builder = io.opentelemetry.api.common.Attributes.builder();
        map.forEach(builder::put);
        return builder.build();
    }
}

// ==================== CIRCUIT BREAKER ====================

/**
 * Circuit breaker for LLM provider calls
 */
@ApplicationScoped
public class LLMCircuitBreaker {
    
    private static final Logger LOG = LoggerFactory.getLogger(LLMCircuitBreaker.class);
    
    /**
     * Call LLM with circuit breaker protection
     */
    @CircuitBreaker(
        requestVolumeThreshold = 10,
        failureRatio = 0.5,
        delay = 5000,
        successThreshold = 3
    )
    @CircuitBreakerName("llm-provider")
    @Timeout(30000) // 30 seconds
    @Retry(
        maxRetries = 3,
        delay = 1000,
        maxDuration = 60000,
        jitter = 500
    )
    @Bulkhead(value = 10, waitingTaskQueue = 20)
    @Fallback(fallbackMethod = "fallbackLLMCall")
    public <T> Uni<T> callWithProtection(java.util.function.Supplier<Uni<T>> call) {
        LOG.debug("Executing LLM call with circuit breaker protection");
        return call.get();
    }
    
    /**
     * Fallback when circuit is open
     */
    public <T> Uni<T> fallbackLLMCall() {
        LOG.warn("Circuit breaker open - using fallback");
        return Uni.createFrom().failure(
            new CircuitBreakerOpenException("LLM provider circuit breaker is open"));
    }
}

/**
 * Circuit breaker for tool executions
 */
@ApplicationScoped
public class ToolCircuitBreaker {
    
    private static final Logger LOG = LoggerFactory.getLogger(ToolCircuitBreaker.class);
    
    /**
     * Execute tool with circuit breaker protection
     */
    @CircuitBreaker(
        requestVolumeThreshold = 5,
        failureRatio = 0.6,
        delay = 3000,
        successThreshold = 2
    )
    @CircuitBreakerName("tool-execution")
    @Timeout(15000) // 15 seconds
    @Retry(
        maxRetries = 2,
        delay = 500,
        maxDuration = 30000
    )
    @Bulkhead(value = 5, waitingTaskQueue = 10)
    public <T> Uni<T> executeWithProtection(
            String toolName,
            java.util.function.Supplier<Uni<T>> execution) {
        
        LOG.debug("Executing tool with circuit breaker: {}", toolName);
        return execution.get();
    }
}

// ==================== HEALTH CHECKS ====================

/**
 * Health check for agent system
 */
@ApplicationScoped
public class AgentHealthCheck implements org.eclipse.microprofile.health.HealthCheck {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentHealthCheck.class);
    
    @Inject
    tech.kayys.silat.agent.model.LLMProviderRegistry llmRegistry;
    
    @Inject
    tech.kayys.silat.agent.tools.ToolRegistry toolRegistry;
    
    @Inject
    tech.kayys.silat.agent.memory.AgentMemoryManager memoryManager;
    
    @Override
    @org.eclipse.microprofile.health.Liveness
    public org.eclipse.microprofile.health.HealthCheckResponse call() {
        var builder = org.eclipse.microprofile.health.HealthCheckResponse
            .named("agent-system")
            .up();
        
        try {
            // Check LLM providers
            List<String> providers = llmRegistry.getAvailableProviders();
            builder.withData("llm_providers", providers.size());
            
            // Check tool registry
            builder.withData("tools_registered", true);
            
            // Check memory manager
            builder.withData("memory_manager", "operational");
            
            return builder.build();
            
        } catch (Exception e) {
            LOG.error("Health check failed", e);
            return builder.down()
                .withData("error", e.getMessage())
                .build();
        }
    }
}

/**
 * Readiness check for agent system
 */
@ApplicationScoped
public class AgentReadinessCheck implements org.eclipse.microprofile.health.HealthCheck {
    
    @Inject
    tech.kayys.silat.agent.persistence.AgentConfigurationRepository configRepo;
    
    @Override
    @org.eclipse.microprofile.health.Readiness
    public org.eclipse.microprofile.health.HealthCheckResponse call() {
        var builder = org.eclipse.microprofile.health.HealthCheckResponse
            .named("agent-system-ready")
            .up();
        
        try {
            // Check database connectivity
            configRepo.count()
                .await().atMost(Duration.ofSeconds(5));
            
            builder.withData("database", "connected");
            
            return builder.build();
            
        } catch (Exception e) {
            return builder.down()
                .withData("database", "disconnected")
                .withData("error", e.getMessage())
                .build();
        }
    }
}

// ==================== STRUCTURED LOGGING ====================

/**
 * Structured logging for agent operations
 */
@ApplicationScoped
public class AgentStructuredLogger {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentStructuredLogger.class);
    
    /**
     * Log agent execution start
     */
    public void logExecutionStart(
            String runId,
            String nodeId,
            String tenantId,
            String sessionId) {
        
        LOG.info("Agent execution started: runId={}, nodeId={}, tenantId={}, sessionId={}",
            runId, nodeId, tenantId, sessionId);
    }
    
    /**
     * Log agent execution completion
     */
    public void logExecutionComplete(
            String runId,
            String nodeId,
            boolean success,
            int iterations,
            long durationMs,
            int totalTokens) {
        
        if (success) {
            LOG.info("Agent execution completed: runId={}, nodeId={}, " +
                "iterations={}, durationMs={}, totalTokens={}",
                runId, nodeId, iterations, durationMs, totalTokens);
        } else {
            LOG.error("Agent execution failed: runId={}, nodeId={}, " +
                "iterations={}, durationMs={}",
                runId, nodeId, iterations, durationMs);
        }
    }
    
    /**
     * Log LLM call
     */
    public void logLLMCall(
            String provider,
            String model,
            int messageCount,
            int promptTokens,
            int completionTokens) {
        
        LOG.debug("LLM call: provider={}, model={}, messages={}, " +
            "promptTokens={}, completionTokens={}",
            provider, model, messageCount, promptTokens, completionTokens);
    }
    
    /**
     * Log tool execution
     */
    public void logToolExecution(
            String toolName,
            boolean success,
            long durationMs,
            String error) {
        
        if (success) {
            LOG.debug("Tool executed: tool={}, durationMs={}",
                toolName, durationMs);
        } else {
            LOG.warn("Tool execution failed: tool={}, durationMs={}, error={}",
                toolName, durationMs, error);
        }
    }
    
    /**
     * Log memory operation
     */
    public void logMemoryOperation(
            String operation,
            String sessionId,
            int messageCount) {
        
        LOG.trace("Memory operation: op={}, sessionId={}, messageCount={}",
            operation, sessionId, messageCount);
    }
}

// ==================== PERFORMANCE MONITOR ====================

/**
 * Performance monitoring and alerting
 */
@ApplicationScoped
public class AgentPerformanceMonitor {
    
    private static final Logger LOG = LoggerFactory.getLogger(AgentPerformanceMonitor.class);
    
    // Performance thresholds
    private static final long SLOW_EXECUTION_THRESHOLD_MS = 30000; // 30 seconds
    private static final int HIGH_TOKEN_USAGE_THRESHOLD = 4000;
    private static final int MAX_ITERATIONS_THRESHOLD = 8;
    
    /**
     * Check and alert on performance issues
     */
    public void checkPerformance(
            String runId,
            long durationMs,
            int iterations,
            int totalTokens) {
        
        // Check slow execution
        if (durationMs > SLOW_EXECUTION_THRESHOLD_MS) {
            LOG.warn("Slow agent execution detected: runId={}, durationMs={}",
                runId, durationMs);
            // Send alert
        }
        
        // Check high token usage
        if (totalTokens > HIGH_TOKEN_USAGE_THRESHOLD) {
            LOG.warn("High token usage detected: runId={}, totalTokens={}",
                runId, totalTokens);
            // Send alert
        }
        
        // Check excessive iterations
        if (iterations > MAX_ITERATIONS_THRESHOLD) {
            LOG.warn("Excessive iterations detected: runId={}, iterations={}",
                runId, iterations);
            // Send alert
        }
    }
    
    /**
     * Get performance statistics
     */
    public PerformanceStats getStats() {
        // Calculate performance statistics
        return new PerformanceStats(
            0, 0, 0, 0, 0, 0  // Placeholder
        );
    }
}

record PerformanceStats(
    long totalExecutions,
    long slowExecutions,
    long highTokenUsage,
    long excessiveIterations,
    double avgDurationMs,
    double avgTokens
) {}

// ==================== CUSTOM EXCEPTIONS ====================

class CircuitBreakerOpenException extends RuntimeException {
    public CircuitBreakerOpenException(String message) {
        super(message);
    }
}


package tech.kayys.silat.agent.model.impl;

import io.smallrye.mutiny.Uni;
import io.vertx.core.json.JsonArray;
import io.vertx.core.json.JsonObject;
import io.vertx.mutiny.core.buffer.Buffer;
import io.vertx.mutiny.ext.web.client.HttpResponse;
import io.vertx.mutiny.ext.web.client.WebClient;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.eclipse.microprofile.config.inject.ConfigProperty;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import tech.kayys.silat.agent.core.*;
import tech.kayys.silat.agent.model.*;

import java.time.Duration;
import java.util.*;
import java.util.stream.Collectors;

/**
 * ============================================================================
 * REAL LLM HTTP CLIENT IMPLEMENTATIONS
 * ============================================================================
 * 
 * Production-ready HTTP clients for LLM providers using Vert.x WebClient
 * 
 * Features:
 * - Proper HTTP/2 support
 * - Connection pooling
 * - Request/response streaming
 * - Error handling and retries
 * - Rate limit handling
 * - Request/response logging
 */

// ==================== REAL OPENAI PROVIDER ====================

@ApplicationScoped
public class RealOpenAIProvider extends AbstractLLMProvider {
    
    private static final Logger LOG = LoggerFactory.getLogger(RealOpenAIProvider.class);
    
    @Inject
    WebClient webClient;
    
    @ConfigProperty(name = "silat.agent.llm.openai.api-key")
    String apiKey;
    
    @ConfigProperty(name = "silat.agent.llm.openai.base-url", 
                    defaultValue = "https://api.openai.com/v1")
    String baseUrl;
    
    @ConfigProperty(name = "silat.agent.llm.openai.timeout", 
                    defaultValue = "60000")
    long timeout;
    
    public RealOpenAIProvider() {
        super("openai", Map.of());
    }
    
    @Override
    public Uni<LLMResponse> complete(LLMRequest request) {
        validateRequest(request);
        
        LOG.debug("OpenAI API call: model={}, messages={}, tools={}", 
            request.model(), request.messages().size(), request.tools().size());
        
        JsonObject requestBody = buildRequestBody(request);
        
        return webClient
            .postAbs(baseUrl + "/chat/completions")
            .putHeader("Authorization", "Bearer " + apiKey)
            .putHeader("Content-Type", "application/json")
            .timeout(timeout)
            .sendJsonObject(requestBody)
            .onItem().transform(this::handleResponse)
            .onFailure().retry()
                .withBackOff(Duration.ofSeconds(1), Duration.ofSeconds(10))
                .atMost(3)
            .onFailure().transform(this::handleError);
    }
    
    @Override
    public io.smallrye.mutiny.Multi<String> stream(LLMRequest request) {
        validateRequest(request);
        
        JsonObject requestBody = buildRequestBody(request);
        requestBody.put("stream", true);
        
        return webClient
            .postAbs(baseUrl + "/chat/completions")
            .putHeader("Authorization", "Bearer " + apiKey)
            .putHeader("Content-Type", "application/json")
            .timeout(timeout)
            .sendJsonObject(requestBody)
            .onItem().transformToMulti(response -> {
                if (response.statusCode() != 200) {
                    return io.smallrye.mutiny.Multi.createFrom()
                        .failure(new RuntimeException("API error: " + response.statusCode()));
                }
                
                // Parse SSE stream
                return parseSSEStream(response.bodyAsString());
            });
    }
    
    @Override
    public boolean supportsFunctionCalling() {
        return true;
    }
    
    @Override
    public List<String> supportedModels() {
        return List.of(
            "gpt-4-turbo-preview",
            "gpt-4-0125-preview",
            "gpt-4",
            "gpt-4-32k",
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-16k",
            "gpt-4o",
            "gpt-4o-mini"
        );
    }
    
    private JsonObject buildRequestBody(LLMRequest request) {
        JsonObject body = new JsonObject()
            .put("model", request.model())
            .put("messages", convertMessages(request.messages()))
            .put("temperature", request.temperature())
            .put("max_tokens", request.maxTokens());
        
        if (!request.tools().isEmpty()) {
            body.put("tools", convertTools(request.tools()));
            body.put("tool_choice", "auto");
        }
        
        // Add additional params
        request.additionalParams().forEach(body::put);
        
        return body;
    }
    
    @Override
    protected Object convertMessages(List<Message> messages) {
        JsonArray jsonMessages = new JsonArray();
        
        for (Message msg : messages) {
            JsonObject jsonMsg = new JsonObject()
                .put("role", msg.role());
            
            if (msg.content() != null) {
                jsonMsg.put("content", msg.content());
            }
            
            if (msg.hasToolCalls()) {
                JsonArray toolCalls = new JsonArray();
                for (ToolCall tc : msg.toolCalls()) {
                    toolCalls.add(new JsonObject()
                        .put("id", tc.id())
                        .put("type", "function")
                        .put("function", new JsonObject()
                            .put("name", tc.name())
                            .put("arguments", new JsonObject(tc.arguments()).encode())
                        )
                    );
                }
                jsonMsg.put("tool_calls", toolCalls);
            }
            
            if (msg.toolCallId() != null) {
                jsonMsg.put("tool_call_id", msg.toolCallId());
            }
            
            jsonMessages.add(jsonMsg);
        }
        
        return jsonMessages;
    }
    
    @Override
    protected Object convertTools(List<ToolDefinition> tools) {
        JsonArray jsonTools = new JsonArray();
        
        for (ToolDefinition tool : tools) {
            jsonTools.add(new JsonObject()
                .put("type", "function")
                .put("function", new JsonObject()
                    .put("name", tool.name())
                    .put("description", tool.description())
                    .put("parameters", new JsonObject(tool.parameters()))
                )
            );
        }
        
        return jsonTools;
    }
    
    @Override
    protected LLMResponse parseResponse(Object response) {
        JsonObject json = (JsonObject) response;
        JsonArray choices = json.getJsonArray("choices");
        JsonObject firstChoice = choices.getJsonObject(0);
        JsonObject message = firstChoice.getJsonObject("message");
        
        String content = message.getString("content", "");
        String finishReason = firstChoice.getString("finish_reason");
        
        // Parse tool calls
        List<ToolCall> toolCalls = new ArrayList<>();
        JsonArray toolCallsArray = message.getJsonArray("tool_calls");
        if (toolCallsArray != null) {
            for (int i = 0; i < toolCallsArray.size(); i++) {
                JsonObject tc = toolCallsArray.getJsonObject(i);
                JsonObject function = tc.getJsonObject("function");
                
                Map<String, Object> arguments = 
                    new JsonObject(function.getString("arguments")).getMap();
                
                toolCalls.add(ToolCall.create(
                    tc.getString("id"),
                    function.getString("name"),
                    arguments
                ));
            }
        }
        
        // Parse usage
        JsonObject usage = json.getJsonObject("usage");
        TokenUsage tokenUsage = TokenUsage.of(
            usage.getInteger("prompt_tokens"),
            usage.getInteger("completion_tokens")
        );
        
        if (!toolCalls.isEmpty()) {
            return LLMResponse.withToolCalls(content, toolCalls, tokenUsage);
        } else {
            return LLMResponse.create(content, finishReason, tokenUsage);
        }
    }
    
    private LLMResponse handleResponse(HttpResponse<Buffer> response) {
        if (response.statusCode() != 200) {
            String error = response.bodyAsString();
            LOG.error("OpenAI API error: {} - {}", response.statusCode(), error);
            throw new RuntimeException("OpenAI API error: " + response.statusCode());
        }
        
        JsonObject json = response.bodyAsJsonObject();
        return parseResponse(json);
    }
    
    private Throwable handleError(Throwable error) {
        LOG.error("OpenAI API request failed", error);
        
        if (error.getMessage().contains("429")) {
            return new RateLimitException("OpenAI rate limit exceeded");
        } else if (error.getMessage().contains("401")) {
            return new AuthenticationException("Invalid OpenAI API key");
        } else if (error.getMessage().contains("timeout")) {
            return new TimeoutException("OpenAI API timeout");
        }
        
        return error;
    }
    
    private io.smallrye.mutiny.Multi<String> parseSSEStream(String sseData) {
        // Parse Server-Sent Events format
        List<String> chunks = Arrays.asList(sseData.split("\n\n"));
        
        return io.smallrye.mutiny.Multi.createFrom().items(chunks.stream())
            .filter(chunk -> chunk.startsWith("data: "))
            .map(chunk -> chunk.substring(6))
            .filter(data -> !data.equals("[DONE]"))
            .map(data -> {
                JsonObject json = new JsonObject(data);
                JsonArray choices = json.getJsonArray("choices");
                if (choices != null && choices.size() > 0) {
                    JsonObject delta = choices.getJsonObject(0)
                        .getJsonObject("delta");
                    return delta.getString("content", "");
                }
                return "";
            })
            .filter(content -> !content.isEmpty());
    }
}

// ==================== REAL ANTHROPIC PROVIDER ====================

@ApplicationScoped
public class RealAnthropicProvider extends AbstractLLMProvider {
    
    private static final Logger LOG = LoggerFactory.getLogger(RealAnthropicProvider.class);
    
    @Inject
    WebClient webClient;
    
    @ConfigProperty(name = "silat.agent.llm.anthropic.api-key")
    String apiKey;
    
    @ConfigProperty(name = "silat.agent.llm.anthropic.base-url",
                    defaultValue = "https://api.anthropic.com/v1")
    String baseUrl;
    
    @ConfigProperty(name = "silat.agent.llm.anthropic.timeout",
                    defaultValue = "60000")
    long timeout;
    
    private static final String ANTHROPIC_VERSION = "2023-06-01";
    
    public RealAnthropicProvider() {
        super("anthropic", Map.of());
    }
    
    @Override
    public Uni<LLMResponse> complete(LLMRequest request) {
        validateRequest(request);
        
        LOG.debug("Anthropic API call: model={}, messages={}", 
            request.model(), request.messages().size());
        
        JsonObject requestBody = buildRequestBody(request);
        
        return webClient
            .postAbs(baseUrl + "/messages")
            .putHeader("x-api-key", apiKey)
            .putHeader("anthropic-version", ANTHROPIC_VERSION)
            .putHeader("Content-Type", "application/json")
            .timeout(timeout)
            .sendJsonObject(requestBody)
            .onItem().transform(this::handleResponse)
            .onFailure().retry()
                .withBackOff(Duration.ofSeconds(1), Duration.ofSeconds(10))
                .atMost(3)
            .onFailure().transform(this::handleError);
    }
    
    @Override
    public io.smallrye.mutiny.Multi<String> stream(LLMRequest request) {
        validateRequest(request);
        
        JsonObject requestBody = buildRequestBody(request);
        requestBody.put("stream", true);
        
        return webClient
            .postAbs(baseUrl + "/messages")
            .putHeader("x-api-key", apiKey)
            .putHeader("anthropic-version", ANTHROPIC_VERSION)
            .putHeader("Content-Type", "application/json")
            .timeout(timeout)
            .sendJsonObject(requestBody)
            .onItem().transformToMulti(response -> parseStreamResponse(response));
    }
    
    @Override
    public boolean supportsFunctionCalling() {
        return true;
    }
    
    @Override
    public List<String> supportedModels() {
        return List.of(
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307",
            "claude-3-5-sonnet-20241022",
            "claude-2.1",
            "claude-2.0"
        );
    }
    
    private JsonObject buildRequestBody(LLMRequest request) {
        // Extract system message
        String systemMessage = request.messages().stream()
            .filter(Message::isSystem)
            .map(Message::content)
            .findFirst()
            .orElse(null);
        
        // Get non-system messages
        List<Message> userMessages = request.messages().stream()
            .filter(msg -> !msg.isSystem())
            .collect(Collectors.toList());
        
        JsonObject body = new JsonObject()
            .put("model", request.model())
            .put("max_tokens", request.maxTokens())
            .put("messages", convertMessages(userMessages));
        
        if (systemMessage != null) {
            body.put("system", systemMessage);
        }
        
        if (request.temperature() != null) {
            body.put("temperature", request.temperature());
        }
        
        if (!request.tools().isEmpty()) {
            body.put("tools", convertTools(request.tools()));
        }
        
        return body;
    }
    
    @Override
    protected Object convertMessages(List<Message> messages) {
        JsonArray jsonMessages = new JsonArray();
        
        for (Message msg : messages) {
            JsonObject jsonMsg = new JsonObject()
                .put("role", msg.role());
            
            // Anthropic uses content array format
            JsonArray content = new JsonArray();
            
            if (msg.content() != null) {
                content.add(new JsonObject()
                    .put("type", "text")
                    .put("text", msg.content())
                );
            }
            
            // Add tool use blocks
            if (msg.hasToolCalls()) {
                for (ToolCall tc : msg.toolCalls()) {
                    content.add(new JsonObject()
                        .put("type", "tool_use")
                        .put("id", tc.id())
                        .put("name", tc.name())
                        .put("input", new JsonObject(tc.arguments()))
                    );
                }
            }
            
            // Add tool result blocks
            if (msg.toolCallId() != null) {
                content.add(new JsonObject()
                    .put("type", "tool_result")
                    .put("tool_use_id", msg.toolCallId())
                    .put("content", msg.content())
                );
            }
            
            jsonMsg.put("content", content);
            jsonMessages.add(jsonMsg);
        }
        
        return jsonMessages;
    }
    
    @Override
    protected Object convertTools(List<ToolDefinition> tools) {
        JsonArray jsonTools = new JsonArray();
        
        for (ToolDefinition tool : tools) {
            jsonTools.add(new JsonObject()
                .put("name", tool.name())
                .put("description", tool.description())
                .put("input_schema", new JsonObject(tool.parameters()))
            );
        }
        
        return jsonTools;
    }
    
    @Override
    protected LLMResponse parseResponse(Object response) {
        JsonObject json = (JsonObject) response;
        JsonArray content = json.getJsonArray("content");
        
        StringBuilder textContent = new StringBuilder();
        List<ToolCall> toolCalls = new ArrayList<>();
        
        for (int i = 0; i < content.size(); i++) {
            JsonObject block = content.getJsonObject(i);
            String type = block.getString("type");
            
            if ("text".equals(type)) {
                textContent.append(block.getString("text"));
            } else if ("tool_use".equals(type)) {
                toolCalls.add(ToolCall.create(
                    block.getString("id"),
                    block.getString("name"),
                    block.getJsonObject("input").getMap()
                ));
            }
        }
        
        JsonObject usage = json.getJsonObject("usage");
        TokenUsage tokenUsage = TokenUsage.of(
            usage.getInteger("input_tokens"),
            usage.getInteger("output_tokens")
        );
        
        String finishReason = json.getString("stop_reason");
        
        if (!toolCalls.isEmpty()) {
            return LLMResponse.withToolCalls(
                textContent.toString(), toolCalls, tokenUsage);
        } else {
            return LLMResponse.create(
                textContent.toString(), finishReason, tokenUsage);
        }
    }
    
    private LLMResponse handleResponse(HttpResponse<Buffer> response) {
        if (response.statusCode() != 200) {
            String error = response.bodyAsString();
            LOG.error("Anthropic API error: {} - {}", response.statusCode(), error);
            throw new RuntimeException("Anthropic API error: " + response.statusCode());
        }
        
        JsonObject json = response.bodyAsJsonObject();
        return parseResponse(json);
    }
    
    private Throwable handleError(Throwable error) {
        LOG.error("Anthropic API request failed", error);
        
        if (error.getMessage().contains("429")) {
            return new RateLimitException("Anthropic rate limit exceeded");
        } else if (error.getMessage().contains("401")) {
            return new AuthenticationException("Invalid Anthropic API key");
        }
        
        return error;
    }
    
    private io.smallrye.mutiny.Multi<String> parseStreamResponse(
            HttpResponse<Buffer> response) {
        
        if (response.statusCode() != 200) {
            return io.smallrye.mutiny.Multi.createFrom()
                .failure(new RuntimeException("API error: " + response.statusCode()));
        }
        
        // Parse SSE stream
        String body = response.bodyAsString();
        return parseSSEStream(body);
    }
    
    private io.smallrye.mutiny.Multi<String> parseSSEStream(String sseData) {
        List<String> chunks = Arrays.asList(sseData.split("\n\n"));
        
        return io.smallrye.mutiny.Multi.createFrom().items(chunks.stream())
            .filter(chunk -> chunk.startsWith("data: "))
            .map(chunk -> chunk.substring(6))
            .filter(data -> !data.equals("[DONE]"))
            .map(data -> {
                JsonObject json = new JsonObject(data);
                String type = json.getString("type");
                
                if ("content_block_delta".equals(type)) {
                    JsonObject delta = json.getJsonObject("delta");
                    return delta.getString("text", "");
                }
                return "";
            })
            .filter(content -> !content.isEmpty());
    }
}

// ==================== AZURE OPENAI PROVIDER ====================

@ApplicationScoped
public class AzureOpenAIProvider extends AbstractLLMProvider {
    
    private static final Logger LOG = LoggerFactory.getLogger(AzureOpenAIProvider.class);
    
    @Inject
    WebClient webClient;
    
    @ConfigProperty(name = "silat.agent.llm.azure.api-key")
    Optional<String> apiKey;
    
    @ConfigProperty(name = "silat.agent.llm.azure.endpoint")
    Optional<String> endpoint;
    
    @ConfigProperty(name = "silat.agent.llm.azure.deployment")
    Optional<String> deployment;
    
    @ConfigProperty(name = "silat.agent.llm.azure.api-version",
                    defaultValue = "2024-02-15-preview")
    String apiVersion;
    
    public AzureOpenAIProvider() {
        super("azure-openai", Map.of());
    }
    
    @Override
    public Uni<LLMResponse> complete(LLMRequest request) {
        if (apiKey.isEmpty() || endpoint.isEmpty() || deployment.isEmpty()) {
            return Uni.createFrom().failure(
                new IllegalStateException("Azure OpenAI not configured"));
        }
        
        validateRequest(request);
        
        String url = String.format("%s/openai/deployments/%s/chat/completions?api-version=%s",
            endpoint.get(), deployment.get(), apiVersion);
        
        JsonObject requestBody = buildRequestBody(request);
        
        return webClient
            .postAbs(url)
            .putHeader("api-key", apiKey.get())
            .putHeader("Content-Type", "application/json")
            .sendJsonObject(requestBody)
            .onItem().transform(this::handleResponse)
            .onFailure().retry().atMost(3)
            .onFailure().transform(this::handleError);
    }
    
    @Override
    public io.smallrye.mutiny.Multi<String> stream(LLMRequest request) {
        // Similar to OpenAI streaming implementation
        return io.smallrye.mutiny.Multi.createFrom()
            .failure(new UnsupportedOperationException("Streaming not yet implemented"));
    }
    
    @Override
    public boolean supportsFunctionCalling() {
        return true;
    }
    
    @Override
    public List<String> supportedModels() {
        // Azure uses deployment names, not model names
        return List.of("azure-deployment");
    }
    
    private JsonObject buildRequestBody(LLMRequest request) {
        // Same as OpenAI format
        return new JsonObject()
            .put("messages", convertMessages(request.messages()))
            .put("temperature", request.temperature())
            .put("max_tokens", request.maxTokens());
    }
    
    @Override
    protected Object convertMessages(List<Message> messages) {
        // Same as OpenAI
        return new RealOpenAIProvider().convertMessages(messages);
    }
    
    @Override
    protected Object convertTools(List<ToolDefinition> tools) {
        // Same as OpenAI
        return new RealOpenAIProvider().convertTools(tools);
    }
    
    @Override
    protected LLMResponse parseResponse(Object response) {
        // Same as OpenAI
        return new RealOpenAIProvider().parseResponse(response);
    }
    
    private LLMResponse handleResponse(HttpResponse<Buffer> response) {
        if (response.statusCode() != 200) {
            throw new RuntimeException("Azure OpenAI error: " + response.statusCode());
        }
        return parseResponse(response.bodyAsJsonObject());
    }
    
    private Throwable handleError(Throwable error) {
        LOG.error("Azure OpenAI request failed", error);
        return error;
    }
}

// ==================== CUSTOM EXCEPTIONS ====================

class RateLimitException extends RuntimeException {
    public RateLimitException(String message) {
        super(message);
    }
}

class AuthenticationException extends RuntimeException {
    public AuthenticationException(String message) {
        super(message);
    }
}

class TimeoutException extends RuntimeException {
    public TimeoutException(String message) {
        super(message);
    }
}


package tech.kayys.silat.agent.vector;

import io.smallrye.mutiny.Uni;
import io.vertx.core.json.JsonArray;
import io.vertx.core.json.JsonObject;
import io.vertx.mutiny.core.buffer.Buffer;
import io.vertx.mutiny.ext.web.client.WebClient;
import jakarta.enterprise.context.ApplicationScoped;
import jakarta.inject.Inject;
import org.eclipse.microprofile.config.inject.ConfigProperty;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import tech.kayys.silat.agent.core.Message;

import java.time.Instant;
import java.util.*;
import java.util.stream.Collectors;

/**
 * ============================================================================
 * VECTOR DATABASE INTEGRATION
 * ============================================================================
 * 
 * Semantic memory using vector embeddings for context-aware retrieval.
 * 
 * Supported vector databases:
 * - Pinecone
 * - Weaviate
 * - Qdrant
 * - Chroma
 * - PostgreSQL with pgvector
 * 
 * Features:
 * - Automatic embedding generation
 * - Semantic similarity search
 * - Metadata filtering
 * - Hybrid search (vector + keyword)
 */

// ==================== EMBEDDING SERVICE ====================

/**
 * Service for generating embeddings from text
 */
@ApplicationScoped
public class EmbeddingService {
    
    private static final Logger LOG = LoggerFactory.getLogger(EmbeddingService.class);
    
    @Inject
    WebClient webClient;
    
    @ConfigProperty(name = "silat.agent.embeddings.provider", 
                    defaultValue = "openai")
    String provider;
    
    @ConfigProperty(name = "silat.agent.embeddings.model",
                    defaultValue = "text-embedding-ada-002")
    String model;
    
    @ConfigProperty(name = "silat.agent.llm.openai.api-key")
    String openaiApiKey;
    
    /**
     * Generate embedding vector for text
     */
    public Uni<float[]> generateEmbedding(String text) {
        LOG.debug("Generating embedding for text: {} chars", text.length());
        
        return switch (provider.toLowerCase()) {
            case "openai" -> generateOpenAIEmbedding(text);
            case "huggingface" -> generateHuggingFaceEmbedding(text);
            default -> Uni.createFrom().failure(
                new IllegalArgumentException("Unsupported embedding provider: " + provider));
        };
    }
    
    /**
     * Generate embeddings for multiple texts (batch)
     */
    public Uni<List<float[]>> generateEmbeddings(List<String> texts) {
        LOG.debug("Generating embeddings for {} texts", texts.size());
        
        // Batch API call for efficiency
        return switch (provider.toLowerCase()) {
            case "openai" -> generateOpenAIEmbeddingsBatch(texts);
            default -> {
                // Fallback to sequential calls
                List<Uni<float[]>> unis = texts.stream()
                    .map(this::generateEmbedding)
                    .collect(Collectors.toList());
                
                yield Uni.combine().all().unis(unis).combinedWith(
                    results -> results.stream()
                        .map(r -> (float[]) r)
                        .collect(Collectors.toList())
                );
            }
        };
    }
    
    private Uni<float[]> generateOpenAIEmbedding(String text) {
        JsonObject requestBody = new JsonObject()
            .put("input", text)
            .put("model", model);
        
        return webClient
            .postAbs("https://api.openai.com/v1/embeddings")
            .putHeader("Authorization", "Bearer " + openaiApiKey)
            .putHeader("Content-Type", "application/json")
            .sendJsonObject(requestBody)
            .map(response -> {
                if (response.statusCode() != 200) {
                    throw new RuntimeException("Embedding API error: " + response.statusCode());
                }
                
                JsonObject json = response.bodyAsJsonObject();
                JsonArray data = json.getJsonArray("data");
                JsonObject embeddingObj = data.getJsonObject(0);
                JsonArray embedding = embeddingObj.getJsonArray("embedding");
                
                float[] vector = new float[embedding.size()];
                for (int i = 0; i < embedding.size(); i++) {
                    vector[i] = embedding.getDouble(i).floatValue();
                }
                
                LOG.trace("Generated embedding: dimension={}", vector.length);
                return vector;
            });
    }
    
    private Uni<List<float[]>> generateOpenAIEmbeddingsBatch(List<String> texts) {
        JsonObject requestBody = new JsonObject()
            .put("input", new JsonArray(texts))
            .put("model", model);
        
        return webClient
            .postAbs("https://api.openai.com/v1/embeddings")
            .putHeader("Authorization", "Bearer " + openaiApiKey)
            .putHeader("Content-Type", "application/json")
            .sendJsonObject(requestBody)
            .map(response -> {
                JsonObject json = response.bodyAsJsonObject();
                JsonArray data = json.getJsonArray("data");
                
                List<float[]> embeddings = new ArrayList<>();
                for (int i = 0; i < data.size(); i++) {
                    JsonObject embeddingObj = data.getJsonObject(i);
                    JsonArray embedding = embeddingObj.getJsonArray("embedding");
                    
                    float[] vector = new float[embedding.size()];
                    for (int j = 0; j < embedding.size(); j++) {
                        vector[j] = embedding.getDouble(j).floatValue();
                    }
                    embeddings.add(vector);
                }
                
                return embeddings;
            });
    }
    
    private Uni<float[]> generateHuggingFaceEmbedding(String text) {
        // Implementation for HuggingFace embeddings
        return Uni.createFrom().failure(
            new UnsupportedOperationException("HuggingFace embeddings not yet implemented"));
    }
}

// ==================== VECTOR STORE INTERFACE ====================

/**
 * Interface for vector database operations
 */
public interface VectorStore {
    
    /**
     * Store message with embedding
     */
    Uni<String> store(
        String sessionId,
        String tenantId,
        Message message,
        float[] embedding
    );
    
    /**
     * Search similar messages
     */
    Uni<List<SimilarMessage>> search(
        String sessionId,
        String tenantId,
        float[] queryEmbedding,
        int limit
    );
    
    /**
     * Search with metadata filters
     */
    Uni<List<SimilarMessage>> searchWithFilter(
        String sessionId,
        String tenantId,
        float[] queryEmbedding,
        Map<String, Object> filters,
        int limit
    );
    
    /**
     * Delete messages for session
     */
    Uni<Void> deleteSession(String sessionId, String tenantId);
    
    /**
     * Get statistics
     */
    Uni<VectorStoreStats> getStats(String tenantId);
}

record SimilarMessage(
    String id,
    Message message,
    double similarity,
    Map<String, Object> metadata
) {}

record VectorStoreStats(
    long totalVectors,
    long dimensionality,
    String indexType
) {}

// ==================== PINECONE IMPLEMENTATION ====================

@ApplicationScoped
public class PineconeVectorStore implements VectorStore {
    
    private static final Logger LOG = LoggerFactory.getLogger(PineconeVectorStore.class);
    
    @Inject
    WebClient webClient;
    
    @Inject
    EmbeddingService embeddingService;
    
    @ConfigProperty(name = "silat.agent.memory.vector.pinecone.api-key")
    Optional<String> apiKey;
    
    @ConfigProperty(name = "silat.agent.memory.vector.pinecone.environment")
    Optional<String> environment;
    
    @ConfigProperty(name = "silat.agent.memory.vector.pinecone.index-name")
    Optional<String> indexName;
    
    @Override
    public Uni<String> store(
            String sessionId,
            String tenantId,
            Message message,
            float[] embedding) {
        
        if (!isConfigured()) {
            return Uni.createFrom().failure(
                new IllegalStateException("Pinecone not configured"));
        }
        
        String vectorId = UUID.randomUUID().toString();
        String url = buildUrl("/vectors/upsert");
        
        JsonObject metadata = new JsonObject()
            .put("sessionId", sessionId)
            .put("tenantId", tenantId)
            .put("role", message.role())
            .put("content", message.content())
            .put("timestamp", message.timestamp().toEpochMilli());
        
        JsonObject vector = new JsonObject()
            .put("id", vectorId)
            .put("values", new JsonArray(toList(embedding)))
            .put("metadata", metadata);
        
        JsonObject requestBody = new JsonObject()
            .put("vectors", new JsonArray().add(vector))
            .put("namespace", makeNamespace(tenantId));
        
        return webClient
            .postAbs(url)
            .putHeader("Api-Key", apiKey.get())
            .putHeader("Content-Type", "application/json")
            .sendJsonObject(requestBody)
            .map(response -> {
                if (response.statusCode() != 200) {
                    throw new RuntimeException("Pinecone error: " + response.statusCode());
                }
                LOG.debug("Stored vector: {}", vectorId);
                return vectorId;
            });
    }
    
    @Override
    public Uni<List<SimilarMessage>> search(
            String sessionId,
            String tenantId,
            float[] queryEmbedding,
            int limit) {
        
        return searchWithFilter(sessionId, tenantId, queryEmbedding, 
            Map.of("sessionId", sessionId), limit);
    }
    
    @Override
    public Uni<List<SimilarMessage>> searchWithFilter(
            String sessionId,
            String tenantId,
            float[] queryEmbedding,
            Map<String, Object> filters,
            int limit) {
        
        if (!isConfigured()) {
            return Uni.createFrom().item(List.of());
        }
        
        String url = buildUrl("/query");
        
        JsonObject filterObj = new JsonObject();
        filters.forEach(filterObj::put);
        
        JsonObject requestBody = new JsonObject()
            .put("vector", new JsonArray(toList(queryEmbedding)))
            .put("topK", limit)
            .put("includeMetadata", true)
            .put("namespace", makeNamespace(tenantId))
            .put("filter", filterObj);
        
        return webClient
            .postAbs(url)
            .putHeader("Api-Key", apiKey.get())
            .putHeader("Content-Type", "application/json")
            .sendJsonObject(requestBody)
            .map(response -> {
                if (response.statusCode() != 200) {
                    throw new RuntimeException("Pinecone query error: " + response.statusCode());
                }
                
                JsonObject json = response.bodyAsJsonObject();
                JsonArray matches = json.getJsonArray("matches");
                
                List<SimilarMessage> results = new ArrayList<>();
                for (int i = 0; i < matches.size(); i++) {
                    JsonObject match = matches.getJsonObject(i);
                    JsonObject metadata = match.getJsonObject("metadata");
                    
                    Message message = new Message(
                        metadata.getString("role"),
                        metadata.getString("content"),
                        null,
                        null,
                        Instant.ofEpochMilli(metadata.getLong("timestamp"))
                    );
                    
                    results.add(new SimilarMessage(
                        match.getString("id"),
                        message,
                        match.getDouble("score"),
                        metadata.getMap()
                    ));
                }
                
                LOG.debug("Found {} similar messages", results.size());
                return results;
            });
    }
    
    @Override
    public Uni<Void> deleteSession(String sessionId, String tenantId) {
        String url = buildUrl("/vectors/delete");
        
        JsonObject requestBody = new JsonObject()
            .put("filter", new JsonObject()
                .put("sessionId", sessionId)
                .put("tenantId", tenantId))
            .put("namespace", makeNamespace(tenantId));
        
        return webClient
            .postAbs(url)
            .putHeader("Api-Key", apiKey.get())
            .putHeader("Content-Type", "application/json")
            .sendJsonObject(requestBody)
            .map(response -> null);
    }
    
    @Override
    public Uni<VectorStoreStats> getStats(String tenantId) {
        String url = buildUrl("/describe_index_stats");
        
        return webClient
            .getAbs(url)
            .putHeader("Api-Key", apiKey.get())
            .send()
            .map(response -> {
                JsonObject json = response.bodyAsJsonObject();
                return new VectorStoreStats(
                    json.getLong("totalVectorCount"),
                    json.getInteger("dimension"),
                    "pinecone"
                );
            });
    }
    
    private boolean isConfigured() {
        return apiKey.isPresent() && environment.isPresent() && indexName.isPresent();
    }
    
    private String buildUrl(String path) {
        return String.format("https://%s-%s.svc.%s.pinecone.io%s",
            indexName.get(), "default", environment.get(), path);
    }
    
    private String makeNamespace(String tenantId) {
        return "tenant_" + tenantId;
    }
    
    private List<Double> toList(float[] array) {
        List<Double> list = new ArrayList<>(array.length);
        for (float value : array) {
            list.add((double) value);
        }
        return list;
    }
}

// ==================== PGVECTOR IMPLEMENTATION ====================

@ApplicationScoped
public class PostgresVectorStore implements VectorStore {
    
    private static final Logger LOG = LoggerFactory.getLogger(PostgresVectorStore.class);
    
    @Inject
    io.vertx.mutiny.pgclient.PgPool pgPool;
    
    @Override
    public Uni<String> store(
            String sessionId,
            String tenantId,
            Message message,
            float[] embedding) {
        
        String id = UUID.randomUUID().toString();
        String vectorString = toVectorString(embedding);
        
        String sql = """
            INSERT INTO vector_memory (
                id, session_id, tenant_id, role, content, 
                embedding, timestamp
            ) VALUES ($1, $2, $3, $4, $5, $6::vector, $7)
            """;
        
        return pgPool.preparedQuery(sql)
            .execute(io.vertx.mutiny.sqlclient.Tuple.of(
                id, sessionId, tenantId, message.role(), message.content(),
                vectorString, message.timestamp()
            ))
            .map(rowSet -> {
                LOG.debug("Stored vector in PostgreSQL: {}", id);
                return id;
            });
    }
    
    @Override
    public Uni<List<SimilarMessage>> search(
            String sessionId,
            String tenantId,
            float[] queryEmbedding,
            int limit) {
        
        String vectorString = toVectorString(queryEmbedding);
        
        String sql = """
            SELECT id, role, content, timestamp, 
                   1 - (embedding <=> $1::vector) as similarity
            FROM vector_memory
            WHERE session_id = $2 AND tenant_id = $3
            ORDER BY embedding <=> $1::vector
            LIMIT $4
            """;
        
        return pgPool.preparedQuery(sql)
            .execute(io.vertx.mutiny.sqlclient.Tuple.of(
                vectorString, sessionId, tenantId, limit
            ))
            .map(rowSet -> {
                List<SimilarMessage> results = new ArrayList<>();
                
                rowSet.forEach(row -> {
                    Message message = new Message(
                        row.getString("role"),
                        row.getString("content"),
                        null,
                        null,
                        row.getLocalDateTime("timestamp")
                            .atZone(java.time.ZoneOffset.UTC)
                            .toInstant()
                    );
                    
                    results.add(new SimilarMessage(
                        row.getString("id"),
                        message,
                        row.getDouble("similarity"),
                        Map.of()
                    ));
                });
                
                return results;
            });
    }
    
    @Override
    public Uni<List<SimilarMessage>> searchWithFilter(
            String sessionId,
            String tenantId,
            float[] queryEmbedding,
            Map<String, Object> filters,
            int limit) {
        
        // For pgvector, metadata filtering would require additional columns
        return search(sessionId, tenantId, queryEmbedding, limit);
    }
    
    @Override
    public Uni<Void> deleteSession(String sessionId, String tenantId) {
        String sql = "DELETE FROM vector_memory WHERE session_id = $1 AND tenant_id = $2";
        
        return pgPool.preparedQuery(sql)
            .execute(io.vertx.mutiny.sqlclient.Tuple.of(sessionId, tenantId))
            .replaceWithVoid();
    }
    
    @Override
    public Uni<VectorStoreStats> getStats(String tenantId) {
        String sql = """
            SELECT COUNT(*) as total_vectors
            FROM vector_memory
            WHERE tenant_id = $1
            """;
        
        return pgPool.preparedQuery(sql)
            .execute(io.vertx.mutiny.sqlclient.Tuple.of(tenantId))
            .map(rowSet -> {
                long total = rowSet.iterator().next().getLong("total_vectors");
                return new VectorStoreStats(total, 1536, "pgvector");
            });
    }
    
    private String toVectorString(float[] vector) {
        StringBuilder sb = new StringBuilder("[");
        for (int i = 0; i < vector.length; i++) {
            if (i > 0) sb.append(",");
            sb.append(vector[i]);
        }
        sb.append("]");
        return sb.toString();
    }
}

// ==================== VECTOR MEMORY STRATEGY ====================

@ApplicationScoped
public class ProductionVectorMemoryStrategy implements 
        tech.kayys.silat.agent.memory.MemoryStrategy {
    
    private static final Logger LOG = LoggerFactory.getLogger(ProductionVectorMemoryStrategy.class);
    
    @Inject
    VectorStore vectorStore;
    
    @Inject
    EmbeddingService embeddingService;
    
    @Override
    public List<Message> process(List<Message> messages, Integer windowSize) {
        // Vector memory retrieval happens via search, not process
        // Return recent messages as fallback
        int window = windowSize != null ? windowSize : 10;
        int startIndex = Math.max(0, messages.size() - window);
        return new ArrayList<>(messages.subList(startIndex, messages.size()));
    }
    
    @Override
    public String getType() {
        return "vector";
    }
    
    /**
     * Search semantic memory
     */
    public Uni<List<Message>> semanticSearch(
            String sessionId,
            String tenantId,
            String query,
            int limit) {
        
        LOG.debug("Semantic search: query='{}', limit={}", query, limit);
        
        return embeddingService.generateEmbedding(query)
            .flatMap(embedding -> 
                vectorStore.search(sessionId, tenantId, embedding, limit)
            )
            .map(results -> results.stream()
                .map(SimilarMessage::message)
                .collect(Collectors.toList())
            );
    }
    
    /**
     * Store messages with embeddings
     */
    public Uni<Void> storeMessages(
            String sessionId,
            String tenantId,
            List<Message> messages) {
        
        // Generate embeddings for all messages
        List<String> texts = messages.stream()
            .map(Message::content)
            .filter(Objects::nonNull)
            .collect(Collectors.toList());
        
        return embeddingService.generateEmbeddings(texts)
            .flatMap(embeddings -> {
                List<Uni<String>> storeOps = new ArrayList<>();
                
                for (int i = 0; i < messages.size(); i++) {
                    Message msg = messages.get(i);
                    float[] embedding = embeddings.get(i);
                    
                    storeOps.add(vectorStore.store(
                        sessionId, tenantId, msg, embedding));
                }
                
                return Uni.combine().all().unis(storeOps).combinedWith(
                    results -> null
                );
            })
            .replaceWithVoid();
    }
}

// ==================== PGVECTOR SCHEMA ====================

/*
-- PostgreSQL schema for pgvector

CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE vector_memory (
    id UUID PRIMARY KEY,
    session_id VARCHAR(255) NOT NULL,
    tenant_id VARCHAR(255) NOT NULL,
    role VARCHAR(50) NOT NULL,
    content TEXT,
    embedding vector(1536), -- OpenAI ada-002 dimension
    timestamp TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_vector_memory_session ON vector_memory(session_id, tenant_id);
CREATE INDEX idx_vector_memory_embedding ON vector_memory 
    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- For faster similarity search
CREATE INDEX idx_vector_memory_hnsw ON vector_memory 
    USING hnsw (embedding vector_cosine_ops);
*/

